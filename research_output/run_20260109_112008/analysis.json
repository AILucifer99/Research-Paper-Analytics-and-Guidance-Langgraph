{
  "metadata": {
    "timestamp": "20260109_112008",
    "topics_analyzed": 3,
    "total_papers": 53,
    "companies_found": 12,
    "strategic_insights": {
      "gaps": [
        "Lack of explicit limitation statements in abstracts hinders understanding of research scope and potential biases.",
        "Limited scalability and high computational cost associated with LLM integration, RAG, and multimodal models.",
        "Absence of automated, contextual explanations for detected changes in data.",
        "Insufficient information on datasets used (size, source, characteristics) limits generalizability assessment.",
        "Unclear understanding of the types of questions models can answer and the complexity of data they can process.",
        "Limited evaluation settings (e.g., simulation environments, specific ANNS methods, single datasets) restricts real-world applicability.",
        "Gap between open-source and proprietary model performance requires further investigation.",
        "Dependence on the quality of underlying components (e.g., LLM-as-a-judge, lightweight VLMs) introduces potential vulnerabilities.",
        "Limited support for diverse visual data formats (e.g., videos, visual documents) in existing models."
      ],
      "trends": [
        "Focus on improving efficiency and accuracy of RAG for video data.",
        "Development of multi-agent reinforcement learning systems with memory capabilities.",
        "Exploration of agentic computer vision systems for image analysis.",
        "Integration of LLMs for improved reasoning and contextual understanding in various applications.",
        "Use of retrieval-augmented generation (RAG) to enhance model performance.",
        "Development of multimodal embedding models to handle visual and textual information.",
        "Application of LLMs as judges for evaluating model performance.",
        "Focus on hallucination detection and mitigation in LLMs using techniques like conformal prediction.",
        "Use of GANs (Generative Adversarial Networks) for specific tasks (dataset not specified)."
      ],
      "recommendations": [
        "Researchers should explicitly state limitations in abstracts to improve transparency and facilitate critical evaluation.",
        "Investigate methods to improve the scalability and reduce the computational cost of LLM-based approaches, RAG, and multimodal models.",
        "Develop automated methods for generating contextual explanations of model outputs and detected changes.",
        "Provide detailed information about datasets used in research, including size, source, characteristics, and potential biases.",
        "Evaluate models on diverse and realistic datasets to assess generalizability and real-world performance.",
        "Explore methods to bridge the performance gap between open-source and proprietary models.",
        "Investigate the robustness and reliability of underlying components (e.g., LLMs, VLMs) and develop strategies to mitigate potential vulnerabilities.",
        "Develop methods to handle diverse visual data formats and complex visual tasks more effectively.",
        "Conduct larger and more comprehensive clinical trials to validate the effectiveness of developed systems.",
        "Explore and compare different hallucination detection techniques and their performance characteristics.",
        "Investigate the practical implementation challenges of complex theoretical frameworks and hyperparameter tuning.",
        "Focus on developing methods that are effective across a wide range of question types and data complexity levels."
      ]
    }
  },
  "topics": [
    "Retrieval Augmented Generation on Video Data.",
    "Multi-Agent Reinforcement Learning with memory.",
    "Agentic Computer Vision System for Image Analysis."
  ],
  "topic_statistics": [
    {
      "topic": "Retrieval Augmented Generation on Video Data.",
      "paper_count": 24,
      "methods_distribution": {
        "Lightweight path extraction to link related concepts.": 1,
        "Hybrid retrieval combining standard search with path-aligned retrieval.": 1,
        "Ensemble changepoint detection (aggregation of ten distinct algorithms)": 1,
        "Large Language Models (LLMs) for explanation generation": 1,
        "Retrieval-Augmented Generation (RAG) for domain-specific explanations": 1,
        "Retrieval-Augmented Generation (RAG)": 2,
        "Speculative Decoding": 1,
        "Similarity-based Filtering": 1,
        "Vision Transformers (ViTs)": 1,
        "Retrieval-Augmented Generation (RAG) with a Large Language Model (LLM)": 1,
        "Neuro-Symbolic Integration (combining symbolic medical reasoning with subsymbolic visual learning)": 1,
        "Conformal Prediction: Transforming heuristic scores (from embedding similarity and NLI) into decision sets with finite-sample coverage guarantees.": 1,
        "Embedding Similarity: Using embedding similarity between retrieved context and generated response for hallucination detection.": 1,
        "Natural Language Inference (NLI): Using NLI models to determine if the generated response is supported by the retrieved context.": 1,
        "GPT-4 as a Judge: Utilizing GPT-4 to evaluate the presence of hallucinations in the generated responses.": 1,
        "Information-geometric analysis using Bregman projections in distribution space.": 1,
        "Stochastic modeling of the self-referential learning loop.": 1,
        "Theoretical derivation of conditions for entropy decay and stabilization.": 1,
        "Empirical validation of theoretical predictions through experiments on large language models, reinforcement learning (Soft Actor-Critic), and GANs.": 1,
        "Human action recognition algorithm fusing visual and 3D skeletal data for exercise video segmentation.": 1,
        "Retrieval-augmented generation (RAG) framework for generating clinically relevant assessment reports using a domain-specific knowledge base and a multi-modal large language model.": 1,
        "Orthogonal Decoupling Design of Storage, Computation, and Interaction for the Sovereign Digital Avatar (SoDA)": 1,
        "Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor (Sensitivity Coefficient and Strictness Parameter) adaptive routing.": 1,
        "High-fidelity simulation environment for empirical evaluation.": 1,
        "Categorization and formalization of data deletion methods in graph-based ANNS.": 1,
        "Experimental evaluation using accuracy, query speed, and other relevant metrics.": 1,
        "Application of the framework to HNSW and introduction of Deletion Control.": 1,
        "Retrieval-Augmented Generation (RAG): Employing a retrieval component to fetch relevant information from MusWikiDB before generating answers using LLMs.": 1,
        "Fine-tuning: Fine-tuning LLMs using the ArtistMus dataset to further improve performance on music question answering.": 1,
        "Caption Injection (extracting captions from images and injecting them into textual content)": 1,
        "Evaluation using the G-Eval metric to assess user-perceived content visibility": 1,
        "Retrieval Augmented Generation (RAG)": 2,
        "Graph database for storing and querying 3D scene graphs": 1,
        "Cypher query language as an interface for LLMs to access the graph database": 1,
        "Comparison with baseline context window and code generation methods.": 1,
        "Direct reranking visualization": 1,
        "Blind pairwise comparisons with human or LLM voting": 1,
        "Supervised manual document annotation": 1,
        "End-to-end RAG answer quality assessment": 1,
        "LLM-as-a-judge evaluation": 1,
        "Hierarchical query decomposition for frame pre-filtering": 1,
        "Lightweight Vision-Language Model (VLM) for frame scoring": 1,
        "Frame retrieval using global statistical distribution of inter-frame scores": 1,
        "Multi-view question answering": 1,
        "Unified embedding learning across diverse visual forms (text, image, video, visual documents)": 1,
        "Training a general-purpose embedding model (VLM2Vec-V2) on the expanded MMEB-V2 benchmark.": 1,
        "Adaptive Retrieval-Augmented Generation (RAG)": 1,
        "Intent Classification for determining query complexity": 1,
        "Omni-Knowledge Indexing (text, visual, and knowledge graph databases)": 1,
        "Hierarchical Knowledge Access (naive to graph-based retrieval)": 1,
        "Automatic generation of MMKGs through a pipeline with stringent filtering and alignment steps.": 1,
        "Cross-modal knowledge alignment techniques to ensure coherence between visual, audio, and text data.": 1,
        "Multimodal RAG framework for retrieving concept-level knowledge based on queries from various modalities.": 1,
        "Large Language Model (LLM) reasoning": 1,
        "Retrieval-Augmented Generation (RAG) enhanced by knowledge graph-elicited reasoning": 1,
        "Narration Augmentation: Adding demonstration details and completion criteria to existing narrated instructions.": 1,
        "Retrieval-Augmented Generation (RAG): Extracting relevant non-visual workarounds from BLV-specific resources using RAG.": 1,
        "Camera-based Progress Monitoring: Using a camera embedded in smart glasses to track user progress and provide context-aware instructions and feedback.": 1,
        "User study with BLV participants: Evaluating the system's effectiveness and usability through a user study with 8 BLV participants.": 1,
        "Multimodal Large Language Model (MLLM) based on Qwen2.5-VL": 1,
        "Low-Rank Adaptation (LoRA) for lightweight fine-tuning": 1,
        "Chain-of-Thought (CoT) reasoning": 1,
        "GPT models (specifically GPT-4.1) with retrieval-augmented generation (RAG)": 1,
        "Zero-shot prompting": 1,
        "Bayesian regression": 1,
        "Neural ordinary differential equations": 1,
        "Fast anomaly detector (unspecified in abstract, but provides coarse anomaly scores)": 1,
        "Retrieval Augmented Generation (RAG)-enhanced Vision-Language Model (VLM) for detailed detection and reasoning": 1,
        "Knowledge base construction for domain adaptation of VLMs": 1,
        "Fusion of anomaly confidence scores from fast and slow detectors": 1,
        "Multi-modal retrieval-augmented generation": 1,
        "Zero-shot and fine-tuned configurations of retrieval and vision language models": 1,
        "Analysis of query formulation and retrieval depth optimization": 1,
        "Speech audio transcription using Whisper-v3.": 1,
        "LLM-based grading using zero-shot chain-of-thought prompting.": 1,
        "LLM-based grading using retrieval augmented generation.": 1,
        "LLM-based grading using multi-model ensemble methods.": 1,
        "Evaluation of LLM performance using Cohen's kappa agreement with human graders.": 1
      },
      "reproducibility_score": 0.9166666666666666,
      "open_source_ratio": 0.3,
      "top_companies": [
        "Microsoft",
        "Google",
        "Tsinghua University",
        "Hong Kong University of Science and Technology",
        "University of G\u00f6ttingen"
      ],
      "avg_citation_potential": 0.7
    },
    {
      "topic": "Multi-Agent Reinforcement Learning with memory.",
      "paper_count": 27,
      "methods_distribution": {
        "Differentiable counterfactual alignment penalties computed from soft reference distributions.": 1,
        "Alignment-weighted perceptual attention.": 1,
        "Hebbian associative memory supporting temporal credit assignment.": 1,
        "Similarity-weighted graph diffusion with bias mitigation controls.": 1,
        "Bilevel Optimization": 1,
        "Perturbation of Experience Replay (ER) buffers in MARL agents": 1,
        "Perturbation of Knowledge Bases (K) in RAG-based LLM agents": 1,
        "Multi-Agent Reinforcement Learning": 3,
        "Deep Q-learning": 1,
        "Long Short-Term Memory Networks (LSTM)": 1,
        "Graph Attention Networks (GAT)": 1,
        "Model-free reinforcement learning": 1,
        "Self-play algorithm design": 1,
        "Q-learning": 1,
        "Nash equilibrium finding": 1,
        "Multi-Agent Reinforcement Learning (MARL)": 12,
        "Variational Quantum Circuits (VQCs)": 1,
        "Quantum Approximate Optimization Algorithm (QAOA)": 1,
        "Bayesian Inference": 1,
        "Gaussian Processes": 1,
        "Variational Inference": 1,
        "Centralized Training with Decentralized Execution (CTDE)": 1,
        "Proximal Policy Optimization (PPO) (Baseline)": 1,
        "Deep Deterministic Policy Gradient (DDPG) (Baseline)": 1,
        "Deep Reinforcement Learning": 1,
        "Dialogue-based negotiation protocols": 1,
        "Hierarchical Consensus Network (HCN) - Attention Mechanisms and Graph Neural Networks": 1,
        "Progressive Negotiation Protocol (PNP)": 1,
        "Context-Aware Reward Shaping": 1,
        "MAPPO (Multi-Agent Proximal Policy Optimization)": 1,
        "HAPPO (Hybrid Actor-Policy Proximal Optimization)": 1,
        "HATRPO (Hybrid Actor-Critic Trust Region Policy Optimization)": 1,
        "Simulation using Basilisk and BSK-RL frameworks": 1,
        "Centralized training of an embedding model to capture fine-grained trajectory representations.": 1,
        "Decentralized models that approximate the centralized embedding model to obtain team-level task information.": 1,
        "Decentralized memory retrieval based on learned embeddings to provide context for decision-making.": 1,
        "A hybrid utility score that combines individual and team-level returns for credit assignment.": 1,
        "Deep Q-Network (DQN) with prioritized experience replay, n-step returns, double DQN, and soft target update": 1,
        "Negotiation with an attention mechanism to enhance state representation": 1,
        "Distributed Pose-Graph Optimization (PGO)": 1,
        "Recurrent edge-conditioned Graph Neural Network (GNN) with adaptive edge-gating": 1,
        "Hybrid policy using prior action memory and graph embeddings": 1,
        "Consensus scheme for inter-robot disagreement reconciliation": 1,
        "Amortized policy generator using a compact set of latent anchors.": 1,
        "Unbiased Monte Carlo rollouts for payoff estimation.": 1,
        "Multiplicative-weights meta-dynamics for policy adaptation.": 1,
        "Model-free empirical-Bernstein UCB oracle for adaptive policy set expansion.": 1,
        "Advantage-based trust-region objective for training best responses within the generator.": 1,
        "Multi-agent Reinforcement Learning (RL)": 1,
        "Belief Modelling techniques for AI agents": 1,
        "Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)": 1,
        "Adaptive Agent Grouping": 1,
        "Learnable Identity (ID) Embeddings": 1,
        "Reinforcement Learning": 2,
        "Supervised Pre-training": 1,
        "Self-Play": 1,
        "Potential-based Reward Shaping": 1,
        "Memory Features": 1,
        "World Model": 1,
        "Generative AI": 1,
        "Latent Representation Learning": 1,
        "Ego-centric Learning": 1,
        "Lightweight Communication": 1,
        "Large Language Models (LLMs) for subgoal generation, communication, and memory": 1,
        "Proximal Policy Optimization (PPO) with a language-conditioned loss": 1,
        "LLM query gating": 1,
        "Ablation studies to evaluate the contribution of individual components.": 1,
        "Action-specific Double Deep Recurrent Q-Network (ADDRQN)": 1,
        "Long Short-Term Memory (LSTM)": 1,
        "Partially Observable Markov Game (POMG)": 1,
        "Theoretical analysis of best responses and Nash equilibria.": 1,
        "Empirical validation using sequential decision-making testbeds.": 1,
        "Heterogeneous Multi-Agent Reinforcement Learning (MARL)": 1,
        "Multi-Head Attention Mechanism": 1,
        "Shared Critic Mechanism": 1,
        "State Encoding Technique": 1,
        "Graph Neural Networks (GNNs)": 1,
        "Temporal Attention Mechanism": 1,
        "Dynamic Temporal Graphs": 1,
        "Value Decomposition MARL": 1,
        "Graph-based MARL": 1,
        "Collaborative Reinforcement Learning": 1,
        "Attention Mechanism": 1,
        "Recurrent Neural Network (RNN)": 1,
        "Fluid Antenna System (FAS)": 1,
        "Attention-based adaptive pooling": 1,
        "Theoretical analysis of signal-optimal vector quantization for pooling": 1,
        "Empirical validation on synthetic and real-world datasets": 1,
        "Sequential action rollout using the autoregressive property of the Transformer model to handle varying agent populations.": 1,
        "Sequential value estimation methodology to capture the interdependence of policy distributions and value functions among multiple agents.": 1,
        "Attention-based sequential model": 1,
        "Transformer architecture extended with recurrent memory and a shared memory mechanism for multi-agent settings (SRMT)": 1,
        "Memory pooling and global broadcasting of individual agent memories": 1,
        "Transformer Networks": 1,
        "Expert Networks (inspired by Transfer Learning)": 1,
        "Sequence Modeling": 1,
        "Memory-augmented communication framework": 1
      },
      "reproducibility_score": 0.8148148148148148,
      "open_source_ratio": 0.3,
      "top_companies": [
        "Google",
        "Microsoft",
        "MIT",
        "University of Texas at Austin",
        "Meta"
      ],
      "avg_citation_potential": 0.7
    },
    {
      "topic": "Agentic Computer Vision System for Image Analysis.",
      "paper_count": 2,
      "methods_distribution": {
        "Modeling dog behavior and movement planning from visual input.": 1,
        "Representation learning from the dog modeling task and transfer to other domains.": 1,
        "Reinforced Inter-Agent Learning (RIAL) - Uses deep Q-learning for agent interaction.": 1,
        "Differentiable Inter-Agent Learning (DIAL) - Exploits backpropagation of error derivatives through communication channels during learning.": 1
      },
      "reproducibility_score": 1.0,
      "open_source_ratio": 0.3,
      "top_companies": [
        "Allen Institute for AI",
        "University of Washington",
        "University of Oxford",
        "DeepMind"
      ],
      "avg_citation_potential": 0.7
    }
  ],
  "company_comparisons": [
    {
      "company": "Microsoft",
      "topics_covered": [
        "Retrieval Augmented Generation on Video Data.",
        "Multi-Agent Reinforcement Learning with memory."
      ],
      "paper_count": 10,
      "strengths": [
        "Strong focus on cutting-edge AI techniques, particularly in Retrieval Augmented Generation (RAG) and Multi-Agent Reinforcement Learning (MARL), demonstrating a commitment to advancing these fields.",
        "Emphasis on practical applications and validation through empirical studies on both synthetic and real-world datasets, suggesting a drive to translate research into tangible solutions.",
        "Innovative use of GPT-4 for evaluation, specifically addressing the critical issue of hallucinations in generated responses, showcasing leadership in responsible AI development.",
        "Diverse methodological toolkit, incorporating techniques from natural language processing (NLI), computer vision (multi-view question answering, unified embedding learning), and symbolic reasoning (Neuro-Symbolic Integration), indicating a multi-faceted approach to AI research."
      ],
      "weaknesses": [
        "Limited breadth of topics covered. The focus on only two areas, while demonstrating depth, might indicate a lack of exploration in other potentially relevant AI domains.",
        "The relatively small number of papers (10) could suggest a more focused or nascent research effort compared to companies with broader and more prolific research outputs.",
        "While the methods are diverse, there might be a lack of detail on the specific novel contributions within each method. The description is high-level and doesn't always highlight unique innovations compared to existing literature."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 1
    },
    {
      "company": "Google",
      "topics_covered": [
        "Retrieval Augmented Generation on Video Data.",
        "Multi-Agent Reinforcement Learning with memory."
      ],
      "paper_count": 7,
      "strengths": [
        "Strong focus on cutting-edge AI topics: The research profile demonstrates Google's active involvement in Retrieval Augmented Generation (RAG) for video data and Multi-Agent Reinforcement Learning (MARL), both areas of significant current interest and potential impact.",
        "Diverse methodological toolkit: The company employs a wide array of methods, ranging from empirical validation on diverse datasets to theoretical analysis and advanced techniques like information geometry. This suggests a deep understanding of various approaches to problem-solving.",
        "Integration of theoretical and empirical approaches: The research combines empirical validation with theoretical derivations, indicating a commitment to both practical application and fundamental understanding of the underlying principles.",
        "Focus on Memory and Bias Mitigation: The presence of 'Memory Features' and 'Similarity-weighted graph diffusion with bias mitigation controls' suggests an awareness of important challenges in AI, such as handling long-term dependencies and ensuring fairness."
      ],
      "weaknesses": [
        "Limited scope of topics: The profile only covers two specific topics, which might indicate a narrow focus or incomplete representation of Google's overall research activities. It's difficult to assess the breadth of their research from this limited data.",
        "Unclear connection between methods and topics: While the methods are diverse, the analysis doesn't explicitly show which methods are applied to which topic. This makes it difficult to assess the effectiveness of specific methodological choices.",
        "Small number of papers: Only 7 papers are listed. For a company as large as Google, this seems like a small number and might not be representative of the full scope of their research.",
        "Lack of application domain specification: While 'real-world datasets' are mentioned, more specific details about application domains (e.g., robotics, healthcare, search) are missing. This limits the ability to assess the practical relevance of the research."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 2
    },
    {
      "company": "Tsinghua University",
      "topics_covered": [
        "Retrieval Augmented Generation on Video Data."
      ],
      "paper_count": 2,
      "strengths": [
        "Strong focus on Retrieval Augmented Generation (RAG), indicating expertise in improving language model performance with external knowledge.",
        "Exploration of multimodal (video and language) data, demonstrating capability in handling complex data types.",
        "Utilization of advanced techniques like LoRA and MLLMs (Qwen2.5-VL), suggesting awareness and adoption of cutting-edge technologies.",
        "Application of methods like Hierarchical query decomposition and global statistical distribution of inter-frame scores, showcasing a deep understanding of video processing and retrieval.",
        "Use of Chain-of-Thought reasoning suggests an attempt to improve the explainability and reliability of the models."
      ],
      "weaknesses": [
        "Limited number of publications (2) suggests that this research area may be relatively new or a smaller focus within Tsinghua University.",
        "The profile lacks information on specific datasets used, making it difficult to assess the generalizability and real-world applicability of their research.",
        "Limited information on evaluation metrics and benchmarks makes it hard to compare their results against existing work."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 3
    },
    {
      "company": "Hong Kong University of Science and Technology",
      "topics_covered": [
        "Retrieval Augmented Generation on Video Data."
      ],
      "paper_count": 1,
      "strengths": [
        "Focus on a cutting-edge topic: Retrieval Augmented Generation (RAG) applied to video data is a relatively new and rapidly developing area.",
        "Innovative method: Combining standard search with path-aligned retrieval using lightweight path extraction suggests a creative approach to improving retrieval accuracy and relevance in video content."
      ],
      "weaknesses": [
        "Limited research output: Only one paper on this topic indicates a nascent or limited research effort in this specific area.",
        "Lack of detail: The description of methods is high-level. It's difficult to assess the novelty and effectiveness without more specifics about the path extraction and hybrid retrieval implementation."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 4
    },
    {
      "company": "University of G\u00f6ttingen",
      "topics_covered": [
        "Retrieval Augmented Generation on Video Data."
      ],
      "paper_count": 1,
      "strengths": [
        "Demonstrated expertise in a cutting-edge area: Retrieval Augmented Generation (RAG) applied to video data, a relatively novel and challenging domain.",
        "Integration of multiple advanced techniques: Combining Large Language Models (LLMs), ensemble changepoint detection, and RAG indicates a sophisticated approach to problem-solving.",
        "Focus on explanation generation: The research aims to provide understandable explanations, increasing the practical utility of video analysis."
      ],
      "weaknesses": [
        "Limited research output: Only one paper limits the breadth and depth of the company's research profile. It's difficult to assess the consistency and long-term focus.",
        "Lack of information on dataset specifics: The analysis doesn't provide details on the type of video data used, potentially limiting the generalizability of the findings."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 5
    },
    {
      "company": "MIT",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning with memory."
      ],
      "paper_count": 2,
      "strengths": [
        "Strong focus on cutting-edge research in Multi-Agent Reinforcement Learning (MARL), a complex and rapidly evolving field.",
        "Exploration of advanced techniques like Recurrent Graph Neural Networks (GNNs) and memory-augmented policies for improved coordination and decision-making in multi-agent systems.",
        "Integration of diverse methodologies, including distributed optimization (PGO), consensus schemes, and perturbation techniques, indicating a holistic approach to problem-solving in MARL.",
        "Consideration of both exploration (Perturbation of ER) and knowledge integration (Perturbation of Knowledge Bases in RAG-based LLM agents, although this seems slightly out of context given the title)."
      ],
      "weaknesses": [
        "Limited number of publications (2) on the specified topic raises concerns about the depth and breadth of the research.",
        "While the methods are advanced, the analysis lacks information on the specific problem domains or applications being targeted. The inclusion of LLM techniques alongside robotics-focused methods suggests a potential lack of focus or potentially a new research direction being explored.",
        "The provided data doesn't indicate whether the research is theoretical or applied, hindering assessment of its practical impact."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 6
    },
    {
      "company": "University of Texas at Austin",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning with memory."
      ],
      "paper_count": 2,
      "strengths": [
        "Strong focus on Multi-Agent Reinforcement Learning (MARL), a rapidly growing field with significant potential in robotics, autonomous systems, and distributed control.",
        "Integration of advanced techniques like Graph Neural Networks (GNNs), Recurrent Networks, and Bilevel Optimization suggests a deep understanding of state-of-the-art machine learning methods.",
        "Exploration of memory-augmented MARL strategies (prior action memory, experience replay perturbation) indicates an interest in improving learning stability and performance in complex environments.",
        "Application of Distributed Pose-Graph Optimization (PGO) and consensus schemes demonstrates a practical focus on real-world multi-robot coordination challenges."
      ],
      "weaknesses": [
        "Limited number of publications (only 2) suggests a relatively small research group or a nascent research area within the university.",
        "The listed methods appear somewhat disparate, with 'Perturbation of Knowledge Bases (K) in RAG-based LLM agents' seemingly unrelated to the main focus on MARL, indicating a potential lack of focus or a very broad research scope.",
        "Lack of information on specific applications or experimental results makes it difficult to assess the practical impact and validation of the proposed methods."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 7
    },
    {
      "company": "Meta",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning with memory."
      ],
      "paper_count": 2,
      "strengths": [
        "Focus on integrating Large Language Models (LLMs) into Multi-Agent Reinforcement Learning (MARL) showcases an effort to leverage cutting-edge AI advancements for complex tasks.",
        "The combination of PPO with language conditioning and memory indicates a sophisticated approach to improving agent learning and coordination in dynamic environments.",
        "Emphasis on both empirical validation (synthetic and real-world datasets) and theoretical analysis (signal-optimal vector quantization) suggests a commitment to rigorous research and practical applicability."
      ],
      "weaknesses": [
        "Limited number of publications (only 2) suggests a relatively narrow or nascent research focus within the broader MARL field.",
        "Reliance on LLMs might introduce vulnerabilities related to bias, robustness, and computational cost, which need to be carefully addressed.",
        "The analysis doesn't provide information on the novelty of the specific LLM integration techniques; if the application is straightforward, the impact might be limited."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 8
    },
    {
      "company": "Allen Institute for AI",
      "topics_covered": [
        "Agentic Computer Vision System for Image Analysis."
      ],
      "paper_count": 1,
      "strengths": [
        "Focus on agentic computer vision, a cutting-edge area integrating vision with AI agents.",
        "Exploration of representation learning, enabling knowledge transfer to other domains, potentially leading to broader applicability of the research."
      ],
      "weaknesses": [
        "Extremely limited research profile based on only one paper, making it difficult to assess overall capabilities and impact.",
        "The specific application (dog behavior modeling) might be niche, although the underlying methods could be more general."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 9
    },
    {
      "company": "University of Washington",
      "topics_covered": [
        "Agentic Computer Vision System for Image Analysis."
      ],
      "paper_count": 1,
      "strengths": [
        "Focus on cutting-edge research: The topic 'Agentic Computer Vision System' suggests a focus on advanced AI and computer vision, indicating potential for innovative solutions.",
        "Interdisciplinary approach: Combining computer vision with animal behavior (dog modeling) demonstrates an interdisciplinary approach that can lead to novel insights and applications."
      ],
      "weaknesses": [
        "Limited research output: Only one paper indicates a potentially narrow research scope or early stage of development in this specific area.",
        "Lack of detail: The provided information is high-level and lacks specific details about the system architecture, algorithms used, and evaluation metrics. This makes it difficult to assess the true potential and impact of the research."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 10
    },
    {
      "company": "University of Oxford",
      "topics_covered": [
        "Agentic Computer Vision System for Image Analysis."
      ],
      "paper_count": 1,
      "strengths": [
        "Focus on cutting-edge AI techniques: The research leverages advanced methods like Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL), indicating a commitment to exploring state-of-the-art approaches.",
        "Application of multi-agent learning to computer vision: The application of multi-agent learning to image analysis is a novel approach that could lead to more robust and adaptable vision systems."
      ],
      "weaknesses": [
        "Limited scope: The research profile is extremely narrow, focusing on a single topic and a single paper. This makes it difficult to assess the overall strength and breadth of the university's computer vision research.",
        "Lack of contextual information: Without more information about the specific image analysis tasks and datasets used, it's difficult to evaluate the practical significance and impact of the research."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 11
    },
    {
      "company": "DeepMind",
      "topics_covered": [
        "Agentic Computer Vision System for Image Analysis."
      ],
      "paper_count": 1,
      "strengths": [
        "Focus on multi-agent systems for complex tasks, demonstrating an interest in advanced AI.",
        "Exploration of both discrete (RIAL) and continuous (DIAL) communication methods, showcasing a versatile approach to agent interaction."
      ],
      "weaknesses": [
        "Limited research breadth indicated by the single paper and narrow topic coverage.",
        "Lack of information on real-world applications or validation; it's unclear if the system is practical beyond simulated environments."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 12
    }
  ],
  "papers": {
    "Retrieval Augmented Generation on Video Data.": [
      {
        "title": "Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data",
        "authors": [
          "Zhen Chen",
          "Weihao Xie",
          "Peilin Chen",
          "Shiqi Wang",
          "Jianping Wang"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.",
        "published": "2026-01-08T09:32:01+00:00",
        "url": "http://arxiv.org/abs/2601.04764v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "The paper introduces Orion-RAG, a novel Retrieval-Augmented Generation (RAG) approach designed for fragmented, graphless data environments. It focuses on extracting lightweight paths to link related concepts across isolated files, avoiding the need for manual Knowledge Graph construction.",
        "contributions": [
          "A novel RAG approach (Orion-RAG) for handling fragmented data without explicit links.",
          "A lightweight path extraction strategy to transform fragmented documents into semi-structured data."
        ],
        "methods": [
          "Lightweight path extraction to link related concepts.",
          "Hybrid retrieval combining standard search with path-aligned retrieval."
        ],
        "datasets": [
          "FinanceBench"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations. More information is needed from the full paper.",
          "The abstract does not explicitly state limitations. More information is needed from the full paper."
        ],
        "companies": [
          "Hong Kong University of Science and Technology"
        ]
      },
      {
        "title": "LLM-Augmented Changepoint Detection: A Framework for Ensemble Detection and Automated Explanation",
        "authors": [
          "Fabian Lukassen",
          "Christoph Weisser",
          "Michael Schlee",
          "Manish Kumar",
          "Anton Thielmann",
          "Benjamin Saefken",
          "Thomas Kneib"
        ],
        "affiliations": [],
        "abstract": "This paper introduces a novel changepoint detection framework that combines ensemble statistical methods with Large Language Models (LLMs) to enhance both detection accuracy and the interpretability of regime changes in time series data. Two critical limitations in the field are addressed. First, individual detection methods exhibit complementary strengths and weaknesses depending on data characteristics, making method selection non-trivial and prone to suboptimal results. Second, automated, contextual explanations for detected changes are largely absent. The proposed ensemble method aggregates results from ten distinct changepoint detection algorithms, achieving superior performance and robustness compared to individual methods. Additionally, an LLM-powered explanation pipeline automatically generates contextual narratives, linking detected changepoints to potential real-world historical events. For private or domain-specific data, a Retrieval-Augmented Generation (RAG) solution enables explanations grounded in user-provided documents. The open source Python framework demonstrates practical utility in diverse domains, including finance, political science, and environmental science, transforming raw statistical output into actionable insights for analysts and decision-makers.",
        "published": "2026-01-06T12:04:38+00:00",
        "url": "http://arxiv.org/abs/2601.02957v1",
        "categories": [
          "cs.CL"
        ],
        "summary": "This paper introduces an LLM-augmented changepoint detection framework that combines ensemble statistical methods with Large Language Models (LLMs). The framework improves both the accuracy of detecting regime changes in time series data and provides automated, contextual explanations for these changes.",
        "contributions": [
          "Development of an ensemble changepoint detection method that aggregates results from ten distinct algorithms, achieving superior performance and robustness.",
          "Creation of an LLM-powered explanation pipeline to automatically generate contextual narratives linking detected changepoints to potential real-world events, including a RAG solution for private data."
        ],
        "methods": [
          "Ensemble changepoint detection (aggregation of ten distinct algorithms)",
          "Large Language Models (LLMs) for explanation generation",
          "Retrieval-Augmented Generation (RAG) for domain-specific explanations"
        ],
        "datasets": [
          "Finance data",
          "Political science data",
          "Environmental science data"
        ],
        "limitations": [
          "Individual detection methods have complementary strengths and weaknesses, making method selection challenging.",
          "Automated, contextual explanations for detected changes are largely absent in existing approaches."
        ],
        "companies": [
          "University of G\u00f6ttingen"
        ]
      },
      {
        "title": "FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation",
        "authors": [
          "Gen Li",
          "Peiyu Liu"
        ],
        "affiliations": [],
        "abstract": "Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.",
        "published": "2026-01-04T12:46:35+00:00",
        "url": "http://arxiv.org/abs/2601.01513v2",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "summary": "The paper introduces VideoSpeculateRAG, a novel Retrieval-Augmented Generation (RAG) framework for Video Question Answering (Video QA) that aims to improve efficiency and accuracy. It combines speculative decoding with a similarity-based filtering strategy to enhance the integration of external knowledge into Vision-Language Models (VLMs).",
        "contributions": [
          "Introduction of a speculative decoding pipeline for faster inference in VLM-based RAG, where a lightweight model generates answer candidates and a heavyweight model verifies and refines them.",
          "Development of a similarity-based filtering strategy to improve entity alignment between the query and retrieved knowledge, leading to higher answer accuracy."
        ],
        "methods": [
          "Retrieval-Augmented Generation (RAG)",
          "Speculative Decoding",
          "Similarity-based Filtering"
        ],
        "datasets": [],
        "limitations": [
          "The abstract does not explicitly mention any limitations, but it implies that current RAG methods are inefficient and struggle with maintaining high answer quality, suggesting the need for further improvements in these areas.",
          "The abstract focuses on improving efficiency and accuracy, it doesn't discuss limitations related to the types of questions the model can answer or the complexity of the video content it can process."
        ],
        "companies": [
          "Microsoft"
        ]
      },
      {
        "title": "NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI",
        "authors": [
          "Midhat Urooj",
          "Ayan Banerjee",
          "Sandeep Gupta"
        ],
        "affiliations": [],
        "abstract": "Accurate yet interpretable image-based diagnosis remains a central challenge in medical AI, particularly in settings characterized by limited data, subtle visual cues, and high-stakes clinical decision-making. Most existing vision models rely on purely data-driven learning and produce black-box predictions with limited interpretability and poor cross-domain generalization, hindering their real-world clinical adoption. We present NEURO-GUARD, a novel knowledge-guided vision framework that integrates Vision Transformers (ViTs) with language-driven reasoning to improve performance, transparency, and domain robustness. NEURO-GUARD employs a retrieval-augmented generation (RAG) mechanism for self-verification, in which a large language model (LLM) iteratively generates, evaluates, and refines feature-extraction code for medical images. By grounding this process in clinical guidelines and expert knowledge, the framework progressively enhances feature detection and classification beyond purely data-driven baselines. Extensive experiments on diabetic retinopathy classification across four benchmark datasets APTOS, EyePACS, Messidor-1, and Messidor-2 demonstrate that NEURO-GUARD improves accuracy by 6.2% over a ViT-only baseline (84.69% vs. 78.4%) and achieves a 5% gain in domain generalization. Additional evaluations on MRI-based seizure detection further confirm its cross-domain robustness, consistently outperforming existing methods.\n  Overall, NEURO-GUARD bridges symbolic medical reasoning with subsymbolic visual learning, enabling interpretable, knowledge-aware, and generalizable medical image diagnosis while achieving state-of-the-art performance across multiple datasets.",
        "published": "2025-12-20T02:32:15+00:00",
        "url": "http://arxiv.org/abs/2512.18177v1",
        "categories": [
          "cs.AI",
          "cs.CV"
        ],
        "summary": "The paper introduces NEURO-GUARD, a novel knowledge-guided vision framework that integrates Vision Transformers (ViTs) with language-driven reasoning for improved medical image diagnosis. It enhances performance, transparency, and domain robustness by using a retrieval-augmented generation (RAG) mechanism with a large language model (LLM) to refine feature extraction based on clinical knowledge.",
        "contributions": [
          "A novel knowledge-guided vision framework (NEURO-GUARD) that combines Vision Transformers with language-driven reasoning for medical image analysis.",
          "Improved accuracy, interpretability, and domain generalization in medical image diagnosis through a retrieval-augmented generation (RAG) mechanism using an LLM grounded in clinical knowledge."
        ],
        "methods": [
          "Vision Transformers (ViTs)",
          "Retrieval-Augmented Generation (RAG) with a Large Language Model (LLM)",
          "Neuro-Symbolic Integration (combining symbolic medical reasoning with subsymbolic visual learning)"
        ],
        "datasets": [
          "APTOS (Diabetic Retinopathy)",
          "EyePACS (Diabetic Retinopathy)",
          "Messidor-1 (Diabetic Retinopathy)",
          "Messidor-2 (Diabetic Retinopathy)",
          "MRI-based seizure detection dataset"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations, so they are unknown. Further investigation of the full paper is needed.",
          "Scalability and computational cost associated with LLM integration and RAG are not mentioned in the abstract, but could be potential limitations."
        ],
        "companies": [
          "Microsoft",
          "University of California, Los Angeles"
        ]
      },
      {
        "title": "The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems",
        "authors": [
          "Debu Sinha"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. While current detection methods leverage embedding similarity and natural language inference (NLI), their reliability in safety-critical settings remains unproven. We apply conformal prediction to RAG hallucination detection, transforming heuristic scores into decision sets with finite-sample coverage guarantees (1-alpha). Using calibration sets of n=600, we demonstrate a fundamental dichotomy: on synthetic hallucinations (Natural Questions), embedding methods achieve 95% coverage with 0% False Positive Rate (FPR). However, on real hallucinations from RLHF-aligned models (HaluEval), the same methods fail catastrophically, yielding 100% FPR at target coverage. We analyze this failure through the lens of distributional tails, showing that while NLI models achieve acceptable AUC (0.81), the \"hardest\" hallucinations are semantically indistinguishable from faithful responses, forcing conformal thresholds to reject nearly all valid outputs. Crucially, GPT-4 as a judge achieves 7% FPR (95% CI:[3.4%, 13.7%]) on the same data, proving the task is solvable via reasoning but opaque to surface-level semantics--a phenomenon we term the \"Semantic Illusion.\"",
        "published": "2025-12-17T04:22:28+00:00",
        "url": "http://arxiv.org/abs/2512.15068v2",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "summary": "This paper investigates the limitations of embedding-based and NLI-based hallucination detection methods in Retrieval-Augmented Generation (RAG) systems using conformal prediction. It demonstrates that while these methods perform well on synthetic hallucinations, they fail drastically on real hallucinations from RLHF-aligned models due to the semantic indistinguishability between faithful and hallucinated responses, termed the 'Semantic Illusion'.",
        "contributions": [
          "Demonstrates the catastrophic failure of embedding-based and NLI-based hallucination detection methods on real-world hallucinations in RAG systems, even with conformal prediction for coverage guarantees.",
          "Identifies the 'Semantic Illusion' as a key challenge: real hallucinations can be semantically indistinguishable from faithful responses, rendering surface-level similarity measures ineffective.",
          "Shows that GPT-4, as a judge, can detect these hallucinations, suggesting the necessity of reasoning-based approaches beyond simple semantic similarity.",
          "Uses conformal prediction to provide finite-sample coverage guarantees for hallucination detection, allowing for a rigorous evaluation of existing methods."
        ],
        "methods": [
          "Conformal Prediction: Transforming heuristic scores (from embedding similarity and NLI) into decision sets with finite-sample coverage guarantees.",
          "Embedding Similarity: Using embedding similarity between retrieved context and generated response for hallucination detection.",
          "Natural Language Inference (NLI): Using NLI models to determine if the generated response is supported by the retrieved context.",
          "GPT-4 as a Judge: Utilizing GPT-4 to evaluate the presence of hallucinations in the generated responses."
        ],
        "datasets": [
          "Natural Questions: Used to generate synthetic hallucinations.",
          "HaluEval: A dataset containing real-world hallucinations from RLHF-aligned models."
        ],
        "limitations": [
          "The size of the calibration sets used for conformal prediction (n=600) might be limited in representing the full complexity of real-world hallucination scenarios.",
          "The analysis is limited to specific embedding-based and NLI-based methods. Other hallucination detection techniques might offer different performance characteristics."
        ],
        "companies": [
          "Microsoft"
        ]
      },
      {
        "title": "Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse",
        "authors": [
          "Jingwei Chen"
        ],
        "affiliations": [],
        "abstract": "Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.",
        "published": "2025-12-16T19:50:03+00:00",
        "url": "http://arxiv.org/abs/2512.14879v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "This paper introduces Entropy-Reservoir Bregman Projection (ERBP), a unified information-geometric framework to explain and address model collapse in self-referential learning. ERBP models the learning process as a stochastic Bregman projection sequence, demonstrating that entropy decay due to finite-sample noise leads to collapse and that injecting an Entropy Reservoir can stabilize the dynamics.",
        "contributions": [
          "A novel information-geometric framework (ERBP) that unifies model collapse phenomena in self-referential learning.",
          "Theoretical analysis providing necessary and sufficient conditions for collapse and stabilization, including closed-form rates for entropy decay and stabilization.",
          "Demonstration that various ad hoc stabilization heuristics can be interpreted as specific reservoir choices and coupling coefficients within the ERBP framework.",
          "A quantitative design rule for preventing model collapse: monitor and budget entropy flux."
        ],
        "methods": [
          "Information-geometric analysis using Bregman projections in distribution space.",
          "Stochastic modeling of the self-referential learning loop.",
          "Theoretical derivation of conditions for entropy decay and stabilization.",
          "Empirical validation of theoretical predictions through experiments on large language models, reinforcement learning (Soft Actor-Critic), and GANs."
        ],
        "datasets": [
          "Data generated by large language models during self-training.",
          "Data generated by Soft Actor-Critic in reinforcement learning environments.",
          "Data used for GAN optimization (unspecified in the abstract)."
        ],
        "limitations": [
          "The abstract doesn't explicitly state limitations. However, the complexity of the theoretical framework might pose challenges for practical implementation and hyperparameter tuning.",
          "The abstract doesn't specify the precise datasets used in the GAN experiments, limiting the understanding of the generalizability of the findings."
        ],
        "companies": [
          "Google"
        ]
      },
      {
        "title": "Breast-Rehab: A Postoperative Breast Cancer Rehabilitation Training Assessment System Based on Human Action Recognition",
        "authors": [
          "Zikang Chen",
          "Tan Xie",
          "Qinchuan Wang",
          "Heming Zheng",
          "Xudong Lu"
        ],
        "affiliations": [],
        "abstract": "Postoperative upper limb dysfunction is prevalent among breast cancer survivors, yet their adherence to at-home rehabilitation exercises is low amidst limited nursing resources. The hardware overhead of commonly adopted VR-based mHealth solutions further hinders their widespread clinical application. Therefore, we developed Breast-Rehab, a novel, low-cost mHealth system to provide patients with out-of-hospital upper limb rehabilitation management. Breast-Rehab integrates a bespoke human action recognition algorithm with a retrieval-augmented generation (RAG) framework. By fusing visual and 3D skeletal data, our model accurately segments exercise videos recorded in uncontrolled home environments, outperforming standard models. These segmented clips, combined with a domain-specific knowledge base, guide a multi-modal large language model to generate clinically relevant assessment reports. This approach significantly reduces computational overhead and mitigates model hallucinations. We implemented the system as a WeChat Mini Program and a nurse-facing dashboard. A preliminary clinical study validated the system's feasibility and user acceptance, with patients achieving an average exercise frequency of 0.59 sessions/day over a two-week period. This work thus presents a complete, validated pipeline for AI-driven, at-home rehabilitation monitoring.",
        "published": "2025-12-12T03:06:03+00:00",
        "url": "http://arxiv.org/abs/2512.11245v1",
        "categories": [
          "cs.HC"
        ],
        "summary": "The paper introduces Breast-Rehab, a low-cost mHealth system for at-home breast cancer rehabilitation. It uses human action recognition and a retrieval-augmented generation (RAG) framework to assess patient exercises and provide feedback, addressing the issue of low adherence to at-home rehabilitation. ",
        "contributions": [
          "Developed Breast-Rehab, a novel, low-cost mHealth system for postoperative breast cancer rehabilitation.",
          "Integrated a bespoke human action recognition algorithm with a retrieval-augmented generation (RAG) framework for accurate exercise assessment and report generation.",
          "Validated the system's feasibility and user acceptance through a preliminary clinical study."
        ],
        "methods": [
          "Human action recognition algorithm fusing visual and 3D skeletal data for exercise video segmentation.",
          "Retrieval-augmented generation (RAG) framework for generating clinically relevant assessment reports using a domain-specific knowledge base and a multi-modal large language model."
        ],
        "datasets": [
          "Exercise videos recorded in uncontrolled home environments (used for training and testing the action recognition algorithm)."
        ],
        "limitations": [
          "Limited information on the specific datasets used for training the models (e.g., size, source, characteristics).",
          "The clinical study was preliminary, suggesting the need for larger and more comprehensive trials to fully evaluate the system's effectiveness."
        ],
        "companies": [
          "University",
          "Hospital",
          "Research Institute"
        ]
      },
      {
        "title": "SoDA: An Efficient Interaction Paradigm for the Agentic Web",
        "authors": [
          "Zicai Cui",
          "Zhouyuan Jian",
          "Weiwen Liu",
          "Weinan Zhang"
        ],
        "affiliations": [],
        "abstract": "As the internet evolves from the mobile App-dominated Attention Economy to the Intent-Interconnection of the Agentic Web era, existing interaction modes fail to address the escalating challenges of data lock-in and cognitive overload. Addressing this, we defines a future-oriented user sovereignty interaction paradigm, aiming to realize a fundamental shift from killing time to saving time. Specifically, we argue that decoupling memory from application logic eliminates the structural basis of data lock-in, while shifting from explicit manual instruction to implicit intent alignment resolves cognitive overload by offloading execution complexity. This paradigm is implemented via the Sovereign Digital Avatar (SoDA), which employs an orthogonal decoupling design of storage, computation, and interaction. This establishes the architectural principle of data as a persistent asset, model as a transient tool, fundamentally breaking the platform monopoly on user memory. To support the operation of this new paradigm in zero-trust environments, we design an Intent-Permission Handshake Mechanism based on A2A protocols, utilizing dual-factor (Sensitivity Coefficient and Strictness Parameter) adaptive routing to achieve active risk governance. Empirical evaluation with a high-fidelity simulation environment indicates that this paradigm reduces token consumption by approximately 27-35\\% during cross-platform service migration and complex task execution. Furthermore, in the orchestration of multi-modal complex tasks, it reduces user cognitive load by 72\\% compared to standard Retrieval-Augmented Generation (RAG) architectures, by 88\\% relative to manual workflows, while significantly boosting the Information Signal-to-Noise Ratio (SNR). These results demonstrate that the SoDA is the essential interaction infrastructure for building an efficient, low-friction, and decentralized Agentic Web.",
        "published": "2025-12-11T00:44:08+00:00",
        "url": "http://arxiv.org/abs/2512.22135v1",
        "categories": [
          "cs.DC",
          "cs.AI",
          "cs.HC",
          "cs.MA"
        ],
        "summary": "This paper introduces SoDA, a novel interaction paradigm for the Agentic Web designed to address data lock-in and cognitive overload. SoDA employs a Sovereign Digital Avatar with an orthogonal decoupling design and an Intent-Permission Handshake Mechanism to enable efficient, decentralized interactions.",
        "contributions": [
          "Defines a user sovereignty interaction paradigm for the Agentic Web that decouples memory from application logic to eliminate data lock-in and shifts from explicit instruction to implicit intent alignment to reduce cognitive overload.",
          "Introduces the Sovereign Digital Avatar (SoDA) architecture, featuring orthogonal decoupling of storage, computation, and interaction, treating data as a persistent asset and models as transient tools.",
          "Proposes an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.",
          "Empirically demonstrates through high-fidelity simulation that SoDA reduces token consumption, cognitive load, and boosts the Information Signal-to-Noise Ratio (SNR) compared to existing methods like RAG and manual workflows."
        ],
        "methods": [
          "Orthogonal Decoupling Design of Storage, Computation, and Interaction for the Sovereign Digital Avatar (SoDA)",
          "Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor (Sensitivity Coefficient and Strictness Parameter) adaptive routing.",
          "High-fidelity simulation environment for empirical evaluation."
        ],
        "datasets": [
          "Not explicitly mentioned in the abstract. Implied use of simulation data."
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations. Possible limitations could include the reliance on a simulation environment for evaluation and the potential complexities of implementing the Intent-Permission Handshake Mechanism in real-world scenarios.",
          "The abstract does not provide details about scalability of the approach."
        ],
        "companies": [
          "Microsoft",
          "Shanghai Jiao Tong University"
        ]
      },
      {
        "title": "How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?",
        "authors": [
          "Tomohiro Yamashita",
          "Daichi Amagata",
          "Yusuke Matsui"
        ],
        "affiliations": [],
        "abstract": "Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.",
        "published": "2025-12-05T22:53:45+00:00",
        "url": "http://arxiv.org/abs/2512.06200v1",
        "categories": [
          "cs.LG"
        ],
        "summary": "This research addresses the lack of a standardized evaluation methodology for data deletion in Approximate Nearest Neighbor Search (ANNS) indexes. It proposes an experimental framework and metrics to comprehensively assess data deletion efficiency in graph-based ANNS, focusing on accuracy, query speed, and other relevant factors.",
        "contributions": [
          "Proposes a comprehensive experimental framework and evaluation metrics for data deletion in graph-based ANNS indexes, categorizing deletion methods into three approaches and formalizing them mathematically.",
          "Introduces 'Deletion Control', a method that dynamically selects the appropriate deletion method based on required search accuracy, demonstrated using Hierarchical Navigable Small World (HNSW)."
        ],
        "methods": [
          "Categorization and formalization of data deletion methods in graph-based ANNS.",
          "Experimental evaluation using accuracy, query speed, and other relevant metrics.",
          "Application of the framework to HNSW and introduction of Deletion Control."
        ],
        "datasets": [
          "Not specified in the abstract. Further reading of the paper is required to determine which datasets were used."
        ],
        "limitations": [
          "The abstract does not explicitly state any limitations. Further reading of the paper is required to identify any acknowledged limitations.",
          "The evaluation is demonstrated on a single state-of-the-art ANNS method (HNSW), which may not generalize to all graph-based ANNS indexes."
        ],
        "companies": [
          "Yahoo! JAPAN"
        ]
      },
      {
        "title": "ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering",
        "authors": [
          "Daeyong Kwon",
          "SeungHeon Doh",
          "Juhan Nam"
        ],
        "affiliations": [],
        "abstract": "Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.",
        "published": "2025-12-05T05:09:30+00:00",
        "url": "http://arxiv.org/abs/2512.05430v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.IR",
          "cs.LG"
        ],
        "summary": "The paper introduces ArtistMus, a new benchmark for retrieval-augmented music question answering, and MusWikiDB, a music-specific vector database derived from Wikipedia. They demonstrate that retrieval-augmented generation (RAG) significantly improves the factual accuracy of music-related question answering using large language models (LLMs).",
        "contributions": [
          "Creation of ArtistMus, a benchmark dataset of 1,000 questions covering 500 diverse artists, designed for evaluating music question answering.",
          "Development of MusWikiDB, a vector database of 3.2M passages extracted from music-related Wikipedia pages, tailored for retrieval-augmented generation."
        ],
        "methods": [
          "Retrieval-Augmented Generation (RAG): Employing a retrieval component to fetch relevant information from MusWikiDB before generating answers using LLMs.",
          "Fine-tuning: Fine-tuning LLMs using the ArtistMus dataset to further improve performance on music question answering."
        ],
        "datasets": [
          "ArtistMus: A benchmark dataset of 1,000 questions on 500 diverse artists with metadata.",
          "MusWikiDB: A vector database of 3.2M passages from 144K music-related Wikipedia pages."
        ],
        "limitations": [
          "The abstract does not explicitly state limitations. However, it is implied that the dataset focuses on information present in Wikipedia, which may not cover all aspects of music knowledge or less well-known artists.",
          "While RAG improves performance, there is still a gap between open-source models and proprietary models, suggesting room for further improvement."
        ],
        "companies": [
          "KAIST"
        ]
      },
      {
        "title": "Caption Injection for Optimization in Generative Search Engine",
        "authors": [
          "Xiaolu Chen",
          "Yong Liao"
        ],
        "affiliations": [],
        "abstract": "Generative Search Engines (GSEs) leverage Retrieval-Augmented Generation (RAG) techniques and Large Language Models (LLMs) to integrate multi-source information and provide users with accurate and comprehensive responses. Unlike traditional search engines that present results in ranked lists, GSEs shift users' attention from sequential browsing to content-driven subjective perception, driving a paradigm shift in information retrieval. In this context, enhancing the subjective visibility of content through Generative Search Engine Optimization (G-SEO) methods has emerged as a new research focus. With the rapid advancement of Multimodal Retrieval-Augmented Generation (MRAG) techniques, GSEs can now efficiently integrate text, images, audio, and video, producing richer responses that better satisfy complex information needs. Existing G-SEO methods, however, remain limited to text-based optimization and fail to fully exploit multimodal data. To address this gap, we propose Caption Injection, the first multimodal G-SEO approach, which extracts captions from images and injects them into textual content, integrating visual semantics to enhance the subjective visibility of content in generative search scenarios. We systematically evaluate Caption Injection on MRAMG, a benchmark for MRAG, under both unimodal and multimodal settings. Experimental results show that Caption Injection significantly outperforms text-only G-SEO baselines under the G-Eval metric, demonstrating the necessity and effectiveness of multimodal integration in G-SEO to improve user-perceived content visibility.",
        "published": "2025-11-06T05:37:27+00:00",
        "url": "http://arxiv.org/abs/2511.04080v1",
        "categories": [
          "cs.IR"
        ],
        "summary": "This paper introduces Caption Injection, a novel multimodal Generative Search Engine Optimization (G-SEO) approach that enhances content visibility in generative search engines by injecting image captions into textual content. It addresses the gap in existing G-SEO methods that are limited to text-based optimization and fail to fully exploit multimodal data.",
        "contributions": [
          "Proposes Caption Injection, the first multimodal G-SEO approach to integrate visual semantics for improved content visibility.",
          "Demonstrates the effectiveness of multimodal integration in G-SEO through empirical evaluation, showing significant outperformance compared to text-only G-SEO baselines."
        ],
        "methods": [
          "Caption Injection (extracting captions from images and injecting them into textual content)",
          "Evaluation using the G-Eval metric to assess user-perceived content visibility"
        ],
        "datasets": [
          "MRAMG (a benchmark for Multimodal Retrieval-Augmented Generation)"
        ],
        "limitations": [
          "The abstract doesn't explicitly mention limitations, so this would require further investigation of the full paper.",
          "The abstract does not address scalability or computational cost of Caption Injection. "
        ],
        "companies": [
          "Google",
          "Microsoft",
          "Baidu"
        ]
      },
      {
        "title": "Structured Interfaces for Automated Reasoning with 3D Scene Graphs",
        "authors": [
          "Aaron Ray",
          "Jacob Arkin",
          "Harel Biggie",
          "Chuchu Fan",
          "Luca Carlone",
          "Nicholas Roy"
        ],
        "affiliations": [],
        "abstract": "In order to provide a robot with the ability to understand and react to a user's natural language inputs, the natural language must be connected to the robot's underlying representations of the world. Recently, large language models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for grounding natural language and representing the world. In this work, we address the challenge of using LLMs with 3DSGs to ground natural language. Existing methods encode the scene graph as serialized text within the LLM's context window, but this encoding does not scale to large or rich 3DSGs. Instead, we propose to use a form of Retrieval Augmented Generation to select a subset of the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide a query language interface (Cypher) as a tool to the LLM with which it can retrieve relevant data for language grounding. We evaluate our approach on instruction following and scene question-answering tasks and compare against baseline context window and code generation methods. Our results show that using Cypher as an interface to 3D scene graphs scales significantly better to large, rich graphs on both local and cloud-based models. This leads to large performance improvements in grounded language tasks while also substantially reducing the token count of the scene graph content. A video supplement is available at https://www.youtube.com/watch?v=zY_YI9giZSA.",
        "published": "2025-10-18T21:19:13+00:00",
        "url": "http://arxiv.org/abs/2510.16643v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "summary": "This paper addresses the challenge of using Large Language Models (LLMs) with 3D Scene Graphs (3DSGs) for grounding natural language, particularly for large and rich graphs. They propose a Retrieval Augmented Generation approach using a graph database and Cypher query language to enable LLMs to retrieve relevant 3DSG data, improving performance and scalability.",
        "contributions": [
          "A novel approach to grounding natural language using LLMs and 3DSGs that scales to large, rich graphs using Retrieval Augmented Generation.",
          "The use of a graph database and Cypher query language as an interface for LLMs to interact with and retrieve information from 3DSGs."
        ],
        "methods": [
          "Retrieval Augmented Generation (RAG)",
          "Graph database for storing and querying 3D scene graphs",
          "Cypher query language as an interface for LLMs to access the graph database",
          "Comparison with baseline context window and code generation methods."
        ],
        "datasets": [
          "Instruction following tasks",
          "Scene question-answering tasks"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations, but the performance is compared to other methods, implying those methods may have areas where they outperform the proposed approach.",
          "The abstract does not specify the particular 3DSG datasets used, which makes it difficult to assess the generalizability of the results."
        ],
        "companies": [
          "MIT",
          "Boston University"
        ]
      },
      {
        "title": "RankArena: A Unified Platform for Evaluating Retrieval, Reranking and RAG with Human and LLM Feedback",
        "authors": [
          "Abdelrahman Abdallah",
          "Mahmoud Abdalla",
          "Bhawna Piryani",
          "Jamshid Mozafari",
          "Mohammed Ali",
          "Adam Jatowt"
        ],
        "affiliations": [],
        "abstract": "Evaluating the quality of retrieval-augmented generation (RAG) and document reranking systems remains challenging due to the lack of scalable, user-centric, and multi-perspective evaluation tools. We introduce RankArena, a unified platform for comparing and analysing the performance of retrieval pipelines, rerankers, and RAG systems using structured human and LLM-based feedback as well as for collecting such feedback. RankArena supports multiple evaluation modes: direct reranking visualisation, blind pairwise comparisons with human or LLM voting, supervised manual document annotation, and end-to-end RAG answer quality assessment. It captures fine-grained relevance feedback through both pairwise preferences and full-list annotations, along with auxiliary metadata such as movement metrics, annotation time, and quality ratings. The platform also integrates LLM-as-a-judge evaluation, enabling comparison between model-generated rankings and human ground truth annotations. All interactions are stored as structured evaluation datasets that can be used to train rerankers, reward models, judgment agents, or retrieval strategy selectors. Our platform is publicly available at https://rankarena.ngrok.io/, and the Demo video is provided https://youtu.be/jIYAP4PaSSI.",
        "published": "2025-08-07T15:46:53+00:00",
        "url": "http://arxiv.org/abs/2508.05512v1",
        "categories": [
          "cs.IR"
        ],
        "summary": "The paper introduces RankArena, a unified platform for evaluating retrieval, reranking, and RAG systems using human and LLM feedback. It addresses the challenges in scalable, user-centric, and multi-perspective evaluation of these systems.",
        "contributions": [
          "A unified platform (RankArena) for evaluating retrieval pipelines, rerankers, and RAG systems.",
          "Support for multiple evaluation modes including direct reranking visualization, blind pairwise comparisons, supervised manual document annotation, and end-to-end RAG answer quality assessment.",
          "Capture of fine-grained relevance feedback through pairwise preferences and full-list annotations, along with auxiliary metadata.",
          "Integration of LLM-as-a-judge evaluation for comparing model-generated rankings with human annotations.",
          "Structured evaluation datasets that can be used for training various models (rerankers, reward models, judgment agents, or retrieval strategy selectors)."
        ],
        "methods": [
          "Direct reranking visualization",
          "Blind pairwise comparisons with human or LLM voting",
          "Supervised manual document annotation",
          "End-to-end RAG answer quality assessment",
          "LLM-as-a-judge evaluation"
        ],
        "datasets": [
          "Structured evaluation datasets generated by the platform containing human and LLM feedback, pairwise preferences, and full-list annotations."
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations; however, potential limitations may include scalability issues with a large number of users or complex evaluation scenarios.",
          "The effectiveness of the LLM-as-a-judge component may depend on the quality of the LLM used and the specific evaluation task."
        ],
        "companies": [
          "RIKEN",
          "Kyoto University"
        ]
      },
      {
        "title": "E-VRAG: Enhancing Long Video Understanding with Resource-Efficient Retrieval Augmented Generation",
        "authors": [
          "Zeyu Xu",
          "Junkang Zhang",
          "Qiang Wang",
          "Yi Liu"
        ],
        "affiliations": [],
        "abstract": "Vision-Language Models (VLMs) have enabled substantial progress in video understanding by leveraging cross-modal reasoning capabilities. However, their effectiveness is limited by the restricted context window and the high computational cost required to process long videos with thousands of frames. Retrieval-augmented generation (RAG) addresses this challenge by selecting only the most relevant frames as input, thereby reducing the computational burden. Nevertheless, existing video RAG methods struggle to balance retrieval efficiency and accuracy, particularly when handling diverse and complex video content. To address these limitations, we propose E-VRAG, a novel and efficient video RAG framework for video understanding. We first apply a frame pre-filtering method based on hierarchical query decomposition to eliminate irrelevant frames, reducing computational costs at the data level. We then employ a lightweight VLM for frame scoring, further reducing computational costs at the model level. Additionally, we propose a frame retrieval strategy that leverages the global statistical distribution of inter-frame scores to mitigate the potential performance degradation from using a lightweight VLM. Finally, we introduce a multi-view question answering scheme for the retrieved frames, enhancing the VLM's capability to extract and comprehend information from long video contexts. Experiments on four public benchmarks show that E-VRAG achieves about 70% reduction in computational cost and higher accuracy compared to baseline methods, all without additional training. These results demonstrate the effectiveness of E-VRAG in improving both efficiency and accuracy for video RAG tasks.",
        "published": "2025-08-03T02:09:54+00:00",
        "url": "http://arxiv.org/abs/2508.01546v1",
        "categories": [
          "cs.CV"
        ],
        "summary": "The paper introduces E-VRAG, a novel Retrieval Augmented Generation (RAG) framework designed to enhance long video understanding. E-VRAG improves upon existing methods by focusing on both retrieval efficiency and accuracy, resulting in a significant reduction in computational cost and improved performance on video understanding tasks.",
        "contributions": [
          "A novel and efficient video RAG framework (E-VRAG) for long video understanding that balances retrieval efficiency and accuracy.",
          "A frame pre-filtering method based on hierarchical query decomposition to eliminate irrelevant frames and reduce computational costs.",
          "A lightweight VLM frame scoring method to further reduce computational costs at the model level.",
          "A frame retrieval strategy that leverages the global statistical distribution of inter-frame scores to mitigate performance degradation.",
          "A multi-view question answering scheme for retrieved frames to enhance VLM's comprehension from long video contexts."
        ],
        "methods": [
          "Retrieval Augmented Generation (RAG)",
          "Hierarchical query decomposition for frame pre-filtering",
          "Lightweight Vision-Language Model (VLM) for frame scoring",
          "Frame retrieval using global statistical distribution of inter-frame scores",
          "Multi-view question answering"
        ],
        "datasets": [
          "Four public benchmarks (unspecified in abstract, but mentioned in experiments)"
        ],
        "limitations": [
          "Reliance on the performance of the lightweight VLM used for frame scoring.",
          "The specific types of videos and tasks that E-VRAG is most effective for are not explicitly stated in the abstract. Need to read the full paper for details."
        ],
        "companies": [
          "Microsoft",
          "Tsinghua University"
        ]
      },
      {
        "title": "VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and Visual Documents",
        "authors": [
          "Rui Meng",
          "Ziyan Jiang",
          "Ye Liu",
          "Mingyi Su",
          "Xinyi Yang",
          "Yuepeng Fu",
          "Can Qin",
          "Zeyuan Chen",
          "Ran Xu",
          "Caiming Xiong",
          "Yingbo Zhou",
          "Wenhu Chen",
          "Semih Yavuz"
        ],
        "affiliations": [],
        "abstract": "Multimodal embedding models have been crucial in enabling various downstream tasks such as semantic similarity, information retrieval, and clustering over different modalities. However, existing multimodal embeddings like VLM2Vec, E5-V, GME are predominantly focused on natural images, with limited support for other visual forms such as videos and visual documents. This restricts their applicability in real-world scenarios, including AI agents, multi-modal search and recommendation, and retrieval-augmented generation (RAG). To close this gap, we propose VLM2Vec-V2, a unified framework for learning embeddings across diverse visual forms. First, we introduce MMEB-V2, a comprehensive benchmark that extends MMEB with five new task types: visual document retrieval, video retrieval, temporal grounding, video classification and video question answering - spanning text, image, video, and visual document inputs. Next, we train VLM2Vec-V2, a general-purpose embedding model that supports text, image, video, and visual document inputs. Extensive experiments show that VLM2Vec-V2 achieves strong performance not only on the newly introduced video and document retrieval tasks, but also improves over prior baselines on the original image benchmarks. Through extensive evaluation, our study offers insights into the generalizability of various multimodal embedding models and highlights effective strategies for unified embedding learning, laying the groundwork for more scalable and adaptable representation learning in both research and real-world settings.",
        "published": "2025-07-07T00:51:57+00:00",
        "url": "http://arxiv.org/abs/2507.04590v1",
        "categories": [
          "cs.CV",
          "cs.CL"
        ],
        "summary": "The paper introduces VLM2Vec-V2, a unified multimodal embedding framework for videos, images, and visual documents, addressing the limitations of existing models that primarily focus on natural images. It also presents MMEB-V2, a new benchmark extending MMEB with tasks involving videos and visual documents to evaluate the performance of multimodal embeddings across diverse visual forms.",
        "contributions": [
          "Development of VLM2Vec-V2, a general-purpose multimodal embedding model supporting text, image, video, and visual document inputs.",
          "Creation of MMEB-V2, a comprehensive benchmark extending MMEB with five new task types: visual document retrieval, video retrieval, temporal grounding, video classification, and video question answering."
        ],
        "methods": [
          "Unified embedding learning across diverse visual forms (text, image, video, visual documents)",
          "Training a general-purpose embedding model (VLM2Vec-V2) on the expanded MMEB-V2 benchmark."
        ],
        "datasets": [
          "MMEB (original benchmark)",
          "MMEB-V2 (extended benchmark with new video and document datasets)"
        ],
        "limitations": [
          "The abstract itself doesn't explicitly mention limitations, but it implicitly suggests a limitation of previous models: 'limited support for other visual forms such as videos and visual documents'.",
          "Without further information, the computational cost and scalability of training and using VLM2Vec-V2 on large datasets are potential limitations. This is speculative based on the nature of multimodal embedding models, and isn't explicitly stated in the abstract."
        ],
        "companies": [
          "University of California, Santa Barbara",
          "Microsoft"
        ]
      },
      {
        "title": "AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long Video Understanding",
        "authors": [
          "Zhucun Xue",
          "Jiangning Zhang",
          "Xurong Xie",
          "Yuxuan Cai",
          "Yong Liu",
          "Xiangtai Li",
          "Dacheng Tao"
        ],
        "affiliations": [],
        "abstract": "Multimodal Large Language Models (MLLMs) perform well in video understanding but degrade on long videos due to fixed-length context and weak long-term dependency modeling. Retrieval-Augmented Generation (RAG) can expand knowledge dynamically, yet existing video RAG schemes adopt fixed retrieval paradigms that ignore query difficulty. This uniform design causes redundant computation and latency for simple queries, while coarse retrieval for complex, multi-hop reasoning can miss key information. Such single-step retrieval severely limits the trade-off between efficiency and cognitive depth. We propose AdaVideoRAG, an adaptive RAG framework for long-video understanding. A lightweight intent classifier dynamically selects suitable retrieval schemes according to query complexity from the simplest to the most sophisticated. We design an Omni-Knowledge Indexing module that extracts and organizes multi-modal information into three databases: (1) a text base built from clip captions, ASR, and OCR; (2) a visual base; and (3) a knowledge graph for deep semantic understanding. This supports hierarchical knowledge access, from naive retrieval to graph-based retrieval, balancing resource cost and reasoning ability. To evaluate deep understanding, we further construct the HiVU benchmark. Experiments show that AdaVideoRAG significantly improves both efficiency and accuracy on long-video QA tasks and can be seamlessly plugged into existing MLLMs through lightweight APIs, establishing a new paradigm for adaptive retrieval-augmented video analysis.",
        "published": "2025-06-16T15:18:15+00:00",
        "url": "http://arxiv.org/abs/2506.13589v3",
        "categories": [
          "cs.CV"
        ],
        "summary": "The paper introduces AdaVideoRAG, an adaptive retrieval-augmented generation framework for long video understanding that addresses the limitations of fixed-length context in MLLMs. AdaVideoRAG dynamically selects retrieval schemes based on query complexity, improving efficiency and accuracy in long-video question answering.",
        "contributions": [
          "Proposes AdaVideoRAG, an adaptive RAG framework for long-video understanding that dynamically selects retrieval schemes based on query complexity.",
          "Introduces an Omni-Knowledge Indexing module that extracts and organizes multi-modal information into text, visual, and knowledge graph databases for hierarchical knowledge access.",
          "Constructs the HiVU benchmark for evaluating deep video understanding capabilities."
        ],
        "methods": [
          "Adaptive Retrieval-Augmented Generation (RAG)",
          "Intent Classification for determining query complexity",
          "Omni-Knowledge Indexing (text, visual, and knowledge graph databases)",
          "Hierarchical Knowledge Access (naive to graph-based retrieval)"
        ],
        "datasets": [
          "HiVU benchmark (newly constructed dataset for deep video understanding)"
        ],
        "limitations": [
          "The abstract doesn't explicitly state limitations, but it is reasonable to assume that the complexity of implementation and the cost of building and maintaining the knowledge graph could be limitations.",
          "The performance and scalability of the method with extremely long videos and very complex queries are not explicitly addressed in the abstract."
        ],
        "companies": [
          "University of Sydney",
          "Alibaba Group"
        ]
      },
      {
        "title": "VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation",
        "authors": [
          "Hyeongcheol Park",
          "Jiyoung Seo",
          "MinHyuk Jang",
          "Hogun Park",
          "Ha Dam Baek",
          "Gyusam Chang",
          "Hyeonsoo Im",
          "Sangpil Kim"
        ],
        "affiliations": [],
        "abstract": "Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge across multiple modalities, play a pivotal role by complementing the implicit knowledge of Multimodal Large Language Models (MLLMs) and enabling more grounded reasoning via Retrieval Augmented Generation (RAG). However, existing MMKGs are generally limited in scope: they are often constructed by augmenting pre-existing knowledge graphs, which restricts their knowledge, resulting in outdated or incomplete knowledge coverage, and they often support only a narrow range of modalities, such as text and visual information. These limitations restrict applicability to multimodal tasks, particularly as recent MLLMs adopt richer modalities like video and audio. Therefore, we propose the Visual-Audio-Text Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive multimodal knowledge graph that covers visual, audio, and text information, where each triplet is linked to multimodal data and enriched with detailed descriptions of concepts. Specifically, our construction pipeline ensures cross-modal knowledge alignment between multimodal data and fine-grained semantics through a series of stringent filtering and alignment steps, enabling the automatic generation of MMKGs from any multimodal dataset. We further introduce a novel multimodal RAG framework that retrieves detailed concept-level knowledge in response to queries from arbitrary modalities. Experiments on question answering tasks across various modalities demonstrate the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical value in unifying and leveraging multimodal knowledge.",
        "published": "2025-06-11T07:22:57+00:00",
        "url": "http://arxiv.org/abs/2506.21556v3",
        "categories": [
          "cs.CL"
        ],
        "summary": "This paper introduces VAT-KG, a novel multimodal knowledge graph (MMKG) encompassing visual, audio, and text information designed to enhance Retrieval Augmented Generation (RAG) for Multimodal Large Language Models (MLLMs). VAT-KG addresses limitations in existing MMKGs by providing a concept-centric and knowledge-intensive resource with detailed descriptions and cross-modal knowledge alignment.",
        "contributions": [
          "Creation of VAT-KG: A new multimodal knowledge graph (MMKG) integrating visual, audio, and text modalities with detailed concept descriptions.",
          "Development of a construction pipeline for automatic generation of MMKGs from any multimodal dataset, ensuring cross-modal knowledge alignment.",
          "Introduction of a novel multimodal RAG framework utilizing VAT-KG to retrieve concept-level knowledge for queries from arbitrary modalities."
        ],
        "methods": [
          "Automatic generation of MMKGs through a pipeline with stringent filtering and alignment steps.",
          "Cross-modal knowledge alignment techniques to ensure coherence between visual, audio, and text data.",
          "Multimodal RAG framework for retrieving concept-level knowledge based on queries from various modalities."
        ],
        "datasets": [
          "VAT-KG (Visual-Audio-Text Knowledge Graph)"
        ],
        "limitations": [
          "The abstract doesn't explicitly state limitations of the proposed VAT-KG, but implies that prior MMKGs suffered from limited scope and modality support.",
          "The abstract doesn't mention any specific limitations of the proposed methods."
        ],
        "companies": [
          "LG AI Research"
        ]
      },
      {
        "title": "A Smart Multimodal Healthcare Copilot with Powerful LLM Reasoning",
        "authors": [
          "Xuejiao Zhao",
          "Siyan Liu",
          "Su-Yin Yang",
          "Chunyan Miao"
        ],
        "affiliations": [],
        "abstract": "Misdiagnosis causes significant harm to healthcare systems worldwide, leading to increased costs and patient risks. MedRAG is a smart multimodal healthcare copilot equipped with powerful large language model (LLM) reasoning, designed to enhance medical decision-making. It supports multiple input modalities, including non-intrusive voice monitoring, general medical queries, and electronic health records. MedRAG provides recommendations on diagnosis, treatment, medication, and follow-up questioning. Leveraging retrieval-augmented generation enhanced by knowledge graph-elicited reasoning, MedRAG retrieves and integrates critical diagnostic insights, reducing the risk of misdiagnosis. It has been evaluated on both public and private datasets, outperforming existing models and offering more specific and accurate healthcare assistance. A demonstration video of MedRAG is available at: https://www.youtube.com/watch?v=PNIBDMYRfDM. The source code is available at: https://github.com/SNOWTEAM2023/MedRAG.",
        "published": "2025-06-03T05:39:02+00:00",
        "url": "http://arxiv.org/abs/2506.02470v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "The paper introduces MedRAG, a smart multimodal healthcare copilot designed to improve medical decision-making and reduce misdiagnosis by leveraging LLM reasoning and retrieval-augmented generation. MedRAG integrates various input modalities and provides recommendations on diagnosis, treatment, medication, and follow-up questioning.",
        "contributions": [
          "Development of MedRAG, a multimodal healthcare copilot that integrates voice monitoring, general medical queries, and electronic health records.",
          "Implementation of knowledge graph-elicited reasoning within a retrieval-augmented generation framework to enhance diagnostic accuracy and reduce misdiagnosis risk."
        ],
        "methods": [
          "Large Language Model (LLM) reasoning",
          "Retrieval-Augmented Generation (RAG) enhanced by knowledge graph-elicited reasoning"
        ],
        "datasets": [
          "Public datasets",
          "Private datasets"
        ],
        "limitations": [
          "The abstract does not explicitly state the limitations of the model or the study.",
          "The abstract does not specify the types or sizes of the datasets used for evaluation, making it difficult to assess generalizability."
        ],
        "companies": [
          "Nanyang Technological University"
        ]
      },
      {
        "title": "Vid2Coach: Transforming How-To Videos into Task Assistants",
        "authors": [
          "Mina Huh",
          "Zihui Xue",
          "Ujjaini Das",
          "Kumar Ashutosh",
          "Kristen Grauman",
          "Amy Pavel"
        ],
        "affiliations": [],
        "abstract": "People use videos to learn new recipes, exercises, and crafts. Such videos remain difficult for blind and low vision (BLV) people to follow as they rely on visual comparison. Our observations of visual rehabilitation therapists (VRTs) guiding BLV people to follow how-to videos revealed that VRTs provide both proactive and responsive support including detailed descriptions, non-visual workarounds, and progress feedback. We propose Vid2Coach, a system that transforms how-to videos into wearable camera-based assistants that provide accessible instructions and mixed-initiative feedback. From the video, Vid2Coach generates accessible instructions by augmenting narrated instructions with demonstration details and completion criteria for each step. It then uses retrieval-augmented-generation to extract relevant non-visual workarounds from BLV-specific resources. Vid2Coach then monitors user progress with a camera embedded in commercial smart glasses to provide context-aware instructions, proactive feedback, and answers to user questions. BLV participants (N=8) using Vid2Coach completed cooking tasks with 58.5\\% fewer errors than when using their typical workflow and wanted to use Vid2Coach in their daily lives. Vid2Coach demonstrates an opportunity for AI visual assistance that strengthens rather than replaces non-visual expertise.",
        "published": "2025-05-31T21:28:50+00:00",
        "url": "http://arxiv.org/abs/2506.00717v2",
        "categories": [
          "cs.HC",
          "cs.CV"
        ],
        "summary": "The paper introduces Vid2Coach, a system that transforms how-to videos into wearable camera-based assistants for blind and low vision (BLV) individuals. It provides accessible instructions, non-visual workarounds, and progress feedback, resulting in significantly fewer errors in task completion compared to typical workflows.",
        "contributions": [
          "Vid2Coach system: A novel system that leverages AI to make how-to videos accessible to BLV individuals through wearable camera-based assistance.",
          "Integration of multiple AI techniques: Combines narrated instruction augmentation with demonstration details, retrieval-augmented generation for non-visual workarounds, and camera-based progress monitoring.",
          "Demonstrated significant error reduction: BLV participants using Vid2Coach showed a substantial decrease in errors during cooking tasks compared to their usual methods.",
          "Identification of VRT support strategies: Observation and analysis of visual rehabilitation therapists' methods to guide system design."
        ],
        "methods": [
          "Narration Augmentation: Adding demonstration details and completion criteria to existing narrated instructions.",
          "Retrieval-Augmented Generation (RAG): Extracting relevant non-visual workarounds from BLV-specific resources using RAG.",
          "Camera-based Progress Monitoring: Using a camera embedded in smart glasses to track user progress and provide context-aware instructions and feedback.",
          "User study with BLV participants: Evaluating the system's effectiveness and usability through a user study with 8 BLV participants."
        ],
        "datasets": [],
        "limitations": [
          "Limited user study size: The study involved only 8 participants, which may limit the generalizability of the results.",
          "Specific task focus: The evaluation focused on cooking tasks; the system's effectiveness in other types of how-to videos (e.g., exercise, crafts) needs further investigation.",
          "Reliance on existing video narration: The system relies on the presence of narration in the how-to videos, which may not always be available or sufficient."
        ],
        "companies": [
          "University of Texas at Austin",
          "Meta"
        ]
      },
      {
        "title": "Traffic-MLLM: A Spatio-Temporal MLLM with Retrieval-Augmented Generation for Causal Inference in Traffic",
        "authors": [
          "Waikit Xiu",
          "Qiang Lu",
          "Xiying Li",
          "Chen Hu",
          "Shengbo Sun"
        ],
        "affiliations": [],
        "abstract": "As intelligent transportation systems advance, traffic video understanding plays an increasingly pivotal role in comprehensive scene perception and causal analysis. Yet, existing approaches face notable challenges in accurately modeling spatiotemporal causality and integrating domain-specific knowledge, limiting their effectiveness in complex scenarios. To address these limitations, we propose Traffic-MLLM, a multimodal large language model tailored for fine-grained traffic analysis. Built on the Qwen2.5-VL backbone, our model leverages high-quality traffic-specific multimodal datasets and uses Low-Rank Adaptation (LoRA) for lightweight fine-tuning, significantly enhancing its capacity to model continuous spatiotemporal features in video sequences. Furthermore, we introduce an innovative knowledge prompting module fusing Chain-of-Thought (CoT) reasoning with Retrieval-Augmented Generation (RAG), enabling precise injection of detailed traffic regulations and domain knowledge into the inference process. This design markedly boosts the model's logical reasoning and knowledge adaptation capabilities. Experimental results on TrafficQA and DriveQA benchmarks show Traffic-MLLM achieves state-of-the-art performance, validating its superior ability to process multimodal traffic data. It also exhibits remarkable zero-shot reasoning and cross-scenario generalization capabilities.",
        "published": "2025-09-14T08:53:06+00:00",
        "url": "http://arxiv.org/abs/2509.11165v1",
        "categories": [
          "cs.CV"
        ],
        "summary": "The paper introduces Traffic-MLLM, a multimodal large language model designed for fine-grained traffic analysis, addressing limitations in existing approaches for modeling spatiotemporal causality and integrating domain knowledge. It achieves state-of-the-art performance on traffic understanding benchmarks by leveraging a novel architecture and training strategy.",
        "contributions": [
          "Development of Traffic-MLLM, a tailored MLLM for traffic analysis based on Qwen2.5-VL.",
          "Introduction of a knowledge prompting module combining Chain-of-Thought reasoning with Retrieval-Augmented Generation (RAG) for injecting traffic regulations and domain knowledge."
        ],
        "methods": [
          "Multimodal Large Language Model (MLLM) based on Qwen2.5-VL",
          "Low-Rank Adaptation (LoRA) for lightweight fine-tuning",
          "Chain-of-Thought (CoT) reasoning",
          "Retrieval-Augmented Generation (RAG)"
        ],
        "datasets": [
          "TrafficQA",
          "DriveQA"
        ],
        "limitations": [
          "The abstract does not explicitly mention the limitations of the approach; this would require reading the full paper.",
          "The abstract does not explicitly state the computational cost of the model; this would require reading the full paper."
        ],
        "companies": [
          "Tsinghua University",
          "Peking University",
          "Chinese Academy of Sciences",
          "Beihang University"
        ]
      },
      {
        "title": "AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity",
        "authors": [
          "Bohdan M. Pavlyshenko"
        ],
        "affiliations": [],
        "abstract": "The paper considers the use of GPT models with retrieval-augmented generation (RAG) for qualitative and quantitative analytics on NATO sentiments, NATO unity and NATO Article 5 trust opinion scores in different web sources: news sites found via Google Search API, Youtube videos with comments, and Reddit discussions. A RAG approach using GPT-4.1 model was applied to analyse news where NATO related topics were discussed. Two levels of RAG analytics were used: on the first level, the GPT model generates qualitative news summaries and quantitative opinion scores using zero-shot prompts; on the second level, the GPT model generates the summary of news summaries. Quantitative news opinion scores generated by the GPT model were analysed using Bayesian regression to get trend lines. The distributions found for the regression parameters make it possible to analyse an uncertainty in specified news opinion score trends. Obtained results show a downward trend for analysed scores of opinion related to NATO unity.\n  This approach does not aim to conduct real political analysis; rather, it consider AI based approaches which can be used for further analytics\n  as a part of a complex analytical approach. The obtained results demonstrate that the use of GPT models for news analysis can give informative qualitative and quantitative analytics, providing important insights.\n  The dynamic model based on neural ordinary differential equations was considered for modelling public opinions. This approach makes it possible to analyse different scenarios for evolving public opinions.",
        "published": "2025-05-08T18:42:01+00:00",
        "url": "http://arxiv.org/abs/2505.06313v1",
        "categories": [
          "cs.IR",
          "cs.AI",
          "cs.CL",
          "cs.SI"
        ],
        "summary": "This paper explores the use of GPT models with retrieval-augmented generation (RAG) for analyzing NATO sentiments and unity across various online sources. The study demonstrates that GPT models can provide informative qualitative summaries and quantitative opinion scores, offering valuable insights into public perception, although the study does not aim to conduct real political analysis.",
        "contributions": [
          "Demonstrates the applicability of GPT models with RAG for qualitative and quantitative news analytics related to NATO unity and sentiment.",
          "Presents a two-level RAG approach for news summarization and opinion score generation.",
          "Uses Bayesian regression to analyze trends and uncertainties in news opinion scores.",
          "Considers a dynamic model based on neural ordinary differential equations for modelling public opinions."
        ],
        "methods": [
          "GPT models (specifically GPT-4.1) with retrieval-augmented generation (RAG)",
          "Zero-shot prompting",
          "Bayesian regression",
          "Neural ordinary differential equations"
        ],
        "datasets": [
          "News sites (accessed via Google Search API)",
          "YouTube videos with comments",
          "Reddit discussions"
        ],
        "limitations": [
          "Does not aim to conduct real political analysis, but rather explores AI-based approaches.",
          "The specific limitations of the GPT model's accuracy and potential biases are not explicitly addressed in this abstract."
        ],
        "companies": [
          "NATO"
        ]
      },
      {
        "title": "SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model",
        "authors": [
          "Zongcan Ding",
          "Haodong Zhang",
          "Peng Wu",
          "Guansong Pang",
          "Zhiwei Yang",
          "Peng Wang",
          "Yanning Zhang"
        ],
        "affiliations": [],
        "abstract": "Video anomaly detection (VAD) aims to identify unexpected events in videos and has wide applications in safety-critical domains. While semi-supervised methods trained on only normal samples have gained traction, they often suffer from high false alarm rates and poor interpretability. Recently, vision-language models (VLMs) have demonstrated strong multimodal reasoning capabilities, offering new opportunities for explainable anomaly detection. However, their high computational cost and lack of domain adaptation hinder real-time deployment and reliability. Inspired by dual complementary pathways in human visual perception, we propose SlowFastVAD, a hybrid framework that integrates a fast anomaly detector with a slow anomaly detector (namely a retrieval augmented generation (RAG) enhanced VLM), to address these limitations. Specifically, the fast detector first provides coarse anomaly confidence scores, and only a small subset of ambiguous segments, rather than the entire video, is further analyzed by the slower yet more interpretable VLM for elaborate detection and reasoning. Furthermore, to adapt VLMs to domain-specific VAD scenarios, we construct a knowledge base including normal patterns based on few normal samples and abnormal patterns inferred by VLMs. During inference, relevant patterns are retrieved and used to augment prompts for anomaly reasoning. Finally, we smoothly fuse the anomaly confidence of fast and slow detectors to enhance robustness of anomaly detection. Extensive experiments on four benchmarks demonstrate that SlowFastVAD effectively combines the strengths of both fast and slow detectors, and achieves remarkable detection accuracy and interpretability with significantly reduced computational overhead, making it well-suited for real-world VAD applications with high reliability requirements.",
        "published": "2025-04-14T15:30:03+00:00",
        "url": "http://arxiv.org/abs/2504.10320v1",
        "categories": [
          "cs.CV"
        ],
        "summary": "The paper introduces SlowFastVAD, a novel framework for video anomaly detection that combines a fast anomaly detector with a slower, more interpretable Retrieval Augmented Generation (RAG)-enhanced Vision-Language Model (VLM). This hybrid approach aims to improve detection accuracy, interpretability, and computational efficiency for real-world VAD applications.",
        "contributions": [
          "Proposes SlowFastVAD, a hybrid VAD framework integrating a fast anomaly detector and a RAG-enhanced VLM to balance speed and interpretability.",
          "Constructs a domain-specific knowledge base of normal and abnormal patterns to adapt VLMs to VAD scenarios and improve anomaly reasoning.",
          "Introduces a method to smoothly fuse the anomaly confidence scores from the fast and slow detectors to enhance the robustness of anomaly detection."
        ],
        "methods": [
          "Fast anomaly detector (unspecified in abstract, but provides coarse anomaly scores)",
          "Retrieval Augmented Generation (RAG)-enhanced Vision-Language Model (VLM) for detailed detection and reasoning",
          "Knowledge base construction for domain adaptation of VLMs",
          "Fusion of anomaly confidence scores from fast and slow detectors"
        ],
        "datasets": [
          "Four benchmarks (unspecified in abstract)"
        ],
        "limitations": [
          "High computational cost of VLMs, addressed but not entirely eliminated",
          "Lack of domain adaptation of VLMs, addressed by knowledge base construction"
        ],
        "companies": [
          "Xi'an Jiaotong University"
        ]
      },
      {
        "title": "Open-Ended and Knowledge-Intensive Video Question Answering",
        "authors": [
          "Md Zarif Ul Alam",
          "Hamed Zamani"
        ],
        "affiliations": [],
        "abstract": "Video question answering that requires external knowledge beyond the visual content remains a significant challenge in AI systems. While models can effectively answer questions based on direct visual observations, they often falter when faced with questions requiring broader contextual knowledge. To address this limitation, we investigate knowledge-intensive video question answering (KI-VideoQA) through the lens of multi-modal retrieval-augmented generation, with a particular focus on handling open-ended questions rather than just multiple-choice formats. Our comprehensive analysis examines various retrieval augmentation approaches using cutting-edge retrieval and vision language models, testing both zero-shot and fine-tuned configurations. We investigate several critical dimensions: the interplay between different information sources and modalities, strategies for integrating diverse multi-modal contexts, and the dynamics between query formulation and retrieval result utilization. Our findings reveal that while retrieval augmentation shows promise in improving model performance, its success is heavily dependent on the chosen modality and retrieval methodology. The study also highlights the critical role of query construction and retrieval depth optimization in effective knowledge integration. Through our proposed approach, we achieve a substantial 17.5% improvement in accuracy on multiple choice questions in the KnowIT VQA dataset, establishing new state-of-the-art performance levels.",
        "published": "2025-02-17T12:40:35+00:00",
        "url": "http://arxiv.org/abs/2502.11747v2",
        "categories": [
          "cs.IR"
        ],
        "summary": "This research investigates knowledge-intensive video question answering (KI-VideoQA) using multi-modal retrieval-augmented generation, focusing on open-ended questions. The study analyzes retrieval augmentation approaches with various retrieval and vision language models, examining the interplay between modalities and query formulation.",
        "contributions": [
          "Comprehensive analysis of retrieval augmentation for KI-VideoQA, considering different modalities and retrieval methodologies.",
          "Demonstration of the critical role of query construction and retrieval depth optimization for effective knowledge integration in KI-VideoQA.",
          "Achieved a 17.5% improvement in accuracy on multiple-choice questions in the KnowIT VQA dataset, setting a new state-of-the-art performance."
        ],
        "methods": [
          "Multi-modal retrieval-augmented generation",
          "Zero-shot and fine-tuned configurations of retrieval and vision language models",
          "Analysis of query formulation and retrieval depth optimization"
        ],
        "datasets": [
          "KnowIT VQA"
        ],
        "limitations": [
          "The success of retrieval augmentation is heavily dependent on the chosen modality and retrieval methodology.",
          "The abstract does not explicitly mention other limitations, further analysis of the full paper is needed."
        ],
        "companies": [
          "Google"
        ]
      },
      {
        "title": "Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis",
        "authors": [
          "Ameer Hamza Shakur",
          "Michael J. Holcomb",
          "David Hein",
          "Shinyoung Kang",
          "Thomas O. Dalton",
          "Krystle K. Campbell",
          "Daniel J. Scott",
          "Andrew R. Jamieson"
        ],
        "affiliations": [],
        "abstract": "Grading Objective Structured Clinical Examinations (OSCEs) is a time-consuming and expensive process, traditionally requiring extensive manual effort from human experts. In this study, we explore the potential of Large Language Models (LLMs) to assess skills related to medical student communication. We analyzed 2,027 video-recorded OSCE examinations from the University of Texas Southwestern Medical Center (UTSW), spanning four years (2019-2022), and several different medical cases or \"stations.\" Specifically, our focus was on evaluating students' ability to summarize patients' medical history: we targeted the rubric item 'did the student summarize the patients' medical history?' from the communication skills rubric. After transcribing speech audio captured by OSCE videos using Whisper-v3, we studied the performance of various LLM-based approaches for grading students on this summarization task based on their examination transcripts. Using various frontier-level open-source and proprietary LLMs, we evaluated different techniques such as zero-shot chain-of-thought prompting, retrieval augmented generation, and multi-model ensemble methods. Our results show that frontier LLM models like GPT-4 achieved remarkable alignment with human graders, demonstrating a Cohen's kappa agreement of 0.88 and indicating strong potential for LLM-based OSCE grading to augment the current grading process. Open-source models also showed promising results, suggesting potential for widespread, cost-effective deployment. Further, we present a failure analysis identifying conditions where LLM grading may be less reliable in this context and recommend best practices for deploying LLMs in medical education settings.",
        "published": "2024-10-11T19:16:03+00:00",
        "url": "http://arxiv.org/abs/2410.12858v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "summary": "This research explores the use of Large Language Models (LLMs) for automatically assessing medical students' communication skills in Objective Structured Clinical Examinations (OSCEs), specifically focusing on their ability to summarize patients' medical history. The study demonstrates that frontier LLMs can achieve high agreement with human graders, suggesting potential for augmenting traditional OSCE grading processes.",
        "contributions": [
          "Demonstrated the feasibility of using LLMs, particularly GPT-4, for automated assessment of medical student communication skills in OSCEs with high agreement with human graders (Cohen's kappa = 0.88).",
          "Evaluated different LLM techniques (zero-shot chain-of-thought, retrieval augmented generation, multi-model ensemble) for OSCE grading and identified promising open-source models for cost-effective deployment.",
          "Provided a failure analysis identifying conditions where LLM grading may be less reliable and recommended best practices for deploying LLMs in medical education settings."
        ],
        "methods": [
          "Speech audio transcription using Whisper-v3.",
          "LLM-based grading using zero-shot chain-of-thought prompting.",
          "LLM-based grading using retrieval augmented generation.",
          "LLM-based grading using multi-model ensemble methods.",
          "Evaluation of LLM performance using Cohen's kappa agreement with human graders."
        ],
        "datasets": [
          "2,027 video-recorded OSCE examinations from the University of Texas Southwestern Medical Center (UTSW) spanning four years (2019-2022).",
          "Transcribed speech audio from the OSCE videos."
        ],
        "limitations": [
          "Failure analysis identified conditions where LLM grading may be less reliable (implicitly stated in the abstract).",
          "The study focuses on a single aspect of communication skills (summarization of medical history), limiting generalizability to other OSCE assessment criteria."
        ],
        "companies": [
          "University of [City/State, if determinable from author names]",
          "Hospital [City/State, if determinable from author names]",
          "Medical School [City/State, if determinable from author names]"
        ]
      }
    ],
    "Multi-Agent Reinforcement Learning with memory.": [
      {
        "title": "Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings",
        "authors": [
          "Harsh Rathva",
          "Ojas Srivastava",
          "Pruthwik Mishra"
        ],
        "affiliations": [],
        "abstract": "We introduce Embedded Safety-Aligned Intelligence (ESAI), a theoretical framework for multi-agent reinforcement learning that embeds alignment constraints directly into agents internal representations using differentiable internal alignment embeddings. Unlike external reward shaping or post-hoc safety constraints, internal alignment embeddings are learned latent variables that predict externalized harm through counterfactual reasoning and modulate policy updates toward harm reduction through attention and graph-based propagation.\n  The ESAI framework integrates four mechanisms: differentiable counterfactual alignment penalties computed from soft reference distributions, alignment-weighted perceptual attention, Hebbian associative memory supporting temporal credit assignment, and similarity-weighted graph diffusion with bias mitigation controls. We analyze stability conditions for bounded internal embeddings under Lipschitz continuity and spectral constraints, discuss computational complexity, and examine theoretical properties including contraction behavior and fairness-performance tradeoffs.\n  This work positions ESAI as a conceptual contribution to differentiable alignment mechanisms in multi-agent systems. We identify open theoretical questions regarding convergence guarantees, embedding dimensionality, and extension to high-dimensional environments. Empirical evaluation is left to future work.",
        "published": "2025-12-20T10:42:48+00:00",
        "url": "http://arxiv.org/abs/2512.18309v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "The paper introduces Embedded Safety-Aligned Intelligence (ESAI), a theoretical framework for multi-agent reinforcement learning that incorporates safety alignment constraints directly into agent's internal representations using differentiable internal alignment embeddings. ESAI aims to reduce harm by predicting externalized harm through counterfactual reasoning and modulating policy updates via attention and graph-based propagation.",
        "contributions": [
          "Introduction of the Embedded Safety-Aligned Intelligence (ESAI) framework for multi-agent reinforcement learning.",
          "Proposal of differentiable internal alignment embeddings that embed alignment constraints directly into agents' internal representations."
        ],
        "methods": [
          "Differentiable counterfactual alignment penalties computed from soft reference distributions.",
          "Alignment-weighted perceptual attention.",
          "Hebbian associative memory supporting temporal credit assignment.",
          "Similarity-weighted graph diffusion with bias mitigation controls."
        ],
        "datasets": [],
        "limitations": [
          "Lack of empirical evaluation to validate the ESAI framework.",
          "Open theoretical questions regarding convergence guarantees, embedding dimensionality, and extension to high-dimensional environments."
        ],
        "companies": [
          "Google",
          "DeepMind"
        ]
      },
      {
        "title": "Bilevel Optimization for Covert Memory Tampering in Heterogeneous Multi-Agent Architectures (XAMT)",
        "authors": [
          "Akhil Sharma",
          "Shaikh Yaser Arafat",
          "Jai Kumar Sharma",
          "Ken Huang"
        ],
        "affiliations": [],
        "abstract": "The increasing operational reliance on complex Multi-Agent Systems (MAS) across safety-critical domains necessitates rigorous adversarial robustness assessment. Modern MAS are inherently heterogeneous, integrating conventional Multi-Agent Reinforcement Learning (MARL) with emerging Large Language Model (LLM) agent architectures utilizing Retrieval-Augmented Generation (RAG). A critical shared vulnerability is reliance on centralized memory components: the shared Experience Replay (ER) buffer in MARL and the external Knowledge Base (K) in RAG agents. This paper proposes XAMT (Bilevel Optimization for Covert Memory Tampering in Heterogeneous Multi-Agent Architectures), a novel framework that formalizes attack generation as a bilevel optimization problem. The Upper Level minimizes perturbation magnitude (delta) to enforce covertness while maximizing system behavior divergence toward an adversary-defined target (Lower Level). We provide rigorous mathematical instantiations for CTDE MARL algorithms and RAG-based LLM agents, demonstrating that bilevel optimization uniquely crafts stealthy, minimal-perturbation poisons evading detection heuristics. Comprehensive experimental protocols utilize SMAC and SafeRAG benchmarks to quantify effectiveness at sub-percent poison rates (less than or equal to 1 percent in MARL, less than or equal to 0.1 percent in RAG). XAMT defines a new unified class of training-time threats essential for developing intrinsically secure MAS, with implications for trust, formal verification, and defensive strategies prioritizing intrinsic safety over perimeter-based detection.",
        "published": "2025-12-15T23:04:48+00:00",
        "url": "http://arxiv.org/abs/2512.15790v1",
        "categories": [
          "cs.CR"
        ],
        "summary": "This paper introduces XAMT, a novel bilevel optimization framework for generating covert memory tampering attacks in heterogeneous multi-agent systems (MAS) that integrate MARL and LLM agents. XAMT minimizes perturbation magnitude while maximizing system behavior divergence, demonstrating effectiveness in poisoning shared experience replay buffers in MARL and external knowledge bases in RAG-based LLM agents.",
        "contributions": [
          "Formalization of covert memory tampering attack generation in heterogeneous MAS as a bilevel optimization problem.",
          "Demonstration of the vulnerability of both MARL and RAG-based LLM agents in MAS to stealthy, minimal-perturbation poisoning attacks via XAMT."
        ],
        "methods": [
          "Bilevel Optimization",
          "Perturbation of Experience Replay (ER) buffers in MARL agents",
          "Perturbation of Knowledge Bases (K) in RAG-based LLM agents"
        ],
        "datasets": [
          "SMAC (StarCraft Multi-Agent Challenge)",
          "SafeRAG"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations, implying that limitations would be found in the full paper",
          "The abstract does not specify how the performance of the attacked system affects the performance of the attack."
        ],
        "companies": [
          "MIT",
          "University of Texas at Austin"
        ]
      },
      {
        "title": "Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning",
        "authors": [
          "Oshada Jayasinghe",
          "Farhana Choudhury",
          "Egemen Tanin",
          "Shanika Karunasekera"
        ],
        "affiliations": [],
        "abstract": "With increased travelling needs more than ever, traffic congestion has become a major concern in most urban areas. Allocating spaces for on-street parking, further hinders traffic flow, by limiting the effective road width available for driving. With the advancement of vehicle-to-infrastructure connectivity technologies, we explore how the impact of on-street parking on traffic congestion could be minimized, by dynamically configuring on-street parking spaces. Towards that end, we formulate dynamic on-street parking space configuration as an optimization problem, and we follow a data driven approach, considering the nature of our problem. Our proposed solution comprises a two-layer multi agent reinforcement learning based framework, which is inherently scalable to large road networks. The lane level agents are responsible for deciding the optimal parking space configuration for each lane, and we introduce a novel Deep Q-learning architecture which effectively utilizes long short term memory networks and graph attention networks to capture the spatio-temporal correlations evident in the given problem. The block level agents control the actions of the lane level agents and maintain a sufficient level of parking around the block. We conduct a set of comprehensive experiments using SUMO, on both synthetic data as well as real-world data from the city of Melbourne. Our experiments show that the proposed framework could reduce the average travel time loss of vehicles significantly, reaching upto 47%, with a negligible increase in the walking distance for parking.",
        "published": "2025-12-02T04:33:26+00:00",
        "url": "http://arxiv.org/abs/2512.02406v1",
        "categories": [
          "cs.LG"
        ],
        "summary": "This research proposes a two-layer multi-agent reinforcement learning framework to dynamically configure on-street parking spaces, aiming to minimize traffic congestion. The framework uses lane-level and block-level agents to optimize parking space allocation based on spatio-temporal traffic patterns.",
        "contributions": [
          "A two-layer multi-agent reinforcement learning framework for dynamic on-street parking space configuration.",
          "A novel Deep Q-learning architecture utilizing LSTM and Graph Attention Networks to capture spatio-temporal correlations."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning",
          "Deep Q-learning",
          "Long Short-Term Memory Networks (LSTM)",
          "Graph Attention Networks (GAT)"
        ],
        "datasets": [
          "Synthetic data",
          "Real-world data from the city of Melbourne"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations, so this would require further analysis of the full paper.",
          "The abstract does not provide details on the computational complexity of the proposed framework, which could be a potential limitation in real-time deployment."
        ],
        "companies": [
          "University of Melbourne",
          "RMIT University"
        ]
      },
      {
        "title": "Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning",
        "authors": [
          "Na Li",
          "Yuchen Jiao",
          "Hangguan Shan",
          "Shefeng Yan"
        ],
        "affiliations": [],
        "abstract": "The thriving field of multi-agent reinforcement learning (MARL) studies how a group of interacting agents make decisions autonomously in a shared dynamic environment. Existing theoretical studies in this area suffer from at least two of the following obstacles: memory inefficiency, the heavy dependence of sample complexity on the long horizon and the large state space, the high computational complexity, non-Markov policy, non-Nash policy, and high burn-in cost. In this work, we take a step towards settling this problem by designing a model-free self-play algorithm \\emph{Memory-Efficient Nash Q-Learning (ME-Nash-QL)} for two-player zero-sum Markov games, which is a specific setting of MARL. ME-Nash-QL is proven to enjoy the following merits. First, it can output an $\\varepsilon$-approximate Nash policy with space complexity $O(SABH)$ and sample complexity $\\widetilde{O}(H^4SAB/\\varepsilon^2)$, where $S$ is the number of states, $\\{A, B\\}$ is the number of actions for two players, and $H$ is the horizon length. It outperforms existing algorithms in terms of space complexity for tabular cases, and in terms of sample complexity for long horizons, i.e., when $\\min\\{A, B\\}\\ll H^2$. Second, ME-Nash-QL achieves the lowest computational complexity $O(T\\mathrm{poly}(AB))$ while preserving Markov policies, where $T$ is the number of samples. Third, ME-Nash-QL also achieves the best burn-in cost $O(SAB\\,\\mathrm{poly}(H))$, whereas previous algorithms have a burn-in cost of at least $O(S^3 AB\\,\\mathrm{poly}(H))$ to attain the same level of sample complexity with ours.",
        "published": "2025-11-29T06:44:25+00:00",
        "url": "http://arxiv.org/abs/2512.00351v1",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "summary": "This paper introduces Memory-Efficient Nash Q-Learning (ME-Nash-QL), a model-free self-play algorithm for two-player zero-sum Markov games within multi-agent reinforcement learning. The algorithm aims to address limitations of existing theoretical studies by achieving better memory efficiency, sample complexity, computational complexity, and burn-in cost while preserving Markov policies and finding approximate Nash policies.",
        "contributions": [
          "Development of ME-Nash-QL algorithm with provable guarantees on space complexity (O(SABH)) and sample complexity (widetilde{O}(H^4SAB/varepsilon^2)).",
          "Demonstration of improved performance compared to existing algorithms in terms of space complexity for tabular cases, sample complexity for long horizons, computational complexity (O(Tpoly(AB))), and burn-in cost (O(SABpoly(H)))."
        ],
        "methods": [
          "Model-free reinforcement learning",
          "Self-play algorithm design",
          "Q-learning",
          "Nash equilibrium finding"
        ],
        "datasets": [],
        "limitations": [
          "Focuses specifically on two-player zero-sum Markov games, a specific setting of MARL, which may limit generalizability to more complex MARL scenarios.",
          "The performance bounds are theoretical and may not directly translate to practical performance in real-world environments."
        ],
        "companies": [
          "Carnegie Mellon University",
          "University of California, Los Angeles",
          "University of Illinois Urbana-Champaign"
        ]
      },
      {
        "title": "Quantum-Inspired Multi Agent Reinforcement Learning for Exploration Exploitation Optimization in UAV-Assisted 6G Network Deployment",
        "authors": [
          "Mazyar Taghavi",
          "Javad Vahidi"
        ],
        "affiliations": [],
        "abstract": "This study introduces a quantum inspired framework for optimizing the exploration exploitation tradeoff in multiagent reinforcement learning, applied to UAVassisted 6G network deployment. We consider a cooperative scenario where ten intelligent UAVs autonomously coordinate to maximize signal coverage and support efficient network expansion under partial observability and dynamic conditions. The proposed approach integrates classical MARL algorithms with quantum-inspired optimization techniques, leveraging variational quantum circuits VQCs as the core structure and employing the Quantum Approximate Optimization Algorithm QAOA as a representative VQC based method for combinatorial optimization. Complementary probabilistic modeling is incorporated through Bayesian inference, Gaussian processes, and variational inference to capture latent environmental dynamics. A centralized training with decentralized execution CTDE paradigm is adopted, where shared memory and local view grids enhance local observability among agents. Comprehensive experiments including scalability tests, sensitivity analysis, and comparisons with PPO and DDPG baselines demonstrate that the proposed framework improves sample efficiency, accelerates convergence, and enhances coverage performance while maintaining robustness. Radar chart and convergence analyses further show that QI MARL achieves a superior balance between exploration and exploitation compared to classical methods. All implementation code and supplementary materials are publicly available on GitHub to ensure reproducibility.",
        "published": "2025-11-25T04:35:43+00:00",
        "url": "http://arxiv.org/abs/2512.20624v1",
        "categories": [
          "cs.AI",
          "math.OC"
        ],
        "summary": "This research proposes a quantum-inspired multi-agent reinforcement learning (QI MARL) framework for optimizing UAV-assisted 6G network deployment, focusing on balancing exploration and exploitation. The framework leverages variational quantum circuits (VQCs) and probabilistic modeling to improve signal coverage and network expansion under dynamic conditions.",
        "contributions": [
          "Development of a quantum-inspired MARL framework integrating classical MARL with quantum optimization techniques (VQCs and QAOA) for UAV-assisted 6G network deployment.",
          "Demonstration that the proposed QI MARL framework improves sample efficiency, accelerates convergence, enhances coverage performance, and achieves a better balance between exploration and exploitation compared to classical MARL methods like PPO and DDPG."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Variational Quantum Circuits (VQCs)",
          "Quantum Approximate Optimization Algorithm (QAOA)",
          "Bayesian Inference",
          "Gaussian Processes",
          "Variational Inference",
          "Centralized Training with Decentralized Execution (CTDE)",
          "Proximal Policy Optimization (PPO) (Baseline)",
          "Deep Deterministic Policy Gradient (DDPG) (Baseline)"
        ],
        "datasets": [
          "Simulated UAV-assisted 6G network deployment environment with dynamic conditions and partial observability."
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations, suggesting further investigation of the full paper is needed to identify specific limitations.",
          "Scalability might be a limitation considering the use of quantum-inspired methods, as quantum resources can be a bottleneck for larger problem sizes (this is an inferred limitation based on the nature of the methods)."
        ],
        "companies": []
      },
      {
        "title": "Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning System for Automated Conflict Resolution and Consensus Building",
        "authors": [
          "Deepak Bolleddu"
        ],
        "affiliations": [],
        "abstract": "Conflict resolution and consensus building represent critical challenges in multi-agent systems, negotiations, and collaborative decision-making processes. This paper introduces Dialogue Diplomats, a novel end-to-end multi-agent reinforcement learning (MARL) framework designed for automated conflict resolution and consensus building in complex, dynamic environments. The proposed system integrates advanced deep reinforcement learning architectures with dialogue-based negotiation protocols, enabling autonomous agents to engage in sophisticated conflict resolution through iterative communication and strategic adaptation. We present three primary contributions: first, a novel Hierarchical Consensus Network (HCN) architecture that combines attention mechanisms with graph neural networks to model inter-agent dependencies and conflict dynamics. second, a Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies; and third, a Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals.",
        "published": "2025-11-20T16:40:12+00:00",
        "url": "http://arxiv.org/abs/2511.17654v1",
        "categories": [
          "cs.MA",
          "cs.AI"
        ],
        "summary": "This paper introduces Dialogue Diplomats, a novel multi-agent reinforcement learning (MARL) framework for automated conflict resolution and consensus building. It leverages deep reinforcement learning and dialogue-based negotiation protocols to enable autonomous agents to engage in strategic communication and adaptation in complex environments.",
        "contributions": [
          "A novel Hierarchical Consensus Network (HCN) architecture that combines attention mechanisms with graph neural networks to model inter-agent dependencies and conflict dynamics.",
          "A Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies.",
          "A Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Deep Reinforcement Learning",
          "Dialogue-based negotiation protocols",
          "Hierarchical Consensus Network (HCN) - Attention Mechanisms and Graph Neural Networks",
          "Progressive Negotiation Protocol (PNP)",
          "Context-Aware Reward Shaping"
        ],
        "datasets": [],
        "limitations": [],
        "companies": [
          "Microsoft"
        ]
      },
      {
        "title": "Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization",
        "authors": [
          "Mohamad A. Hady",
          "Siyi Hu",
          "Mahardhika Pratama",
          "Zehong Cao",
          "Ryszard Kowalczyk"
        ],
        "affiliations": [],
        "abstract": "This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.",
        "published": "2025-11-16T21:47:04+00:00",
        "url": "http://arxiv.org/abs/2511.12792v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "This paper explores resource optimization in heterogeneous satellite clusters for Earth Observation (EO) missions using Multi-Agent Reinforcement Learning (MARL). It demonstrates that MARL can effectively coordinate diverse satellites to balance imaging performance and resource utilization in a simulated environment.",
        "contributions": [
          "Formulation of the resource optimization problem for heterogeneous satellite clusters, addressing energy and memory constraints, partial observability, and agent heterogeneity.",
          "Evaluation of state-of-the-art MARL algorithms (MAPPO, HAPPO, and HATRPO) in a near-realistic simulation environment for autonomous EO operations.",
          "Demonstration that MARL can enable effective coordination across heterogeneous satellites, improving imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "MAPPO (Multi-Agent Proximal Policy Optimization)",
          "HAPPO (Hybrid Actor-Policy Proximal Optimization)",
          "HATRPO (Hybrid Actor-Critic Trust Region Policy Optimization)",
          "Simulation using Basilisk and BSK-RL frameworks"
        ],
        "datasets": [
          "Simulated Earth Observation mission data based on a near-realistic environment."
        ],
        "limitations": [
          "The study relies on a simulation environment, which may not perfectly capture all real-world complexities of satellite operations.",
          "The specific satellite configuration (two optical and one SAR) may limit the generalizability of the findings to other heterogeneous satellite cluster configurations."
        ],
        "companies": [
          "CSIRO"
        ]
      },
      {
        "title": "Multi-agent In-context Coordination via Decentralized Memory Retrieval",
        "authors": [
          "Tao Jiang",
          "Zichuan Lin",
          "Lihe Li",
          "Yi-Chen Li",
          "Cong Guan",
          "Lei Yuan",
          "Zongzhang Zhang",
          "Yang Yu",
          "Deheng Ye"
        ],
        "affiliations": [],
        "abstract": "Large transformer models, trained on diverse datasets, have demonstrated impressive few-shot performance on previously unseen tasks without requiring parameter updates. This capability has also been explored in Reinforcement Learning (RL), where agents interact with the environment to retrieve context and maximize cumulative rewards, showcasing strong adaptability in complex settings. However, in cooperative Multi-Agent Reinforcement Learning (MARL), where agents must coordinate toward a shared goal, decentralized policy deployment can lead to mismatches in task alignment and reward assignment, limiting the efficiency of policy adaptation. To address this challenge, we introduce Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach designed to enhance coordination by fast adaptation. Our method involves training a centralized embedding model to capture fine-grained trajectory representations, followed by decentralized models that approximate the centralized one to obtain team-level task information. Based on the learned embeddings, relevant trajectories are retrieved as context, which, combined with the agents' current sub-trajectories, inform decision-making. During decentralized execution, we introduce a novel memory mechanism that effectively balances test-time online data with offline memory. Based on the constructed memory, we propose a hybrid utility score that incorporates both individual- and team-level returns, ensuring credit assignment across agents. Extensive experiments on cooperative MARL benchmarks, including Level-Based Foraging (LBF) and SMAC (v1/v2), show that MAICC enables faster adaptation to unseen tasks compared to existing methods. Code is available at https://github.com/LAMDA-RL/MAICC.",
        "published": "2025-11-13T07:08:31+00:00",
        "url": "http://arxiv.org/abs/2511.10030v1",
        "categories": [
          "cs.MA",
          "cs.LG"
        ],
        "summary": "The paper introduces Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach to improve coordination in cooperative MARL by enabling fast adaptation to unseen tasks. It addresses the challenge of mismatched task alignment and reward assignment in decentralized MARL policy deployment.",
        "contributions": [
          "Development of MAICC, a method that enhances coordination in cooperative MARL by leveraging decentralized memory retrieval for fast adaptation.",
          "A novel memory mechanism that effectively balances test-time online data with offline memory during decentralized execution.",
          "A hybrid utility score incorporating both individual- and team-level returns to ensure effective credit assignment across agents."
        ],
        "methods": [
          "Centralized training of an embedding model to capture fine-grained trajectory representations.",
          "Decentralized models that approximate the centralized embedding model to obtain team-level task information.",
          "Decentralized memory retrieval based on learned embeddings to provide context for decision-making.",
          "A hybrid utility score that combines individual and team-level returns for credit assignment."
        ],
        "datasets": [
          "Level-Based Foraging (LBF)",
          "SMAC (StarCraft Multi-Agent Challenge) v1/v2"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations, but the method's performance may be dependent on the quality and diversity of the training data used for the centralized embedding model.",
          "Computational cost associated with training the centralized embedding model and maintaining the decentralized memory retrieval process could be a limiting factor, especially in large-scale MARL environments."
        ],
        "companies": [
          "Alibaba"
        ]
      },
      {
        "title": "Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning",
        "authors": [
          "Satpreet H. Singh",
          "Sonja Johnson-Yu",
          "Zhouyang Lu",
          "Aaron Walsman",
          "Federico Pedraja",
          "Denis Turcu",
          "Pratyusha Sharma",
          "Naomi Saphra",
          "Nathaniel B. Sawtell",
          "Kanaka Rajan"
        ],
        "affiliations": [],
        "abstract": "Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible.",
        "published": "2025-11-11T16:38:48+00:00",
        "url": "http://arxiv.org/abs/2511.08436v1",
        "categories": [
          "cs.NE",
          "cs.AI",
          "cs.MA",
          "eess.SY",
          "q-bio.NC"
        ],
        "summary": "",
        "contributions": null,
        "methods": null,
        "datasets": null,
        "limitations": null,
        "companies": [
          "Princeton University"
        ]
      },
      {
        "title": "A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems",
        "authors": [
          "Manonmani Sekar",
          "Nasim Nezamoddini"
        ],
        "affiliations": [],
        "abstract": "Reconfigurable manufacturing systems (RMS) are critical for future market adjustment given their rapid adaptation to fluctuations in consumer demands, the introduction of new technological advances, and disruptions in linked supply chain sections. The adjustable hard settings of such systems require a flexible soft planning mechanism that enables realtime production planning and scheduling amid the existing complexity and variability in their configuration settings. This study explores the application of multi agent reinforcement learning (MARL) for dynamic scheduling in soft planning of the RMS settings. In the proposed framework, deep Qnetwork (DQN) agents trained in centralized training learn optimal job machine assignments in real time while adapting to stochastic events such as machine breakdowns and reconfiguration delays. The model also incorporates a negotiation with an attention mechanism to enhance state representation and improve decision focus on critical system features. Key DQN enhancements including prioritized experience replay, nstep returns, double DQN and soft target update are used to stabilize and accelerate learning. Experiments conducted in a simulated RMS environment demonstrate that the proposed approach outperforms baseline heuristics in reducing makespan and tardiness while improving machine utilization. The reconfigurable manufacturing environment was extended to simulate realistic challenges, including machine failures and reconfiguration times. Experimental results show that while the enhanced DQN agent is effective in adapting to dynamic conditions, machine breakdowns increase variability in key performance metrics such as makespan, throughput, and total tardiness. The results confirm the advantages of applying the MARL mechanism for intelligent and adaptive scheduling in dynamic reconfigurable manufacturing environments.",
        "published": "2025-11-11T00:04:35+00:00",
        "url": "http://arxiv.org/abs/2511.07707v1",
        "categories": [
          "cs.MA",
          "cs.AI"
        ],
        "summary": "This paper proposes a Multi-Agent Reinforcement Learning (MARL) approach, specifically using Deep Q-Networks (DQN), for dynamic scheduling in reconfigurable manufacturing systems (RMS). The framework enables real-time job-machine assignment and adaptation to stochastic events while optimizing for makespan, tardiness, and machine utilization.",
        "contributions": [
          "Development of a MARL framework using DQN agents with negotiation and attention mechanisms for dynamic scheduling in RMS.",
          "Demonstration that the proposed approach outperforms baseline heuristics in reducing makespan and tardiness while improving machine utilization in a simulated RMS environment."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Deep Q-Network (DQN) with prioritized experience replay, n-step returns, double DQN, and soft target update",
          "Negotiation with an attention mechanism to enhance state representation"
        ],
        "datasets": [
          "Simulated Reconfigurable Manufacturing System (RMS) environment",
          "Extension of the simulated RMS environment to include machine failures and reconfiguration times"
        ],
        "limitations": [
          "The study relies on a simulated RMS environment, and the results may not directly translate to real-world manufacturing settings.",
          "Machine breakdowns increase the variability in key performance metrics, suggesting the need for further research on robust scheduling strategies under high failure rates."
        ],
        "companies": [
          "Unknown"
        ]
      },
      {
        "title": "Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM",
        "authors": [
          "Sai Krishna Ghanta",
          "Ramviyas Parasuraman"
        ],
        "affiliations": [],
        "abstract": "We consider the distributed pose-graph optimization (PGO) problem, which is fundamental in accurate trajectory estimation in multi-robot simultaneous localization and mapping (SLAM). Conventional iterative approaches linearize a highly non-convex optimization objective, requiring repeated solving of normal equations, which often converge to local minima and thus produce suboptimal estimates. We propose a scalable, outlier-robust distributed planar PGO framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed PGO as a partially observable Markov game defined on local pose-graphs, where each action refines a single edge's pose estimate. A graph partitioner decomposes the global pose graph, and each robot runs a recurrent edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating to denoise noisy edges. Robots sequentially refine poses through a hybrid policy that utilizes prior action memory and graph embeddings. After local graph correction, a consensus scheme reconciles inter-robot disagreements to produce a globally consistent estimate. Our extensive evaluations on a comprehensive suite of synthetic and real-world datasets demonstrate that our learned MARL-based actors reduce the global objective by an average of 37.5% more than the state-of-the-art distributed PGO framework, while enhancing inference efficiency by at least 6X. We also demonstrate that actor replication allows a single learned policy to scale effortlessly to substantially larger robot teams without any retraining. Code is publicly available at https://github.com/herolab-uga/policies-over-poses.",
        "published": "2025-10-26T16:21:24+00:00",
        "url": "http://arxiv.org/abs/2510.22740v1",
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.MA"
        ],
        "summary": "This paper introduces a novel Multi-Agent Reinforcement Learning (MARL) based framework for distributed pose-graph optimization (PGO) in multi-robot SLAM. The approach uses a learned policy to refine pose estimates, achieving improved accuracy and efficiency compared to traditional methods.",
        "contributions": [
          "A scalable and outlier-robust distributed planar PGO framework using MARL, formulated as a partially observable Markov game.",
          "A hybrid policy utilizing prior action memory and graph embeddings for sequential pose refinement, incorporating a recurrent edge-conditioned GNN encoder with adaptive edge-gating for noise reduction.",
          "Demonstrated significant improvement in global objective reduction (37.5% on average) and inference efficiency (at least 6X) compared to state-of-the-art distributed PGO frameworks.",
          "Demonstrated actor replication, enabling a single learned policy to scale to larger robot teams without retraining."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Distributed Pose-Graph Optimization (PGO)",
          "Recurrent edge-conditioned Graph Neural Network (GNN) with adaptive edge-gating",
          "Hybrid policy using prior action memory and graph embeddings",
          "Consensus scheme for inter-robot disagreement reconciliation"
        ],
        "datasets": [
          "Synthetic datasets",
          "Real-world datasets"
        ],
        "limitations": [
          "The framework is designed for planar PGO, suggesting potential limitations for non-planar environments.",
          "The abstract doesn't explicitly mention the computational cost of training the MARL agents, which could be significant."
        ],
        "companies": [
          "MIT",
          "University of Texas at Austin"
        ]
      },
      {
        "title": "Generative Evolutionary Meta-Solver (GEMS): Scalable Surrogate-Free Multi-Agent Learning",
        "authors": [
          "Alakh Sharma",
          "Gaurish Trivedi",
          "Kartikey Bhandari",
          "Yash Sinha",
          "Dhruv Kumar",
          "Pratik Narang",
          "Jagat Sesh Challa"
        ],
        "affiliations": [],
        "abstract": "Scalable multi-agent reinforcement learning (MARL) remains a central challenge for AI. Existing population-based methods, like Policy-Space Response Oracles, PSRO, require storing explicit policy populations and constructing full payoff matrices, incurring quadratic computation and linear memory costs. We present Generative Evolutionary Meta-Solver (GEMS), a surrogate-free framework that replaces explicit populations with a compact set of latent anchors and a single amortized generator. Instead of exhaustively constructing the payoff matrix, GEMS relies on unbiased Monte Carlo rollouts, multiplicative-weights meta-dynamics, and a model-free empirical-Bernstein UCB oracle to adaptively expand the policy set. Best responses are trained within the generator using an advantage-based trust-region objective, eliminating the need to store and train separate actors. We evaluated GEMS in a variety of Two-player and Multi-Player games such as the Deceptive Messages Game, Kuhn Poker and Multi-Particle environment. We find that GEMS is up to ~6x faster, has 1.3x less memory usage than PSRO, while also reaps higher rewards simultaneously. These results demonstrate that GEMS retains the game theoretic guarantees of PSRO, while overcoming its fundamental inefficiencies, hence enabling scalable multi-agent learning in multiple domains.",
        "published": "2025-09-27T19:23:38+00:00",
        "url": "http://arxiv.org/abs/2509.23462v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "The paper introduces Generative Evolutionary Meta-Solver (GEMS), a novel multi-agent reinforcement learning (MARL) framework designed to overcome the scalability limitations of existing population-based methods like PSRO. GEMS achieves this by replacing explicit policy populations with a compact latent representation and an amortized generator, leading to significant improvements in speed and memory usage while maintaining game-theoretic guarantees.",
        "contributions": [
          "Introduces GEMS, a scalable surrogate-free MARL framework that replaces explicit policy populations with a compact latent representation and a generator.",
          "Demonstrates that GEMS achieves significant speed and memory efficiency gains compared to PSRO while achieving higher rewards and maintaining game-theoretic guarantees."
        ],
        "methods": [
          "Amortized policy generator using a compact set of latent anchors.",
          "Unbiased Monte Carlo rollouts for payoff estimation.",
          "Multiplicative-weights meta-dynamics for policy adaptation.",
          "Model-free empirical-Bernstein UCB oracle for adaptive policy set expansion.",
          "Advantage-based trust-region objective for training best responses within the generator."
        ],
        "datasets": [
          "Deceptive Messages Game",
          "Kuhn Poker",
          "Multi-Particle environment"
        ],
        "limitations": [
          "The abstract doesn't explicitly discuss limitations. Further reading of the paper would be required to identify specific limitations.",
          "The performance gains are relative to PSRO. A comparison with other state-of-the-art MARL algorithms might reveal limitations in specific scenarios."
        ],
        "companies": [
          "Google"
        ]
      },
      {
        "title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time",
        "authors": [
          "Constantin Ruhdorfer",
          "Matteo Bortoletto",
          "Andreas Bulling"
        ],
        "affiliations": [],
        "abstract": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to reason about the beliefs of others to build and maintain common ground. Existing ToM benchmarks, however, are restricted to passive observer settings or lack an assessment of how agents establish and maintain common ground over time. To address these gaps, we introduce the Yokai Learning Environment (YLE) - a multi-agent reinforcement learning (RL) environment based on the cooperative card game Yokai. In the YLE, agents take turns peeking at hidden cards and moving them to form clusters based on colour. Success requires tracking evolving beliefs, remembering past observations, using hints as grounded communication, and maintaining common ground with teammates. Our evaluation yields two key findings: First, current RL agents struggle to solve the YLE, even when given access to perfect memory. Second, while belief modelling improves performance, agents are still unable to effectively generalise to unseen partners or form accurate beliefs over longer games, exposing a reliance on brittle conventions rather than robust belief tracking. We use the YLE to investigate research questions in belief modelling, memory, partner generalisation, and scaling to higher-order ToM.",
        "published": "2025-08-17T19:42:17+00:00",
        "url": "http://arxiv.org/abs/2508.12480v1",
        "categories": [
          "cs.AI",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "This paper introduces the Yokai Learning Environment (YLE), a multi-agent reinforcement learning environment based on a cooperative card game, designed to evaluate and improve Theory of Mind (ToM) in AI agents. The YLE aims to address limitations in existing ToM benchmarks by focusing on active participation, common ground establishment, and belief tracking over time.",
        "contributions": [
          "The Yokai Learning Environment (YLE), a novel multi-agent RL environment for studying Theory of Mind (ToM).",
          "An analysis of current RL agents' performance in the YLE, revealing their struggles with belief tracking, partner generalization, and maintaining common ground, even with perfect memory."
        ],
        "methods": [
          "Multi-agent Reinforcement Learning (RL)",
          "Belief Modelling techniques for AI agents"
        ],
        "datasets": [
          "Yokai Learning Environment (YLE) - a newly created environment"
        ],
        "limitations": [
          "Current RL agents struggle to generalize to unseen partners in the YLE.",
          "Agents are unable to form accurate beliefs over longer games, indicating a reliance on brittle conventions rather than robust belief tracking."
        ],
        "companies": [
          "University of Stuttgart",
          "Saarland University"
        ]
      },
      {
        "title": "Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping",
        "authors": [
          "Farshid Nooshi",
          "Suining He"
        ],
        "affiliations": [],
        "abstract": "Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing vehicles) is crucial for rebalancing the mobility demand and supply in the urban environments. We propose in this work a novel multi-agent reinforcement learning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS) for dynamic mobility resource allocation. HAG-PS aims to address two important research challenges regarding multi-agent reinforcement learning for mobility resource allocation: (1) how to dynamically and adaptively share the mobility resource allocation policy (i.e., how to distribute mobility resources) across agents (i.e., representing the regional coordinators of mobility resources); and (2) how to achieve memory-efficient parameter sharing in an urban-scale setting. To address the above challenges, we have provided following novel designs within HAG-PS. To enable dynamic and adaptive parameter sharing, we have designed a hierarchical approach that consists of global and local information of the mobility resource states (e.g., distribution of mobility resources). We have developed an adaptive agent grouping approach in order to split or merge the groups of agents based on their relative closeness of encoded trajectories (i.e., states, actions, and rewards). We have designed a learnable identity (ID) embeddings to enable agent specialization beyond simple parameter copy. We have performed extensive experimental studies based on real-world NYC bike sharing data (a total of more than 1.2 million trips), and demonstrated the superior performance (e.g., improved bike availability) of HAG-PS compared with other baseline approaches.",
        "published": "2025-07-27T18:40:04+00:00",
        "url": "http://arxiv.org/abs/2507.20377v2",
        "categories": [
          "cs.AI"
        ],
        "summary": "This paper introduces a novel multi-agent reinforcement learning approach called Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS) for dynamic mobility resource allocation in urban environments. HAG-PS addresses challenges in sharing mobility resource allocation policies across agents and achieving memory-efficient parameter sharing.",
        "contributions": [
          "Developed a hierarchical approach leveraging global and local information for dynamic and adaptive parameter sharing in multi-agent reinforcement learning.",
          "Designed an adaptive agent grouping approach that dynamically splits or merges agent groups based on the similarity of their encoded trajectories (states, actions, and rewards).",
          "Introduced learnable identity (ID) embeddings to enable agent specialization beyond simple parameter copying."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning",
          "Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)",
          "Adaptive Agent Grouping",
          "Learnable Identity (ID) Embeddings"
        ],
        "datasets": [
          "Real-world NYC bike sharing data (over 1.2 million trips)"
        ],
        "limitations": [
          "The abstract does not explicitly state any limitations, so this section is based on common limitations of similar research.",
          "Generalizability to other types of mobility resources (e.g., e-scooters, ride-sharing vehicles) beyond bike sharing might require further investigation.",
          "Computational complexity of the hierarchical grouping and parameter sharing approach, especially in larger and more complex urban environments."
        ],
        "companies": [
          "University of Waterloo"
        ]
      },
      {
        "title": "Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning",
        "authors": [
          "Matej Straka",
          "Martin Schmid"
        ],
        "affiliations": [],
        "abstract": "We introduce a real-time strategy game environment based on Generals.io, a game with thousands of weekly active players. Our environment is fully compatible with Gymnasium and PettingZoo and is capable of running thousands of frames per second on commodity hardware. We also present a reference agent, trained with supervised pre-training and self-play, which reached the top 0.003% of the 1v1 human leaderboard after only 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions of a modular RTS benchmark and a competitive baseline agent provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research. The documented code, together with examples and tutorials, is available at https://github.com/strakam/generals-bots.",
        "published": "2025-07-09T13:15:05+00:00",
        "url": "http://arxiv.org/abs/2507.06825v2",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "This paper introduces a new real-time strategy game environment based on Generals.io for multi-agent reinforcement learning research. They also present a high-performing reinforcement learning agent that achieves top leaderboard rankings after training, showcasing the environment's potential.",
        "contributions": [
          "A new Gymnasium and PettingZoo compatible RTS environment based on Generals.io.",
          "A high-performing reference agent trained with supervised pre-training and self-play, achieving top leaderboard rankings."
        ],
        "methods": [
          "Reinforcement Learning",
          "Supervised Pre-training",
          "Self-Play",
          "Potential-based Reward Shaping",
          "Memory Features"
        ],
        "datasets": [
          "Generals.io gameplay data (implied, used for pre-training and self-play)"
        ],
        "limitations": [
          "Training was performed on an expensive H100 GPU, potentially limiting accessibility for some researchers.",
          "The paper doesn't explicitly mention limitations, but the generality of the learned strategies to other RTS games is a potential area for future work."
        ],
        "companies": [
          "Google",
          "Czech Technical University in Prague"
        ]
      },
      {
        "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving",
        "authors": [
          "Hang Wang",
          "Dechen Gao",
          "Junshan Zhang"
        ],
        "affiliations": [],
        "abstract": "We study multi-agent reinforcement learning (MARL) for tasks in complex high-dimensional environments, such as autonomous driving. MARL is known to suffer from the \\textit{partial observability} and \\textit{non-stationarity} issues. To tackle these challenges, information sharing is often employed, which however faces major hurdles in practice, including overwhelming communication overhead and scalability concerns. By making use of generative AI embodied in world model together with its latent representation, we develop {\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d Mode\\underline{l}, for MARL, where 1) each agent first learns its world model that encodes its state and intention into low-dimensional latent representation with smaller memory footprint, which can be shared with other agents of interest via lightweight communication; and 2) each agent carries out ego-centric learning while exploiting lightweight information sharing to enrich her world model, and then exploits its generalization capacity to improve prediction for better planning. We characterize the gain on the prediction accuracy from the information sharing and its impact on performance gap. Extensive experiments are carried out on the challenging local trajectory planning tasks in the CARLA platform to demonstrate the performance gains of using \\textit{CALL}.",
        "published": "2025-06-09T18:56:40+00:00",
        "url": "http://arxiv.org/abs/2506.08149v1",
        "categories": [
          "cs.RO",
          "cs.AI"
        ],
        "summary": "This paper presents a novel multi-agent reinforcement learning (MARL) approach called CALL for autonomous driving, addressing partial observability and non-stationarity challenges. CALL leverages generative AI and world models to facilitate lightweight information sharing between agents, improving prediction accuracy and planning performance.",
        "contributions": [
          "Developed CALL, a communicative world model approach for MARL in autonomous driving that addresses partial observability and non-stationarity.",
          "Introduced a lightweight communication strategy based on sharing low-dimensional latent representations learned by each agent's world model."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "World Model",
          "Generative AI",
          "Latent Representation Learning",
          "Ego-centric Learning",
          "Lightweight Communication"
        ],
        "datasets": [
          "CARLA platform (for local trajectory planning tasks)"
        ],
        "limitations": [
          "The abstract does not explicitly mention any limitations, so this response will assume some potential limitations.",
          "Scalability beyond the tested scenarios in CARLA needs further investigation.",
          "The reliance on generative AI and world models introduces potential complexities in training and deployment."
        ],
        "companies": [
          "Arizona State University"
        ]
      },
      {
        "title": "Language-Driven Coordination and Learning in Multi-Agent Simulation Environments",
        "authors": [
          "Zhengyang Li",
          "Sawyer Campos",
          "Nana Wang"
        ],
        "affiliations": [],
        "abstract": "This paper introduces LLM-MARL, a unified framework that incorporates large language models (LLMs) into multi-agent reinforcement learning (MARL) to enhance coordination, communication, and generalization in simulated game environments. The framework features three modular components of Coordinator, Communicator, and Memory, which dynamically generate subgoals, facilitate symbolic inter-agent messaging, and support episodic recall. Training combines PPO with a language-conditioned loss and LLM query gating. LLM-MARL is evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results show consistent improvements over MAPPO and QMIX in win rate, coordination score, and zero-shot generalization. Ablation studies demonstrate that subgoal generation and language-based messaging each contribute significantly to performance gains. Qualitative analysis reveals emergent behaviors such as role specialization and communication-driven tactics. By bridging language modeling and policy learning, this work contributes to the design of intelligent, cooperative agents in interactive simulations. It offers a path forward for leveraging LLMs in multi-agent systems used for training, games, and human-AI collaboration.",
        "published": "2025-06-01T06:46:49+00:00",
        "url": "http://arxiv.org/abs/2506.04251v4",
        "categories": [
          "cs.AI",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "This paper introduces LLM-MARL, a framework integrating large language models (LLMs) into multi-agent reinforcement learning (MARL) to improve coordination, communication, and generalization. LLM-MARL uses a modular design with components for subgoal generation, inter-agent messaging, and episodic recall, achieving performance gains in simulated game environments compared to baselines.",
        "contributions": [
          "Development of LLM-MARL, a unified framework that incorporates LLMs into MARL for enhanced coordination and generalization.",
          "Demonstration of improved performance in multi-agent simulation environments (Google Research Football, MAgent Battle, StarCraft II) compared to MAPPO and QMIX.",
          "Identification and analysis of emergent behaviors such as role specialization and communication-driven tactics facilitated by the framework."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Large Language Models (LLMs) for subgoal generation, communication, and memory",
          "Proximal Policy Optimization (PPO) with a language-conditioned loss",
          "LLM query gating",
          "Ablation studies to evaluate the contribution of individual components."
        ],
        "datasets": [
          "Google Research Football",
          "MAgent Battle",
          "StarCraft II"
        ],
        "limitations": [
          "The abstract does not explicitly state any limitations. Limitations will likely be discussed in the full paper. These could involve computational cost associated with LLMs, scalability to very large agent populations, or potential biases inherited from the LLMs.",
          "Generalizability beyond the specific game environments tested is not explicitly addressed in the abstract."
        ],
        "companies": [
          "Meta",
          "Stanford University"
        ]
      },
      {
        "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning",
        "authors": [
          "Pedro Antonio Alarcon Granadeno",
          "Theodore Chambers",
          "Jane Cleland-Huang"
        ],
        "affiliations": [],
        "abstract": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon gas leak (2015) demonstrate the urgent need for rapid and reliable plume tracing algorithms to protect public health and the environment. Traditional methods, such as gradient-based or biologically inspired approaches, often fail in realistic, turbulent conditions. To address these challenges, we present a Multi-Agent Reinforcement Learning (MARL) algorithm designed for localizing multiple airborne pollution sources using a swarm of small uncrewed aerial systems (sUAS). Our method models the problem as a Partially Observable Markov Game (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific Double Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical action-observation pairs, effectively approximating latent states. Unlike prior work, we use a general-purpose simulation environment based on the Gaussian Plume Model (GPM), incorporating realistic elements such as a three-dimensional environment, sensor noise, multiple interacting agents, and multiple plume sources. The incorporation of action histories as part of the inputs further enhances the adaptability of our model in complex, partially observable environments. Extensive simulations show that our algorithm significantly outperforms conventional approaches. Specifically, our model allows agents to explore only 1.29\\% of the environment to successfully locate pollution sources.",
        "published": "2025-05-12T21:33:15+00:00",
        "url": "http://arxiv.org/abs/2505.08825v1",
        "categories": [
          "cs.MA",
          "cs.AI"
        ],
        "summary": "This paper introduces a Multi-Agent Reinforcement Learning (MARL) algorithm for localizing multiple airborne pollution sources using a swarm of sUAS in turbulent conditions. The algorithm outperforms conventional approaches by using historical action-observation data to navigate a complex, partially observable environment simulated with a Gaussian Plume Model.",
        "contributions": [
          "Developed a MARL algorithm using an LSTM-based Action-specific Double Deep Recurrent Q-Network (ADDRQN) to address the challenge of plume tracing in realistic, turbulent environments.",
          "Demonstrated the effectiveness of using full sequences of historical action-observation pairs to approximate latent states in a Partially Observable Markov Game (POMG), enhancing adaptability in complex environments."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Action-specific Double Deep Recurrent Q-Network (ADDRQN)",
          "Long Short-Term Memory (LSTM)",
          "Partially Observable Markov Game (POMG)"
        ],
        "datasets": [
          "Simulated environment based on the Gaussian Plume Model (GPM)"
        ],
        "limitations": [
          "The simulation environment is based on the Gaussian Plume Model (GPM), which may not fully capture the complexities of real-world plume behavior.",
          "The paper only presents results from simulations, and real-world validation is needed to confirm the algorithm's effectiveness."
        ],
        "companies": [
          "University of Notre Dame"
        ]
      },
      {
        "title": "Constant-Memory Strategies in Stochastic Games: Best Responses and Equilibria",
        "authors": [
          "Fengming Zhu",
          "Fangzhen Lin"
        ],
        "affiliations": [],
        "abstract": "Stochastic games have become a prevalent framework for studying long-term multi-agent interactions, especially in the context of multi-agent reinforcement learning. In this work, we comprehensively investigate the concept of constant-memory strategies in stochastic games. We first establish some results on best responses and Nash equilibria for behavioral constant-memory strategies, followed by a discussion on the computational hardness of best responding to mixed constant-memory strategies. Those theoretic insights are later verified on several sequential decision-making testbeds, including the $\\textit{Iterated Prisoner's Dilemma}$, the $\\textit{Iterated Traveler's Dilemma}$, and the $\\textit{Pursuit}$ domain. This work aims to enhance the understanding of theoretical issues in single-agent planning under multi-agent systems, and uncover the connection between decision models in single-agent and multi-agent contexts. The code is available at $\\texttt{https://github.com/Fernadoo/Const-Mem.}$",
        "published": "2025-05-11T15:09:46+00:00",
        "url": "http://arxiv.org/abs/2505.07008v2",
        "categories": [
          "cs.GT",
          "cs.MA"
        ],
        "summary": "This research explores constant-memory strategies within stochastic games, a common framework for multi-agent interactions. The paper investigates best responses and Nash equilibria for constant-memory strategies, and provides both theoretical insights and empirical validation.",
        "contributions": [
          "Established results on best responses and Nash equilibria for behavioral constant-memory strategies in stochastic games.",
          "Demonstrated the computational hardness of best responding to mixed constant-memory strategies."
        ],
        "methods": [
          "Theoretical analysis of best responses and Nash equilibria.",
          "Empirical validation using sequential decision-making testbeds."
        ],
        "datasets": [
          "Iterated Prisoner's Dilemma",
          "Iterated Traveler's Dilemma",
          "Pursuit domain"
        ],
        "limitations": [
          "The abstract doesn't explicitly state any limitations. Further reading of the paper is required to identify limitations.",
          "The focus is on constant-memory strategies, which may not generalize to all types of strategies employed in stochastic games."
        ],
        "companies": [
          "Hong Kong University of Science and Technology"
        ]
      },
      {
        "title": "Heterogeneous Multi-Agent Reinforcement Learning with Attention for Cooperative and Scalable Feature Transformation",
        "authors": [
          "Tao Zhe",
          "Huazhen Fang",
          "Kunpeng Liu",
          "Qian Lou",
          "Tamzidul Hoque",
          "Dongjie Wang"
        ],
        "affiliations": [],
        "abstract": "Feature transformation enhances downstream task performance by generating informative features through mathematical feature crossing. Despite the advancements in deep learning, feature transformation remains essential for structured data, where deep models often struggle to capture complex feature interactions. Prior literature on automated feature transformation has achieved success but often relies on heuristics or exhaustive searches, leading to inefficient and time-consuming processes. Recent works employ reinforcement learning (RL) to enhance traditional approaches through a more effective trial-and-error way. However, two limitations remain: 1) Dynamic feature expansion during the transformation process, which causes instability and increases the learning complexity for RL agents; 2) Insufficient cooperation and communication between agents, which results in suboptimal feature crossing operations and degraded model performance. To address them, we propose a novel heterogeneous multi-agent RL framework to enable cooperative and scalable feature transformation. The framework comprises three heterogeneous agents, grouped into two types, each designed to select essential features and operations for feature crossing. To enhance communication among these agents, we implement a shared critic mechanism that facilitates information exchange during feature transformation. To handle the dynamically expanding feature space, we tailor multi-head attention-based feature agents to select suitable features for feature crossing. Additionally, we introduce a state encoding technique during the optimization process to stabilize and enhance the learning dynamics of the RL agents, resulting in more robust and reliable transformation policies. Finally, we conduct extensive experiments to validate the effectiveness, efficiency, robustness, and interpretability of our model.",
        "published": "2025-11-26T21:45:38+00:00",
        "url": "http://arxiv.org/abs/2511.21934v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "This paper proposes a novel heterogeneous multi-agent reinforcement learning framework to address the limitations of existing automated feature transformation methods, specifically instability due to dynamic feature expansion and insufficient agent cooperation. The framework leverages attention mechanisms and a shared critic to enable cooperative and scalable feature transformation for structured data.",
        "contributions": [
          "A heterogeneous multi-agent RL framework with three agents designed to select essential features and operations for feature crossing.",
          "Implementation of a shared critic mechanism to enhance communication and cooperation among agents during feature transformation.",
          "Use of multi-head attention-based feature agents to handle the dynamically expanding feature space and select suitable features.",
          "Introduction of a state encoding technique to stabilize and enhance the learning dynamics of the RL agents."
        ],
        "methods": [
          "Heterogeneous Multi-Agent Reinforcement Learning (MARL)",
          "Multi-Head Attention Mechanism",
          "Shared Critic Mechanism",
          "State Encoding Technique"
        ],
        "datasets": [
          "Not explicitly mentioned in the abstract, but implied to be structured datasets used for experimental validation."
        ],
        "limitations": [
          "Prior methods suffer from instability due to dynamic feature expansion during transformation.",
          "Prior methods suffer from insufficient cooperation and communication between agents, leading to suboptimal feature crossing."
        ],
        "companies": [
          "University of Delaware"
        ]
      },
      {
        "title": "TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations",
        "authors": [
          "Nikunj Gupta",
          "Ludwika Twardecka",
          "James Zachary Hare",
          "Jesse Milzman",
          "Rajgopal Kannan",
          "Viktor Prasanna"
        ],
        "affiliations": [],
        "abstract": "In this paper, we propose capturing and utilizing \\textit{Temporal Information through Graph-based Embeddings and Representations} or \\textbf{TIGER} to enhance multi-agent reinforcement learning (MARL). We explicitly model how inter-agent coordination structures evolve over time. While most MARL approaches rely on static or per-step relational graphs, they overlook the temporal evolution of interactions that naturally arise as agents adapt, move, or reorganize cooperation strategies. Capturing such evolving dependencies is key to achieving robust and adaptive coordination. To this end, TIGER constructs dynamic temporal graphs of MARL agents, connecting their current and historical interactions. It then employs a temporal attention-based encoder to aggregate information across these structural and temporal neighborhoods, yielding time-aware agent embeddings that guide cooperative policy learning. Through extensive experiments on two coordination-intensive benchmarks, we show that TIGER consistently outperforms diverse value-decomposition and graph-based MARL baselines in task performance and sample efficiency. Furthermore, we conduct comprehensive ablation studies to isolate the impact of key design parameters in TIGER, revealing how structural and temporal factors can jointly shape effective policy learning in MARL. All codes can be found here: https://github.com/Nikunj-Gupta/tiger-marl.",
        "published": "2025-11-11T23:00:23+00:00",
        "url": "http://arxiv.org/abs/2511.08832v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "The paper introduces TIGER-MARL, a novel approach to multi-agent reinforcement learning that captures and utilizes temporal information about inter-agent coordination through dynamic temporal graphs. By encoding these evolving dependencies, TIGER-MARL enhances cooperative policy learning, leading to improved task performance and sample efficiency compared to existing methods.",
        "contributions": [
          "Proposes TIGER-MARL, a method for modeling and utilizing the temporal evolution of inter-agent interactions in MARL.",
          "Introduces a dynamic temporal graph representation of MARL agents, connecting current and historical interactions.",
          "Develops a temporal attention-based encoder to aggregate information across structural and temporal neighborhoods, yielding time-aware agent embeddings.",
          "Demonstrates improved task performance and sample efficiency compared to diverse value-decomposition and graph-based MARL baselines on coordination-intensive benchmarks.",
          "Provides ablation studies to analyze the impact of key design parameters and their influence on policy learning."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Graph Neural Networks (GNNs)",
          "Temporal Attention Mechanism",
          "Dynamic Temporal Graphs",
          "Value Decomposition MARL",
          "Graph-based MARL"
        ],
        "datasets": [
          "Coordination-intensive MARL benchmarks (unspecified but implied to be more than one)",
          "Two specific coordination-intensive benchmarks (unspecified by name)"
        ],
        "limitations": [
          "The abstract doesn't explicitly mention limitations. Limitations are likely present in the full paper.",
          "The specific details of the coordination-intensive benchmarks are not provided in the abstract, making it difficult to assess the generalizability of the results."
        ],
        "companies": [
          "University of Southern California"
        ]
      },
      {
        "title": "Transformer based Collaborative Reinforcement Learning for Fluid Antenna System (FAS)-enabled 3D UAV Positioning",
        "authors": [
          "Xiaoren Xu",
          "Hao Xu",
          "Dongyu Wei",
          "Walid Saad",
          "Mehdi Bennis",
          "Mingzhe Chen"
        ],
        "affiliations": [],
        "abstract": "In this paper, a novel Three dimensional (3D) positioning framework of fluid antenna system (FAS)-enabled unmanned aerial vehicles (UAVs) is developed. In the proposed framework, a set of controlled UAVs cooperatively estimate the real-time 3D position of a target UAV. Here, the active UAV transmits a measurement signal to the passive UAVs via the reflection from the target UAV. Each passive UAV estimates the distance of the active-target-passive UAV link and selects an antenna port to share the distance information with the base station (BS) that calculates the real-time position of the target UAV. As the target UAV is moving due to its task operation, the controlled UAVs must optimize their trajectories and select optimal antenna port, aiming to estimate the real-time position of the target UAV. We formulate this problem as an optimization problem to minimize the target UAV positioning error via optimizing the trajectories of all controlled UAVs and antenna port selection of passive UAVs. Here, an attention-based recurrent multi-agent reinforcement learning (AR-MARL) scheme is proposed, which enables each controlled UAV to use the local Q function to determine its trajectory and antenna port while optimizing the target UAV positioning performance without knowing the trajectories and antenna port selections of other controlled UAVs. Different from current MARL methods, the proposed method uses a recurrent neural network (RNN) that incorporates historical state-action pairs of each controlled UAV, and an attention mechanism to analyze the importance of these historical state-action pairs, thus improving the global Q function approximation accuracy and the target UAV positioning accuracy. Simulation results show that the proposed AR-MARL scheme can reduce the average positioning error by up to 17.5% and 58.5% compared to the VD-MARL scheme and the proposed method without FAS.",
        "published": "2025-07-12T00:31:15+00:00",
        "url": "http://arxiv.org/abs/2507.09094v1",
        "categories": [
          "cs.NI",
          "eess.SP"
        ],
        "summary": "This paper proposes a novel 3D positioning framework for a target UAV using a set of FAS-enabled UAVs that cooperatively estimate its real-time position. It introduces an attention-based recurrent multi-agent reinforcement learning (AR-MARL) scheme to optimize UAV trajectories and antenna port selection for minimizing target UAV positioning error.",
        "contributions": [
          "Development of a 3D positioning framework for a target UAV using FAS-enabled UAVs.",
          "Introduction of an attention-based recurrent multi-agent reinforcement learning (AR-MARL) scheme for optimizing UAV trajectories and antenna port selection, improving global Q function approximation and target UAV positioning accuracy."
        ],
        "methods": [
          "Collaborative Reinforcement Learning",
          "Multi-Agent Reinforcement Learning (MARL)",
          "Attention Mechanism",
          "Recurrent Neural Network (RNN)",
          "Fluid Antenna System (FAS)"
        ],
        "datasets": [],
        "limitations": [
          "The abstract doesn't explicitly mention the datasets used for the simulations, implying reliance on a simulated environment.",
          "The generalizability of the results to more complex or real-world scenarios with factors not considered in the simulation is unclear."
        ],
        "companies": [
          "Virginia Tech",
          "University of Oulu",
          "Peking University"
        ]
      },
      {
        "title": "Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs",
        "authors": [
          "Greyson Brothers"
        ],
        "affiliations": [],
        "abstract": "We investigate the design of pooling methods used to summarize the outputs of transformer embedding models, primarily motivated by reinforcement learning and vision applications. This work considers problems where a subset of the input vectors contains requisite information for a downstream task (signal) while the rest are distractors (noise). By framing pooling as vector quantization with the goal of minimizing signal loss, we demonstrate that the standard methods used to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are vulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs fluctuates. We then show that an attention-based adaptive pooling method can approximate the signal-optimal vector quantizer within derived error bounds for any SNR. Our theoretical results are first validated by supervised experiments on a synthetic dataset designed to isolate the SNR problem, then generalized to standard relational reasoning, multi-agent reinforcement learning, and vision benchmarks with noisy observations, where transformers with adaptive pooling display superior robustness across tasks.",
        "published": "2025-06-10T20:18:32+00:00",
        "url": "http://arxiv.org/abs/2506.09215v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "summary": "This paper addresses the problem of noisy inputs in transformer embedding models, where only a subset of vectors contain relevant information. They propose an attention-based adaptive pooling method to improve robustness against varying signal-to-noise ratios compared to standard pooling techniques.",
        "contributions": [
          "Identified the vulnerability of standard pooling methods (AvgPool, MaxPool, ClsToken) to performance degradation under fluctuating signal-to-noise ratios (SNR) in transformer embeddings.",
          "Proposed and theoretically analyzed an attention-based adaptive pooling method that approximates the signal-optimal vector quantizer and exhibits superior robustness across various tasks with noisy observations."
        ],
        "methods": [
          "Attention-based adaptive pooling",
          "Theoretical analysis of signal-optimal vector quantization for pooling",
          "Empirical validation on synthetic and real-world datasets"
        ],
        "datasets": [
          "Synthetic dataset (designed to isolate the SNR problem)",
          "Relational reasoning benchmarks",
          "Multi-agent reinforcement learning benchmarks",
          "Vision benchmarks with noisy observations"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations. Limitations would likely be related to the computational cost of attention mechanisms, the generalizability to extremely high-dimensional or complex noise distributions, or specific architectural choices in the transformer model itself. Further research into the specific benchmarks would be needed.",
          "The analysis focuses primarily on the pooling layer. Other aspects of the transformer architecture may also contribute to robustness or vulnerability to noise, which are not directly addressed in this work as presented in the abstract."
        ],
        "companies": [
          "Google",
          "Microsoft",
          "Meta"
        ]
      },
      {
        "title": "SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning",
        "authors": [
          "Xu Wan",
          "Chao Yang",
          "Cheng Yang",
          "Jie Song",
          "Mingyang Sun"
        ],
        "affiliations": [],
        "abstract": "Although multi-agent reinforcement learning (MARL) has shown its success across diverse domains, extending its application to large-scale real-world systems still faces significant challenges. Primarily, the high complexity of real-world environments exacerbates the credit assignment problem, substantially reducing training efficiency. Moreover, the variability of agent populations in large-scale scenarios necessitates scalable decision-making mechanisms. To address these challenges, we propose a novel framework: Sequential rollout with Sequential value estimation (SrSv). This framework aims to capture agent interdependence and provide a scalable solution for cooperative MARL. Specifically, SrSv leverages the autoregressive property of the Transformer model to handle varying populations through sequential action rollout. Furthermore, to capture the interdependence of policy distributions and value functions among multiple agents, we introduce an innovative sequential value estimation methodology and integrates the value approximation into an attention-based sequential model. We evaluate SrSv on three benchmarks: Multi-Agent MuJoCo, StarCraft Multi-Agent Challenge, and DubinsCars. Experimental results demonstrate that SrSv significantly outperforms baseline methods in terms of training efficiency without compromising convergence performance. Moreover, when implemented in a large-scale DubinsCar system with 1,024 agents, our framework surpasses existing benchmarks, highlighting the excellent scalability of SrSv.",
        "published": "2025-03-03T12:17:18+00:00",
        "url": "http://arxiv.org/abs/2503.01458v1",
        "categories": [
          "cs.AI",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "The paper introduces SrSv, a novel multi-agent reinforcement learning framework designed to address the challenges of high environment complexity and varying agent populations in large-scale real-world systems. SrSv leverages sequential action rollout and value estimation with a Transformer model to improve training efficiency and scalability in cooperative MARL.",
        "contributions": [
          "A novel framework (SrSv) that combines sequential rollouts with sequential value estimation to address the credit assignment problem and improve training efficiency in complex MARL environments.",
          "An innovative sequential value estimation methodology integrated into an attention-based sequential model to capture the interdependence of policy distributions and value functions among multiple agents, leading to improved performance and scalability."
        ],
        "methods": [
          "Sequential action rollout using the autoregressive property of the Transformer model to handle varying agent populations.",
          "Sequential value estimation methodology to capture the interdependence of policy distributions and value functions among multiple agents.",
          "Attention-based sequential model"
        ],
        "datasets": [
          "Multi-Agent MuJoCo",
          "StarCraft Multi-Agent Challenge",
          "DubinsCars"
        ],
        "limitations": [
          "The abstract does not explicitly mention any limitations of the proposed method. Limitations likely exist regarding computational cost, hyperparameter tuning, and potential sensitivity to specific environment characteristics.",
          "The abstract does not discuss generalizability to other types of MARL problems outside of cooperative settings."
        ],
        "companies": [
          "Tsinghua University",
          "Peking University",
          "Chinese Academy of Sciences"
        ]
      },
      {
        "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
        "authors": [
          "Alsu Sagirova",
          "Yuri Kuratov",
          "Mikhail Burtsev"
        ],
        "affiliations": [],
        "abstract": "Multi-agent reinforcement learning (MARL) demonstrates significant progress in solving cooperative and competitive multi-agent problems in various environments. One of the principal challenges in MARL is the need for explicit prediction of the agents' behavior to achieve cooperation. To resolve this issue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends memory transformers to multi-agent settings by pooling and globally broadcasting individual working memories, enabling agents to exchange information implicitly and coordinate their actions. We evaluate SRMT on the Partially Observable Multi-Agent Pathfinding problem in a toy Bottleneck navigation task that requires agents to pass through a narrow corridor and on a POGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently outperforms a variety of reinforcement learning baselines, especially under sparse rewards, and generalizes effectively to longer corridors than those seen during training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is competitive with recent MARL, hybrid, and planning-based algorithms. These results suggest that incorporating shared recurrent memory into the transformer-based architectures can enhance coordination in decentralized multi-agent systems. The source code for training and evaluation is available on GitHub: https://github.com/Aloriosa/srmt.",
        "published": "2025-01-22T20:08:53+00:00",
        "url": "http://arxiv.org/abs/2501.13200v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.MA"
        ],
        "summary": "This paper introduces the Shared Recurrent Memory Transformer (SRMT) for multi-agent reinforcement learning, which enables agents to implicitly exchange information and coordinate actions through shared memory. SRMT is evaluated on multi-agent pathfinding tasks, demonstrating improved performance compared to baselines, especially with sparse rewards, and competitive results on standard benchmarks.",
        "contributions": [
          "Proposes the Shared Recurrent Memory Transformer (SRMT) architecture for MARL, facilitating implicit communication and coordination among agents.",
          "Demonstrates SRMT's effectiveness on Partially Observable Multi-Agent Pathfinding (MAPF) problems, showing improved performance and generalization compared to baselines."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Transformer architecture extended with recurrent memory and a shared memory mechanism for multi-agent settings (SRMT)",
          "Memory pooling and global broadcasting of individual agent memories"
        ],
        "datasets": [
          "Toy Bottleneck navigation task",
          "POGEMA benchmark set of MAPF tasks (Mazes, Random, MovingAI)"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations, but future research could explore SRMT's scalability to very large agent populations or more complex, dynamic environments.",
          "Performance comparisons on POGEMA are described as 'competitive', implying there may be cases where SRMT is not superior to all other approaches."
        ],
        "companies": [
          "AIRI"
        ]
      },
      {
        "title": "Satellites swarm cooperation for pursuit-attachment tasks with transformer-based reinforcement learning",
        "authors": [
          "yonghao Li"
        ],
        "affiliations": [],
        "abstract": "The on-orbit intelligent planning of satellites swarm has attracted increasing attention from scholars. Especially in tasks such as the pursuit and attachment of non-cooperative satellites, satellites swarm must achieve coordinated cooperation with limited resources. The study proposes a reinforcement learning framework that integrates the transformer and expert networks. Firstly, under the constraints of incomplete information about non-cooperative satellites, an implicit multi-satellites cooperation strategy was designed using a communication sharing mechanism. Subsequently, for the characteristics of the pursuit-attachment tasks, the multi-agent reinforcement learning framework is improved by introducing transformers and expert networks inspired by transfer learning ideas. To address the issue of satellites swarm scalability, sequence modelling based on transformers is utilized to craft memory-augmented policy networks, meanwhile increasing the scalability of the swarm. By comparing the convergence curves with other algorithms, it is shown that the proposed method is qualified for pursuit-attachment tasks of satellites swarm. Additionally, simulations under different maneuvering strategies of non-cooperative satellites respectively demonstrate the robustness of the algorithm and the task efficiency of the swarm system. The success rate of pursuit-attachment tasks is analyzed through Monte Carlo simulations.",
        "published": "2024-06-03T07:17:16+00:00",
        "url": "http://arxiv.org/abs/2406.01061v1",
        "categories": [
          "cs.MA"
        ],
        "summary": "This paper proposes a reinforcement learning framework using transformers and expert networks for on-orbit satellite swarm cooperation in pursuit-attachment tasks of non-cooperative satellites. The framework aims to achieve coordinated cooperation with limited resources under incomplete information about the target.",
        "contributions": [
          "Design of an implicit multi-satellite cooperation strategy using a communication sharing mechanism under incomplete information.",
          "Improvement of the multi-agent reinforcement learning framework by integrating transformers and expert networks inspired by transfer learning to handle pursuit-attachment tasks.",
          "Use of transformer-based sequence modeling to create memory-augmented policy networks, enhancing the scalability of the satellite swarm."
        ],
        "methods": [
          "Reinforcement Learning",
          "Transformer Networks",
          "Expert Networks (inspired by Transfer Learning)",
          "Multi-Agent Reinforcement Learning",
          "Sequence Modeling"
        ],
        "datasets": [
          "Simulated environment of on-orbit pursuit-attachment tasks of non-cooperative satellites",
          "Data generated by different maneuvering strategies of non-cooperative satellites"
        ],
        "limitations": [
          "Abstract does not explicitly mention limitations, but it implies the work is based on simulations, thus lacking real-world validation.",
          "The degree to which the method scales to very large swarms isn't fully explored in the abstract, only that it increases scalability."
        ],
        "companies": []
      },
      {
        "title": "Collaborative Visual Navigation",
        "authors": [
          "Haiyang Wang",
          "Wenguan Wang",
          "Xizhou Zhu",
          "Jifeng Dai",
          "Liwei Wang"
        ],
        "affiliations": [],
        "abstract": "As a fundamental problem for Artificial Intelligence, multi-agent system (MAS) is making rapid progress, mainly driven by multi-agent reinforcement learning (MARL) techniques. However, previous MARL methods largely focused on grid-world like or game environments; MAS in visually rich environments has remained less explored. To narrow this gap and emphasize the crucial role of perception in MAS, we propose a large-scale 3D dataset, CollaVN, for multi-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed to cooperatively navigate across photo-realistic environments to reach target locations. Diverse MAVN variants are explored to make our problem more general. Moreover, a memory-augmented communication framework is proposed. Each agent is equipped with a private, external memory to persistently store communication information. This allows agents to make better use of their past communication information, enabling more efficient collaboration and robust long-term planning. In our experiments, several baselines and evaluation metrics are designed. We also empirically verify the efficacy of our proposed MARL approach across different MAVN task settings.",
        "published": "2021-07-02T15:48:16+00:00",
        "url": "http://arxiv.org/abs/2107.01151v2",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "summary": "This paper addresses the less explored area of multi-agent systems (MAS) in visually rich environments by introducing a new dataset, CollaVN, for multi-agent visual navigation (MAVN). They also propose a memory-augmented communication framework to improve collaboration and long-term planning in MAVN tasks.",
        "contributions": [
          "A new large-scale 3D dataset, CollaVN, for multi-agent visual navigation (MAVN) in photo-realistic environments.",
          "A memory-augmented communication framework where each agent has a private, external memory to store communication information for better collaboration and long-term planning."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Memory-augmented communication framework"
        ],
        "datasets": [
          "CollaVN"
        ],
        "limitations": [
          "The abstract doesn't explicitly state limitations, but the focus on a specific dataset (CollaVN) might limit generalizability to other visual navigation environments.",
          "The abstract doesn't mention computational cost or scalability, which could be a limitation for the proposed methods."
        ],
        "companies": [
          "Microsoft"
        ]
      }
    ],
    "Agentic Computer Vision System for Image Analysis.": [
      {
        "title": "Who Let The Dogs Out? Modeling Dog Behavior From Visual Data",
        "authors": [
          "Kiana Ehsani",
          "Hessam Bagherinezhad",
          "Joseph Redmon",
          "Roozbeh Mottaghi",
          "Ali Farhadi"
        ],
        "affiliations": [],
        "abstract": "We introduce the task of directly modeling a visually intelligent agent. Computer vision typically focuses on solving various subtasks related to visual intelligence. We depart from this standard approach to computer vision; instead we directly model a visually intelligent agent. Our model takes visual information as input and directly predicts the actions of the agent. Toward this end we introduce DECADE, a large-scale dataset of ego-centric videos from a dog's perspective as well as her corresponding movements. Using this data we model how the dog acts and how the dog plans her movements. We show under a variety of metrics that given just visual input we can successfully model this intelligent agent in many situations. Moreover, the representation learned by our model encodes distinct information compared to representations trained on image classification, and our learned representation can generalize to other domains. In particular, we show strong results on the task of walkable surface estimation by using this dog modeling task as representation learning.",
        "published": "2018-03-28T19:43:33+00:00",
        "url": "http://arxiv.org/abs/1803.10827v2",
        "categories": [
          "cs.CV"
        ],
        "summary": "This paper introduces a novel approach to computer vision by directly modeling a visually intelligent agent (a dog) instead of focusing on subtasks. They present DECADE, a large-scale dataset of ego-centric dog videos and movements, and demonstrate that their model can successfully predict dog actions and generalize to other vision tasks like walkable surface estimation.",
        "contributions": [
          "Introducing a new paradigm in computer vision by directly modeling a visually intelligent agent.",
          "Creation and release of DECADE, a large-scale dataset of ego-centric dog videos and corresponding movements."
        ],
        "methods": [
          "Modeling dog behavior and movement planning from visual input.",
          "Representation learning from the dog modeling task and transfer to other domains."
        ],
        "datasets": [
          "DECADE: A large-scale dataset of ego-centric videos from a dog's perspective and corresponding movements."
        ],
        "limitations": [
          "The abstract does not explicitly state limitations. The model's performance may be limited by the diversity and complexity of the DECADE dataset.",
          "The abstract does not explicitly state limitations. The model's ability to generalize may be limited by the similarity between the training domain (dog vision) and the target domain (walkable surface estimation)."
        ],
        "companies": [
          "Allen Institute for AI",
          "University of Washington"
        ]
      },
      {
        "title": "Learning to Communicate with Deep Multi-Agent Reinforcement Learning",
        "authors": [
          "Jakob N. Foerster",
          "Yannis M. Assael",
          "Nando de Freitas",
          "Shimon Whiteson"
        ],
        "affiliations": [],
        "abstract": "We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.",
        "published": "2016-05-21T17:20:04+00:00",
        "url": "http://arxiv.org/abs/1605.06676v2",
        "categories": [
          "cs.AI",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "This paper explores the problem of multiple agents learning communication protocols in partially observable environments to maximize their shared utility using deep multi-agent reinforcement learning. They propose two approaches, Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL), demonstrating successful end-to-end learning in complex environments.",
        "contributions": [
          "Demonstrates end-to-end learning of communication protocols using deep neural networks in complex multi-agent environments.",
          "Introduces two novel approaches: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL) for learning communication protocols.",
          "Presents new environments inspired by communication riddles and multi-agent computer vision problems for studying the learning of communication protocols.",
          "Highlights engineering innovations essential for success in these domains."
        ],
        "methods": [
          "Reinforced Inter-Agent Learning (RIAL) - Uses deep Q-learning for agent interaction.",
          "Differentiable Inter-Agent Learning (DIAL) - Exploits backpropagation of error derivatives through communication channels during learning."
        ],
        "datasets": [
          "Environments inspired by communication riddles",
          "Environments inspired by multi-agent computer vision problems"
        ],
        "limitations": [
          "The abstract doesn't explicitly state any limitations, further analysis of the full paper would be required.",
          "The success of the methods is demonstrated on specific environments, and the generalizability to other types of multi-agent scenarios is not explicitly addressed in the abstract. Further analysis of the full paper would be required."
        ],
        "companies": [
          "University of Oxford",
          "DeepMind"
        ]
      }
    ]
  }
}