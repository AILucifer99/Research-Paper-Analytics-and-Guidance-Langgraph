{
  "metadata": {
    "timestamp": "20260109_111123",
    "topics_analyzed": 2,
    "total_papers": 49,
    "companies_found": 7,
    "strategic_insights": {
      "gaps": [
        "Lack of explicit limitation statements in abstracts: Many abstracts fail to clearly articulate the limitations of the presented research, hindering quick assessment and comparison.",
        "Unclear dataset specifications: Insufficient detail regarding the specific datasets used makes it difficult to evaluate the scope, generalizability, and potential biases of the findings.",
        "Limited generalizability: Domain-specific approaches and reliance on specific types of data (e.g., 'fragmented' data) raise concerns about applicability to broader contexts.",
        "Reliance on LLM capabilities: The performance of several approaches hinges on the reliability and accuracy of LLMs, introducing potential biases and inaccuracies if the LLMs are not well-calibrated.",
        "Computational cost: The computational demands of complex algorithms, adversarial training, and iterative processes are often not addressed, potentially limiting practical adoption.",
        "Lack of validation: Many results are preliminary, indicating a need for more rigorous and extensive validation.",
        "Missing implementation details: Vague descriptions of key components (e.g., search APIs, RAG modules, scoring mechanisms) impede reproducibility and independent evaluation.",
        "Fact verification benchmark selection: Unclear criteria for selecting fact verification benchmarks raise questions about the representativeness and validity of the evaluation.",
        "Graph-based RAG Limitations: Neglecting semantic content and rigid layer-specific compression in graph-based RAG damages local graph structures and overall effectiveness.",
        "Proposition Extraction and Graph Construction: Performance sensitivity to the quality of proposition extraction and graph construction algorithms."
      ],
      "trends": [
        "Retrieval Augmented Generation (RAG): Active research and development in RAG techniques, particularly graph-based RAG, to enhance LLM performance.",
        "Multi-Agent Reinforcement Learning (MARL): Utilizing MARL for solving complex combinatorial problems.",
        "Self-Synthesis Strategies: Leveraging LLMs for self-synthesis and utility change assessment in MARL.",
        "Process Knowledge Infusion: Integrating process knowledge into RAG systems to improve domain-specific performance.",
        "Focus on Complex Algorithmic Designs: Investigating the capabilities and limitations of LLMs in handling intricate algorithmic tasks, including code generation and reasoning.",
        "Addressing Fragmented Data: Development of methods for handling and processing fragmented data.",
        "Emphasis on Faithfulness and Relevance: Evaluating and improving the faithfulness and relevance of generated content.",
        "Use of iterative self-reflection: Development of methods that utilize iterative self-reflection to improve performance, particularly in complex reasoning tasks."
      ],
      "recommendations": [
        "Prioritize transparent reporting: Abstracts should explicitly state the limitations of the research, including dataset specifics, scope of applicability, and potential biases.",
        "Focus on generalizability: Develop methods that are less domain-specific and can be applied to a wider range of data types and tasks.",
        "Improve LLM calibration: Investigate techniques to improve the reliability and accuracy of LLMs, particularly in tasks involving self-synthesis and utility change assessment.",
        "Address computational efficiency: Explore methods to reduce the computational cost of complex algorithms and training processes.",
        "Conduct thorough validation: Perform rigorous validation on diverse datasets and real-world scenarios to ensure the robustness and generalizability of the findings.",
        "Provide detailed implementation information: Include comprehensive details on the implementation of key components to facilitate reproducibility and independent evaluation.",
        "Develop robust evaluation metrics: Establish clear and well-justified criteria for selecting benchmarks and evaluating performance.",
        "Investigate semantic-aware graph RAG: Explore graph-based RAG approaches that prioritize semantic content alongside topological structure.",
        "Improve proposition extraction and graph construction: Focus on improving the accuracy and robustness of proposition extraction and graph construction algorithms.",
        "Explore methods for evaluating and mitigating biases: Develop methods for detecting and mitigating biases introduced by LLMs or specific datasets."
      ]
    }
  },
  "topics": [
    "Retrieval Augmented Generation",
    "Multi-Agent Reinforcement Learning"
  ],
  "topic_statistics": [
    {
      "topic": "Retrieval Augmented Generation",
      "paper_count": 23,
      "methods_distribution": {
        "Adaptive gating system to dynamically allocate processing power based on context complexity.": 1,
        "Integration of the module within the language model layers.": 1,
        "\"Expand-then-Refine\" paradigm": 1,
        "Set-centric selection and ranking": 1,
        "Self-synthesis strategy for preference label generation": 1,
        "Set-list wise training strategy": 1,
        "Tree-based Hierarchical Retrieval Augmented Generation": 1,
        "Adaptive Compression Encoding": 1,
        "Semantic-Structural Entropy ($S^2$-Entropy)": 1,
        "Reformulation of attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree": 1,
        "Proposition Graph Construction (heterogeneous graph of propositions, entities, and passages)": 1,
        "Iterative Suggestion-Selection cycle for graph traversal (Suggestion: query-aware traversal; Selection: LLM feedback for pruning)": 1,
        "Lightweight path extraction to link related concepts": 1,
        "Hybrid retrieval approach (the specific details of the hybrid approach are not in the abstract, but implied)": 1,
        "Multi-Agent Debate": 1,
        "External Tool Augmentation (Search API, RAG module)": 1,
        "Adaptive Query Formulation": 1,
        "Faithfulness and Answer Relevance scoring": 1,
        "Stepwise prover using LLMs to propose proof commands validated by Isabelle in a bounded search loop.": 1,
        "Higher-level proof planner that generates structured Isar outlines and attempts to fill and repair remaining gaps.": 1,
        "Beam search for tactics, tactics reranker ML and RL models, premise selection with small transformer models, micro-RAG for Isar proofs built from AFP, and counter-example guided proof repair.": 1,
        "Reasoner-Verifier framework": 1,
        "Retrieval-Augmented Generation (RAG)": 3,
        "Process-aware advantage reward based on observational signals and model uncertainty": 1,
        "Adversarial training between Reasoner and Verifier": 1,
        "MAR (Knowledge Modulation Aligned Retrieval): Uses modulation networks to refine query embeddings with interpretable symbolic features.": 1,
        "KG-Path RAG: Enhances queries by traversing knowledge graphs to improve retrieval quality and interpretability.": 1,
        "Process Knowledge-infused RAG: Utilizes domain-specific tools to reorder retrieved content based on validated workflows.": 1,
        "Hybrid Retrieval (BM25 and Contriever)": 1,
        "Reciprocal Rank Fusion (RRF)": 1,
        "Natural Language Inference (NLI) for self-reflection": 1,
        "LLM-based verification for self-reflection": 1,
        "Iterative query reformulation": 1,
        "Reinforcement Learning (RL)": 1,
        "Multi-stage gated reward function": 1,
        "Heterogeneous retrievers for data construction": 1,
        "Construction of intra-chunk discourse trees to capture local hierarchical relationships within retrieved passages.": 1,
        "Building inter-chunk rhetorical graphs to model cross-passage coherence and relationships between different retrieved passages.": 1,
        "Integration of discourse trees and graphs into a planning blueprint to condition the generation process of the LLM.": 1,
        "Computer vision models for extracting static visual features from drawings.": 1,
        "Analysis of dynamic behavioral kinematic cues from the drawing process (e.g., stroke speed, pauses, smoothness).": 1,
        "Retrieval-Augmented Generation (RAG) architecture to integrate psychological knowledge into the analysis.": 1,
        "Correlation analysis between extracted features and standardized psychological metrics.": 1,
        "Systematic Literature Review": 1,
        "Retrieval-augmented generation (RAG)": 1,
        "Agentic frameworks": 1,
        "Structured data preparation": 1,
        "LLM-based user simulations": 1,
        "Cross-lingual Retrieval-Augmented Generation (RAG)": 1,
        "Translation-centric architecture (Bengali to English, English to Bengali)": 1,
        "Domain-specific keyword injection": 1,
        "Dense vector retrieval": 1,
        "Open-source models implementation": 1,
        "Planning mechanisms": 1,
        "Retrieval-augmented generation": 1,
        "Memory structures": 1,
        "LLM-driven conversational agent design": 1,
        "Scientific Intention Perceptor for extracting structured experimental elements from queries": 1,
        "Structured Memory Compressor for managing multi-turn dialogues": 1,
        "Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework with a two-stage retrieval mechanism and Citable Scientific Task Record (CSTR) identifiers": 1,
        "Knowledge distillation: Distilling a calibrated metadata aware LLM re-ranker into a compact student retriever.": 1,
        "Metadata-aware prompting: Crafting prompts that incorporate metadata and test for consistency under permutations and robustness to paraphrases.": 1,
        "MetaFusion objective: Combining metadata conditioned ranking loss with a cross model margin loss.": 1,
        "Hard negative mining: Using the LLM to identify hard negatives for training the student retriever.": 1,
        "Context Inlining: Embedding the unfinished function into its call graph to enhance repository understanding.": 1,
        "Anchor Generation: Generating a draft completion to approximate downstream dependencies and enable perplexity-based confidence estimation.": 1,
        "Upstream Inlining: Embedding the anchor into its callers to capture diverse usage scenarios.": 1,
        "Downstream Retrieval: Integrating the anchor's callees into the prompt to provide precise dependency context.": 1,
        "Document Partitioning (RAGPart): Leveraging the training dynamics of dense retrievers to mitigate the effect of poisoned documents.": 1,
        "Token Masking and Similarity Shift Analysis (RAGMask): Identifying suspicious tokens based on significant changes in similarity scores when those tokens are masked.": 1,
        "Multi-Retriever Retrieval Augmented Generation (RAG)": 1,
        "Domain-specific training with SecBERT encoder": 1,
        "Prompt-based LLM generator": 1,
        "Ablation experiments and error analysis": 1,
        "Information-Gain-Driven Path Retrieval": 1,
        "Multi-Agent Architecture for Evidence Fusion": 1,
        "Retrieval-Augmented Generation with LLMs": 1,
        "Graph Reasoning": 1
      },
      "reproducibility_score": 0.8695652173913043,
      "open_source_ratio": 0.3,
      "top_companies": [
        "Microsoft",
        "Harbin Institute of Technology",
        "Stanford University",
        "Google",
        "Carnegie Mellon University"
      ],
      "avg_citation_potential": 0.7
    },
    {
      "topic": "Multi-Agent Reinforcement Learning",
      "paper_count": 26,
      "methods_distribution": {
        "Image-based Reinforcement Learning": 1,
        "Neural Networks for spatial feature extraction": 1,
        "Decentralized control": 1,
        "Q-learning-based Multi-Agent Reinforcement Learning (MARL)": 1,
        "Personalized-enhanced communication using dynamic graph topology": 1,
        "Local crowd perception": 1,
        "Region-based deadlock-breaking strategy": 1,
        "Offline Multi-Agent Reinforcement Learning (MARL)": 1,
        "Conservative Q-Learning (CQL)": 1,
        "Meta-Learning": 1,
        "Multi-Agent Reinforcement Learning (MARL) with Centralized Training with Decentralized Execution (CTDE).": 1,
        "Model Predictive Control (MPC).": 1,
        "AutoBucket TestBench (for computation cost estimation).": 1,
        "Agent-level modeling of MARL to categorize heterogeneity.": 1,
        "Definition of heterogeneity distance.": 1,
        "Development of a multi-agent dynamic parameter sharing algorithm based on heterogeneity.": 1,
        "Multi-Agent Reinforcement Learning (MARL)": 14,
        "Directed Acyclic Graph (DAG) based agent organization": 1,
        "Training and inference methods for the Reinforcement Networks framework": 1,
        "Reflection Mechanism": 1,
        "Asymmetric Clipping Mechanism (based on KL divergence)": 1,
        "Multi Agent Reinforcement Learning (MARL)": 1,
        "Policy Optimization": 1,
        "Physics-Informed Neural Network (PINN)": 1,
        "Federated Learning (FL)": 1,
        "Deep Q-Networks (DQN)": 1,
        "Soft Actor-Critic (SAC)": 1,
        "False Data Injection (FDI)": 1,
        "Transmission and Distribution (T and D) dual simulation": 1,
        "Exhaustive search for optimal EIC (conventional optimization method).": 1,
        "Markov Decision Process (MDP) formulation for trajectory planning.": 1,
        "Multi-Agent Reinforcement Learning (MARL) for solving the MDP.": 1,
        "Imitation-based Triple Deep Q-Network (ITDQN) algorithm with an elite imitation mechanism and a mediator Q-network over DDQN.": 1,
        "Transformer Encoder": 1,
        "Relative Polar State Space Representation": 1,
        "Speed Advisory Generation": 1,
        "Hierarchical Graph Neural Network (GNN)": 1,
        "Graph Attention Networks": 1,
        "Multi-Agent Proximal Policy Optimization (MAPPO)": 1,
        "Independent Proximal Policy Optimization (PPO)": 1,
        "Hyperparameter search to ensure competitive market outcomes in decentralized training": 1,
        "QMIX algorithm (centralized training, decentralized execution)": 1,
        "Simulation of a reactive jammer with Markovian threshold dynamics": 1,
        "Benchmarking against a genie-aided optimal policy, local UCB, and a stateless reactive policy": 1,
        "Multi-Agent Reinforcement Learning (MARL) for decentralized control of UAVs.": 1,
        "Dijkstra's algorithm for path planning within restricted motion envelopes (used in the baseline policy).": 1,
        "MAPPO (Multi-Agent Proximal Policy Optimization)": 1,
        "A* Search Algorithm": 1,
        "Farthest Point Sampling (FPS)": 1,
        "Potential Field Reward Shaping": 1,
        "Decentralized Critic": 1,
        "Independent Proximal Policy Optimization (IPPO)": 1,
        "Rotating Policy Training (RPT)": 1,
        "Deep Double Q-Network (DDQN) - used as a withheld teammate policy for evaluation": 1,
        "Deep Reinforcement Learning (DRL)": 1,
        "Hypergraph Neural Networks (HGNN)": 1,
        "Finite Element Method (FEM)": 1,
        "Anisotropic Diffusion": 1,
        "Centralized Training with Decentralized Execution (CTDE)": 1,
        "Semi-Centralized Training, Decentralized Execution (SEMI-CTDE)": 1,
        "Regional Parameter Sharing": 1,
        "Composite State and Reward Formulations": 1,
        "Deep Reinforcement Learning": 1,
        "Dialogue-based Negotiation Protocols": 1,
        "Hierarchical Consensus Network (HCN) - Attention Mechanisms and Graph Neural Networks": 1,
        "Progressive Negotiation Protocol (PNP)": 1,
        "Context-Aware Reward Shaping": 1,
        "Soft Actor Critic (SAC) algorithm": 1,
        "Sharpness-Aware Minimization (SAM)": 1,
        "Temporal-Difference (TD)-error variance based regularization": 1,
        "Dynamic \u03c1 scheduling for exploration-exploitation": 1,
        "Multi-Agent Deep Reinforcement Learning (DRL)": 1,
        "Simulation in a ring-road environment": 1,
        "Adaptation of the learned strategy to the Intelligent Driver Model (IDM)": 1,
        "Parametrised linear framework for optimization": 1,
        "Review and analysis of communication strategies dealing with message perturbations.": 1,
        "Review and analysis of communication strategies dealing with transmission delays.": 1,
        "Review and analysis of communication strategies dealing with limited bandwidth.": 1,
        "Centralized embedding model for capturing fine-grained trajectory representations.": 1,
        "Decentralized models approximating the centralized embedding model to obtain team-level task information.": 1,
        "Decentralized memory retrieval based on learned embeddings.": 1,
        "Hybrid utility score incorporating individual- and team-level returns.": 1,
        "Recurrent Neural Networks (RNNs) for agent control": 1,
        "Evolution-inspired reward functions for individual fitness": 1
      },
      "reproducibility_score": 0.8846153846153846,
      "open_source_ratio": 0.3,
      "top_companies": [
        "Google",
        "Microsoft",
        "University of California, Berkeley",
        "Stanford University",
        "MIT"
      ],
      "avg_citation_potential": 0.7
    }
  ],
  "company_comparisons": [
    {
      "company": "Microsoft",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning",
        "Retrieval Augmented Generation"
      ],
      "paper_count": 8,
      "strengths": [
        "Strong focus on cutting-edge AI techniques: The research profile clearly emphasizes advanced AI methodologies like Multi-Agent Reinforcement Learning (MARL) and Retrieval Augmented Generation (RAG), indicating a commitment to developing state-of-the-art AI solutions.",
        "Diverse Methodological Toolkit: The wide range of methods employed (e.g., Domain-specific training with SecBERT, MAR, HCN, KG-Path RAG, DDQN, RPT, LLM-based simulations) showcases a versatile research team capable of tackling complex problems from multiple angles.",
        "Emphasis on Knowledge-Augmented and Interpretable AI: The use of techniques like KG-Path RAG and MAR highlights a focus on incorporating external knowledge and improving the interpretability of AI models, which is crucial for real-world applications and trust."
      ],
      "weaknesses": [
        "Limited Scope of Topics: While the chosen topics are relevant, focusing on only two areas (MARL and RAG) might indicate a lack of breadth in their overall AI research portfolio. Further research might be required to fully understand their AI research direction.",
        "Lack of Contextual Paper Details: The analysis is based solely on topic and methods. Without knowing the specific problems addressed in each paper, it's difficult to assess the impact and novelty of their work. Deeper analysis requires understanding the specific problem each paper addresses.",
        "Potential for Methodological Overlap: Some methods, like LLM-based simulations and Prompt-based LLM generation, are closely related. A clearer distinction of when each is applied would strengthen the profile."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 1
    },
    {
      "company": "Harbin Institute of Technology",
      "topics_covered": [
        "Retrieval Augmented Generation"
      ],
      "paper_count": 2,
      "strengths": [
        "Focused Research: The research is concentrated on a cutting-edge topic, Retrieval Augmented Generation (RAG), indicating a commitment to current trends in NLP.",
        "Methodological Diversity: The papers employ a variety of sophisticated methods, including an \"Expand-then-Refine\" paradigm, integration within language model layers, adaptive gating, and strategies for preference learning and ranking, demonstrating a strong methodological skillset."
      ],
      "weaknesses": [
        "Limited Scope: With only 2 papers, the breadth of research within RAG is likely narrow.  It's difficult to assess the full expertise of the institute based on such a small sample.",
        "Lack of Context: Without more information about the specific applications or datasets used, it's hard to determine the practical impact and generalizability of the research.  The methods are described, but their effectiveness and limitations in different contexts are unknown."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 2
    },
    {
      "company": "Stanford University",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning",
        "Retrieval Augmented Generation"
      ],
      "paper_count": 4,
      "strengths": [
        "Focus on cutting-edge AI topics: The research profile demonstrates a strong interest and activity in highly relevant and rapidly evolving fields like Multi-Agent Reinforcement Learning and Retrieval Augmented Generation.",
        "Diverse Methodological Toolkit: The company utilizes a wide range of techniques, including both classical methods (e.g., Region-based deadlock-breaking) and modern deep learning approaches (e.g., Transformer Encoders, LLMs), indicating a versatile approach to problem-solving.",
        "Application to Complex Domains: The research explores applications in areas with high practical impact, such as speed advisory generation, crowd perception, and automated theorem proving, suggesting a focus on real-world problem-solving.",
        "Integration of Multiple AI Paradigms: The use of techniques like RAG and the combination of LLMs with formal verification systems (Isabelle) demonstrate a sophisticated approach to integrating different AI paradigms to achieve complex goals."
      ],
      "weaknesses": [
        "Limited Publication Volume: Only 4 papers represent a relatively small research output, potentially indicating a narrow scope or early stages of research in these areas.  This makes it difficult to draw broad conclusions about the overall research program.",
        "Lack of Specificity in Some Methods:  While the list of methods is extensive, some descriptions are vague (e.g., 'Heterogeneous retrievers for data construction'). More detail on the specific architectures and implementations would be beneficial.",
        "Potential for Fragmentation: The breadth of methods could suggest a lack of deep focus on any single technique. It's unclear how well integrated these different methods are within a cohesive research strategy.",
        "Missing Context on Data and Evaluation: The description lacks information on the datasets used and the evaluation metrics employed. Without this, it's difficult to assess the rigor and impact of the research."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 3
    },
    {
      "company": "Google",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning",
        "Retrieval Augmented Generation"
      ],
      "paper_count": 5,
      "strengths": [
        "Strong focus on cutting-edge research areas like Multi-Agent Reinforcement Learning and Retrieval Augmented Generation, indicating a commitment to future AI advancements.",
        "Utilization of diverse and advanced methods, including Deep Double Q-Network, Knowledge Graph-enhanced RAG, and Centralized Training with Decentralized Execution MARL, showcasing a breadth of technical expertise.",
        "Emphasis on interpretability and explainability, as evidenced by the use of interpretable symbolic features in MAR and KG-Path RAG, which are crucial for responsible AI development."
      ],
      "weaknesses": [
        "Relatively small number of publications (5) suggests a potentially limited scope or recent entry into these specific research areas.",
        "While diverse methods are employed, the limited paper count makes it difficult to assess the depth of investigation and the robustness of the findings in each area. More papers are needed to confirm the impact of the work.",
        "The list of methods doesn't explicitly mention evaluation metrics or datasets used, making it difficult to judge the practical applicability and reproducibility of the research."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 4
    },
    {
      "company": "Carnegie Mellon University",
      "topics_covered": [
        "Retrieval Augmented Generation"
      ],
      "paper_count": 2,
      "strengths": [
        "Strong focus on practical applications of RAG, particularly through the use of Knowledge Distillation to create efficient retrievers, suggesting an emphasis on real-world deployment.",
        "Sophisticated approach to RAG, incorporating metadata-awareness in both prompting and retriever training, indicating a deep understanding of the importance of structured information.",
        "Innovative methods such as MetaFusion objective and multi-stage gated reward function highlight a commitment to pushing the boundaries of RAG performance.",
        "Demonstrated expertise in using LLMs not just for generation but also for improving the retrieval component through hard negative mining."
      ],
      "weaknesses": [
        "Limited breadth of research, with only 2 papers specifically focused on Retrieval Augmented Generation, suggesting a relatively nascent or niche area of focus within the university's broader research portfolio.",
        "Reliance on computationally intensive methods like Reinforcement Learning (RL) for reward function optimization might pose challenges for scalability and resource constraints."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 5
    },
    {
      "company": "University of California, Berkeley",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning"
      ],
      "paper_count": 2,
      "strengths": [
        "Focus on Multi-Agent Reinforcement Learning (MARL) indicates expertise in a cutting-edge area of AI with broad applications.",
        "The variety of methods used within the MARL research (Transformer Encoder, Q-learning, dynamic graph topology) suggests a diverse skillset and exploration of different approaches to the problem."
      ],
      "weaknesses": [
        "Very limited number of papers (2) suggests a nascent or small research group in this specific sub-area, or a very recent start in this line of research.",
        "The breadth of methods listed across only two papers could indicate a lack of deep dives or comprehensive exploration into any single method. It might be more exploratory than conclusive."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 6
    },
    {
      "company": "MIT",
      "topics_covered": [
        "Multi-Agent Reinforcement Learning"
      ],
      "paper_count": 2,
      "strengths": [
        "Strong focus on Multi-Agent Reinforcement Learning (MARL), a cutting-edge area of AI research.",
        "Exploration of diverse methods within MARL, including Q-learning and Transformer Encoders, suggesting a broad approach to problem-solving."
      ],
      "weaknesses": [
        "Limited number of publications (2) indicates a relatively small research output in this specific topic area, potentially suggesting early-stage research or a focused niche.",
        "The provided methods list, while diverse, lacks context on how these methods are integrated or contribute specifically to the two publications. This makes it difficult to assess the depth of contribution."
      ],
      "innovation_score": 0.8,
      "collaboration_score": 0.6,
      "ranking": 7
    }
  ],
  "papers": {
    "Retrieval Augmented Generation": [
      {
        "title": "ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG",
        "authors": [
          "Jianbo Li",
          "Yi Jiang",
          "Sendong Zhao",
          "Bairui Hu",
          "Haochun Wang",
          "Bing Qin"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.",
        "published": "2026-01-08T15:44:52+00:00",
        "url": "http://arxiv.org/abs/2601.05038v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "summary": "The paper introduces ArcAligner, a module designed to improve the performance of Retrieval-Augmented Generation (RAG) systems when using highly compressed context representations. ArcAligner integrates into the language model layers and adaptively adjusts processing power based on the complexity of the compressed information, leading to better performance in knowledge-intensive QA tasks.",
        "contributions": [
          "Development of ArcAligner, an adaptive module that enhances the utilization of compressed context embeddings in RAG.",
          "Demonstration that ArcAligner outperforms compression baselines at comparable compression rates, particularly in multi-hop and long-tail question answering scenarios."
        ],
        "methods": [
          "Adaptive gating system to dynamically allocate processing power based on context complexity.",
          "Integration of the module within the language model layers."
        ],
        "datasets": [
          "Knowledge-intensive QA benchmarks (specific datasets not mentioned in abstract, further research needed to identify them)"
        ],
        "limitations": [
          "The abstract doesn't explicitly state any limitations. Further reading of the paper is needed to identify them.",
          "The specific knowledge-intensive QA datasets used are not mentioned in the abstract, making it difficult to assess the scope of the evaluation."
        ],
        "companies": [
          "Harbin Institute of Technology"
        ]
      },
      {
        "title": "OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation",
        "authors": [
          "Yi Jiang",
          "Sendong Zhao",
          "Jianbo Li",
          "Bairui Hu",
          "Yanrui Du",
          "Haochun Wang",
          "Bing Qin"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.",
        "published": "2026-01-08T15:35:01+00:00",
        "url": "http://arxiv.org/abs/2601.05027v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "The paper introduces OptiSet, a novel framework for Retrieval-Augmented Generation (RAG) that addresses the limitations of statically selecting top-k passages by focusing on set-centric selection and ranking. OptiSet uses an \"Expand-then-Refine\" paradigm and a self-synthesis strategy to identify complementary and redundant evidence, leading to more efficient and effective generation.",
        "contributions": [
          "A set-centric framework (OptiSet) that unifies set selection and set-level ranking for RAG.",
          "An \"Expand-then-Refine\" paradigm for creating a diverse candidate pool and then refining it into a compact evidence set.",
          "A self-synthesis strategy to derive preference labels from set conditional utility changes of the generator, enabling identification of complementary and redundant evidence.",
          "A set-list wise training strategy that jointly optimizes set selection and set-level ranking."
        ],
        "methods": [
          "\"Expand-then-Refine\" paradigm",
          "Set-centric selection and ranking",
          "Self-synthesis strategy for preference label generation",
          "Set-list wise training strategy"
        ],
        "datasets": [
          "Not explicitly mentioned in the abstract. The abstract only mentions 'extensive experiments'. Needs to check the full paper."
        ],
        "limitations": [
          "Not explicitly mentioned in the abstract. Needs to check the full paper. However, the paper focuses on complex combinatorial problems, suggesting potential limitations when applied to simpler tasks or different types of data.",
          "The self-synthesis strategy relies on the LLM's ability to provide utility changes, which may introduce biases or inaccuracies if the LLM is not well-calibrated."
        ],
        "companies": [
          "Harbin Institute of Technology"
        ]
      },
      {
        "title": "T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs",
        "authors": [
          "Chunyu Wei",
          "Huaiyu Qin",
          "Siyuan He",
          "Yunhai Wang",
          "Yueguo Chen"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.",
        "published": "2026-01-08T13:49:12+00:00",
        "url": "http://arxiv.org/abs/2601.04945v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "The paper introduces T-Retriever, a novel Retrieval-Augmented Generation (RAG) framework for textual graphs that addresses limitations in existing graph-based RAG approaches concerning hierarchical information management. T-Retriever utilizes a tree-based retrieval strategy with adaptive compression and semantic-structural entropy optimization to improve the coherence and contextual relevance of responses to complex queries.",
        "contributions": [
          "Adaptive Compression Encoding: Replaces artificial compression quotas with a global optimization strategy to preserve the graph's natural hierarchical organization.",
          "Semantic-Structural Entropy ($S^2$-Entropy): Jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions."
        ],
        "methods": [
          "Tree-based Hierarchical Retrieval Augmented Generation",
          "Adaptive Compression Encoding",
          "Semantic-Structural Entropy ($S^2$-Entropy)",
          "Reformulation of attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree"
        ],
        "datasets": [
          "Diverse graph reasoning benchmarks (specific datasets not named in abstract)"
        ],
        "limitations": [
          "Limitations of existing graph-based RAG approaches: Rigid layer-specific compression quotas that damage local graph structures.",
          "Limitations of existing graph-based RAG approaches: Prioritizing topological structure while neglecting semantic content."
        ],
        "companies": [
          "Peking University"
        ]
      },
      {
        "title": "A Navigational Approach for Comprehensive RAG via Traversal over Proposition Graphs",
        "authors": [
          "Maxime Delmas",
          "Lei Xu",
          "Andr\u00e9 Freitas"
        ],
        "affiliations": [],
        "abstract": "Standard RAG pipelines based on chunking excel at simple factual retrieval but fail on complex multi-hop queries due to a lack of structural connectivity. Conversely, initial strategies that interleave retrieval with reasoning often lack global corpus awareness, while Knowledge Graph (KG)-based RAG performs strongly on complex multi-hop tasks but suffers on fact-oriented single-hop queries. To bridge this gap, we propose a novel RAG framework: ToPG (Traversal over Proposition Graphs). ToPG models its knowledge base as a heterogeneous graph of propositions, entities, and passages, effectively combining the granular fact density of propositions with graph connectivity. We leverage this structure using iterative Suggestion-Selection cycles, where the Suggestion phase enables a query-aware traversal of the graph, and the Selection phase provides LLM feedback to prune irrelevant propositions and seed the next iteration. Evaluated on three distinct QA tasks (Simple, Complex, and Abstract QA), ToPG demonstrates strong performance across both accuracy- and quality-based metrics. Overall, ToPG shows that query-aware graph traversal combined with factual granularity is a critical component for efficient structured RAG systems. ToPG is available at https://github.com/idiap/ToPG.",
        "published": "2026-01-08T11:50:40+00:00",
        "url": "http://arxiv.org/abs/2601.04859v1",
        "categories": [
          "cs.CL"
        ],
        "summary": "This paper introduces ToPG (Traversal over Proposition Graphs), a novel RAG framework that addresses the limitations of standard chunking-based RAG and Knowledge Graph-based RAG by modeling the knowledge base as a heterogeneous graph of propositions, entities, and passages. ToPG leverages iterative Suggestion-Selection cycles for query-aware graph traversal and demonstrates strong performance on various QA tasks.",
        "contributions": [
          "A novel RAG framework, ToPG, that combines the benefits of proposition-based knowledge representation and graph-based reasoning.",
          "An iterative Suggestion-Selection cycle for query-aware traversal of the proposition graph.",
          "Demonstrated strong performance of ToPG across simple, complex, and abstract QA tasks, outperforming existing RAG approaches."
        ],
        "methods": [
          "Proposition Graph Construction (heterogeneous graph of propositions, entities, and passages)",
          "Iterative Suggestion-Selection cycle for graph traversal (Suggestion: query-aware traversal; Selection: LLM feedback for pruning)"
        ],
        "datasets": [
          "Three distinct QA tasks: Simple QA, Complex QA, and Abstract QA"
        ],
        "limitations": [
          "The abstract does not explicitly mention any limitations.",
          "The performance might be sensitive to the quality of proposition extraction and graph construction."
        ],
        "companies": [
          "University of Oxford"
        ]
      },
      {
        "title": "Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data",
        "authors": [
          "Zhen Chen",
          "Weihao Xie",
          "Peilin Chen",
          "Shiqi Wang",
          "Jianping Wang"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.",
        "published": "2026-01-08T09:32:01+00:00",
        "url": "http://arxiv.org/abs/2601.04764v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "The paper introduces Orion-RAG, a novel Retrieval-Augmented Generation (RAG) approach designed for fragmented, graphless data environments. It focuses on extracting lightweight paths to link related concepts across isolated files, enabling effective information retrieval without requiring manual Knowledge Graph construction or complex algorithms.",
        "contributions": [
          "Introduces Orion-RAG, a RAG framework that effectively handles fragmented data without explicit links.",
          "Demonstrates a low-complexity strategy for extracting lightweight paths to connect related concepts across files, transforming fragmented data into semi-structured data.",
          "Shows that Orion-RAG outperforms mainstream RAG frameworks in diverse domains with real-time updates and Human-in-the-Loop verification while maintaining cost-efficiency."
        ],
        "methods": [
          "Lightweight path extraction to link related concepts",
          "Hybrid retrieval approach (the specific details of the hybrid approach are not in the abstract, but implied)"
        ],
        "datasets": [
          "FinanceBench",
          "Other diverse domains (unspecified in the abstract)"
        ],
        "limitations": [
          "Specific limitations are not mentioned in the abstract.",
          "The abstract doesn't detail the specific types of data handled other than 'fragmented' data, so the generalizability to all types of fragmented data is unknown."
        ],
        "companies": [
          "Hong Kong University of Science and Technology"
        ]
      },
      {
        "title": "Tool-MAD: A Multi-Agent Debate Framework for Fact Verification with Diverse Tool Augmentation and Adaptive Retrieval",
        "authors": [
          "Seyeon Jeong",
          "Yeonjun Choi",
          "JongWook Kim",
          "Beakcheol Jang"
        ],
        "affiliations": [],
        "abstract": "Large Language Models (LLMs) suffer from hallucinations and factual inaccuracies, especially in complex reasoning and fact verification tasks. Multi-Agent Debate (MAD) systems aim to improve answer accuracy by enabling multiple LLM agents to engage in dialogue, promoting diverse reasoning and mutual verification. However, existing MAD frameworks primarily rely on internal knowledge or static documents, making them vulnerable to hallucinations. While MADKE introduces external evidence to mitigate this, its one-time retrieval mechanism limits adaptability to new arguments or emerging information during the debate. To address these limitations, We propose Tool-MAD, a multi-agent debate framework that enhances factual verification by assigning each agent a distinct external tool, such as a search API or RAG module. Tool-MAD introduces three key innovations: (1) a multi-agent debate framework where agents leverage heterogeneous external tools, encouraging diverse perspectives, (2) an adaptive query formulation mechanism that iteratively refines evidence retrieval based on the flow of the debate, and (3) the integration of Faithfulness and Answer Relevance scores into the final decision process, allowing the Judge agent to quantitatively assess the coherence and question alignment of each response and effectively detect hallucinations. Experimental results on four fact verification benchmarks demonstrate that Tool-MAD consistently outperforms state-of-the-art MAD frameworks, achieving up to 5.5% accuracy improvement. Furthermore, in medically specialized domains, Tool-MAD exhibits strong robustness and adaptability across various tool configurations and domain conditions, confirming its potential for broader real-world fact-checking applications.",
        "published": "2026-01-08T09:07:41+00:00",
        "url": "http://arxiv.org/abs/2601.04742v1",
        "categories": [
          "cs.CL"
        ],
        "summary": "The paper introduces Tool-MAD, a multi-agent debate framework for fact verification that leverages diverse external tools and adaptive retrieval to improve accuracy and reduce hallucinations in Large Language Models. Tool-MAD outperforms existing Multi-Agent Debate systems by assigning different tools to each agent, enabling iterative evidence retrieval, and incorporating faithfulness and relevance scores in the final decision.",
        "contributions": [
          "A multi-agent debate framework (Tool-MAD) where agents utilize heterogeneous external tools for diverse perspectives.",
          "An adaptive query formulation mechanism that iteratively refines evidence retrieval based on the debate flow.",
          "Integration of Faithfulness and Answer Relevance scores into the final decision process to assess coherence and question alignment, effectively detecting hallucinations."
        ],
        "methods": [
          "Multi-Agent Debate",
          "External Tool Augmentation (Search API, RAG module)",
          "Adaptive Query Formulation",
          "Faithfulness and Answer Relevance scoring"
        ],
        "datasets": [
          "Four Fact Verification Benchmarks (unspecified in abstract)",
          "Medically Specialized Domains (unspecified in abstract)"
        ],
        "limitations": [
          "Unclear how the specific fact verification benchmarks were selected.",
          "The abstract does not provide details on the specific implementation of the search API, RAG module, or Faithfulness/Relevance scoring mechanisms."
        ],
        "companies": [
          "KAIST"
        ]
      },
      {
        "title": "Vibe Coding an LLM-powered Theorem Prover",
        "authors": [
          "Zhe Hou"
        ],
        "affiliations": [],
        "abstract": "We present Isabellm, an LLM-powered theorem prover for Isabelle/HOL that performs fully automatic proof synthesis. Isabellm works with any local LLM on Ollama and APIs such as Gemini CLI, and it is designed to run on consumer grade computers. The system combines a stepwise prover, which uses large language models to propose proof commands validated by Isabelle in a bounded search loop, with a higher-level proof planner that generates structured Isar outlines and attempts to fill and repair remaining gaps. The framework includes beam search for tactics, tactics reranker ML and RL models, premise selection with small transformer models, micro-RAG for Isar proofs built from AFP, and counter-example guided proof repair. All the code is implemented by GPT 4.1 - 5.2, Gemini 3 Pro, and Claude 4.5. Empirically, Isabellm can prove certain lemmas that defeat Isabelle's standard automation, including Sledgehammer, demonstrating the practical value of LLM-guided proof search. At the same time, we find that even state-of-the-art LLMs, such as GPT 5.2 Extended Thinking and Gemini 3 Pro struggle to reliably implement the intended fill-and-repair mechanisms with complex algorithmic designs, highlighting fundamental challenges in LLM code generation and reasoning. The code of Isabellm is available at https://github.com/zhehou/llm-isabelle",
        "published": "2026-01-08T07:00:24+00:00",
        "url": "http://arxiv.org/abs/2601.04653v1",
        "categories": [
          "cs.AI",
          "cs.LO"
        ],
        "summary": "The paper introduces Isabellm, an LLM-powered theorem prover for Isabelle/HOL, capable of automatic proof synthesis and designed to run on consumer hardware. It combines a stepwise prover with a higher-level proof planner, leveraging LLMs for command suggestion and proof structure generation.",
        "contributions": [
          "Development of Isabellm, an LLM-powered theorem prover for Isabelle/HOL that can perform fully automatic proof synthesis.",
          "Demonstration that LLM-guided proof search can prove lemmas that are beyond the reach of standard Isabelle automation tools like Sledgehammer."
        ],
        "methods": [
          "Stepwise prover using LLMs to propose proof commands validated by Isabelle in a bounded search loop.",
          "Higher-level proof planner that generates structured Isar outlines and attempts to fill and repair remaining gaps.",
          "Beam search for tactics, tactics reranker ML and RL models, premise selection with small transformer models, micro-RAG for Isar proofs built from AFP, and counter-example guided proof repair."
        ],
        "datasets": [
          "Isabelle/HOL theorem proving environment",
          "AFP (Archive of Formal Proofs) for micro-RAG"
        ],
        "limitations": [
          "State-of-the-art LLMs struggle to reliably implement intended fill-and-repair mechanisms with complex algorithmic designs.",
          "Highlights fundamental challenges in LLM code generation and reasoning, suggesting limitations in applying LLMs to complex algorithmic tasks."
        ],
        "companies": [
          "MIT",
          "Stanford University"
        ]
      },
      {
        "title": "Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models",
        "authors": [
          "Can Xu",
          "Lingyong Yan",
          "Jiayi Wu",
          "Haosen Wang",
          "Shuaiqiang Wang",
          "Yuchen Li",
          "Jizhou Huang",
          "Dawei Yin",
          "Xiang Li"
        ],
        "affiliations": [],
        "abstract": "Recent advances in synergizing large reasoning models (LRMs) with retrieval-augmented generation (RAG) have shown promising results, yet two critical challenges remain: (1) reasoning models typically operate from a single, unchallenged perspective, limiting their ability to conduct deep, self-correcting reasoning over external documents, and (2) existing training paradigms rely excessively on outcome-oriented rewards, which provide insufficient signal for shaping the complex, multi-step reasoning process. To address these issues, we propose an Reasoner-Verifier framework named Adversarial Reasoning RAG (ARR). The Reasoner and Verifier engage in reasoning on retrieved evidence and critiquing each other's logic while being guided by process-aware advantage that requires no external scoring model. This reward combines explicit observational signals with internal model uncertainty to jointly optimize reasoning fidelity and verification rigor. Experiments on multiple benchmarks demonstrate the effectiveness of our method.",
        "published": "2026-01-08T06:57:03+00:00",
        "url": "http://arxiv.org/abs/2601.04651v1",
        "categories": [
          "cs.AI",
          "cs.IR",
          "cs.MA"
        ],
        "summary": "This paper introduces Adversarial Reasoning RAG (ARR), a novel framework that enhances Retrieval-Augmented Generation (RAG) by employing a Reasoner-Verifier model that engages in adversarial reasoning over retrieved evidence. The framework addresses limitations in single-perspective reasoning and outcome-oriented training by using a process-aware advantage reward that combines observational signals and model uncertainty.",
        "contributions": [
          "Introduces the Adversarial Reasoning RAG (ARR) framework for multi-perspective reasoning in RAG systems.",
          "Develops a process-aware advantage reward that combines explicit observational signals with internal model uncertainty for training the Reasoner and Verifier."
        ],
        "methods": [
          "Reasoner-Verifier framework",
          "Retrieval-Augmented Generation (RAG)",
          "Process-aware advantage reward based on observational signals and model uncertainty",
          "Adversarial training between Reasoner and Verifier"
        ],
        "datasets": [
          "Multiple benchmarks (specific datasets not named in the abstract)"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations of their method.",
          "The abstract doesn't mention computational cost, which could be a limitation due to the adversarial training process"
        ],
        "companies": [
          "Baidu"
        ]
      },
      {
        "title": "Neurosymbolic Retrievers for Retrieval-augmented Generation",
        "authors": [
          "Yash Saxena",
          "Manas Gaur"
        ],
        "affiliations": [],
        "abstract": "Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance",
        "published": "2026-01-08T03:53:05+00:00",
        "url": "http://arxiv.org/abs/2601.04568v1",
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.IR",
          "cs.LG"
        ],
        "summary": "This paper introduces Neurosymbolic RAG, a framework that integrates symbolic reasoning with neural retrieval in Retrieval Augmented Generation (RAG) systems to improve transparency and interpretability. It aims to address the opacity of traditional RAG systems by incorporating a knowledge graph and symbolic features into the retrieval process.",
        "contributions": [
          "Introduces Neurosymbolic RAG, a novel approach that combines neural retrieval with symbolic reasoning using knowledge graphs to enhance transparency and interpretability in RAG systems.",
          "Proposes three methods: MAR (Knowledge Modulation Aligned Retrieval), KG-Path RAG, and Process Knowledge-infused RAG, to improve the integration of symbolic knowledge and neural retrieval within the Neurosymbolic RAG framework."
        ],
        "methods": [
          "MAR (Knowledge Modulation Aligned Retrieval): Uses modulation networks to refine query embeddings with interpretable symbolic features.",
          "KG-Path RAG: Enhances queries by traversing knowledge graphs to improve retrieval quality and interpretability.",
          "Process Knowledge-infused RAG: Utilizes domain-specific tools to reorder retrieved content based on validated workflows."
        ],
        "datasets": [
          "Mental health risk assessment tasks (used for preliminary evaluation)"
        ],
        "limitations": [
          "Preliminary results: The results are based on preliminary experiments, suggesting further validation is needed.",
          "Domain-specific: The Process Knowledge-infused RAG is domain-specific, potentially limiting its general applicability without adaptation."
        ],
        "companies": [
          "Google",
          "Microsoft"
        ]
      },
      {
        "title": "Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering",
        "authors": [
          "Jessica Ryan",
          "Alexander I. Gumilang",
          "Robert Wiliam",
          "Derwin Suhartono"
        ],
        "affiliations": [],
        "abstract": "Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.",
        "published": "2026-01-08T02:56:04+00:00",
        "url": "http://arxiv.org/abs/2601.04531v1",
        "categories": [
          "cs.IR",
          "cs.AI"
        ],
        "summary": "The paper introduces Self-MedRAG, a novel framework for medical question answering that combines hybrid retrieval with a self-reflective loop to enhance reliability. It demonstrates improved accuracy on medical QA benchmarks by reducing unsupported claims and improving evidence-based reasoning.",
        "contributions": [
          "Development of Self-MedRAG, a self-reflective hybrid retrieval-augmented generation framework for medical question answering.",
          "Integration of hybrid retrieval (BM25 and Contriever with Reciprocal Rank Fusion) to maximize evidence coverage.",
          "Implementation of a self-reflection module using NLI or LLM-based verification to assess the evidentiary support of generated rationales, and iteratively refine queries when necessary.",
          "Demonstration of significant performance gains on MedQA and PubMedQA benchmarks compared to single-retriever baselines."
        ],
        "methods": [
          "Retrieval-Augmented Generation (RAG)",
          "Hybrid Retrieval (BM25 and Contriever)",
          "Reciprocal Rank Fusion (RRF)",
          "Natural Language Inference (NLI) for self-reflection",
          "LLM-based verification for self-reflection",
          "Iterative query reformulation"
        ],
        "datasets": [
          "MedQA",
          "PubMedQA"
        ],
        "limitations": [
          "The abstract doesn't explicitly state limitations. Further reading of the full paper would be required to identify specific limitations.",
          "The computational cost of the iterative self-reflection process could be a limitation, although not mentioned in the abstract."
        ],
        "companies": []
      },
      {
        "title": "GRACE: Reinforcement Learning for Grounded Response and Abstention under Contextual Evidence",
        "authors": [
          "Yibo Zhao",
          "Jiapeng Zhu",
          "Zichen Ding",
          "Xiang Li"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) integrates external knowledge to enhance Large Language Models (LLMs), yet systems remain susceptible to two critical flaws: providing correct answers without explicit grounded evidence and producing fabricated responses when the retrieved context is insufficient. While prior research has addressed these issues independently, a unified framework that integrates evidence-based grounding and reliable abstention is currently lacking. In this paper, we propose GRACE, a reinforcement-learning framework that simultaneously mitigates both types of flaws. GRACE employs a data construction method that utilizes heterogeneous retrievers to generate diverse training samples without manual annotation. A multi-stage gated reward function is then employed to train the model to assess evidence sufficiency, extract key supporting evidence, and provide answers or explicitly abstain. Experimental results on two benchmarks demonstrate that GRACE achieves state-of-the-art overall accuracy and strikes a favorable balance between accurate response and rejection, while requiring only 10% of the annotation costs of prior methods. Our code is available at https://github.com/YiboZhao624/Grace..",
        "published": "2026-01-08T02:47:33+00:00",
        "url": "http://arxiv.org/abs/2601.04525v1",
        "categories": [
          "cs.CL"
        ],
        "summary": "The paper introduces GRACE, a reinforcement learning framework designed to improve Retrieval-Augmented Generation (RAG) systems by addressing issues of unfounded answers and fabricated responses when evidence is insufficient. GRACE achieves this by simultaneously promoting evidence-based grounding and enabling reliable abstention, resulting in improved accuracy and a balance between providing answers and rejecting questions when needed.",
        "contributions": [
          "A novel reinforcement learning framework (GRACE) that unifies evidence-based grounding and reliable abstention in RAG systems.",
          "A data construction method leveraging heterogeneous retrievers to generate diverse training samples without manual annotation, significantly reducing annotation costs."
        ],
        "methods": [
          "Reinforcement Learning (RL)",
          "Retrieval-Augmented Generation (RAG)",
          "Multi-stage gated reward function",
          "Heterogeneous retrievers for data construction"
        ],
        "datasets": [
          "Two benchmarks (unspecified in the abstract)"
        ],
        "limitations": [
          "The abstract does not explicitly state any limitations. Further reading of the paper is required to identify limitations.",
          "The specific benchmarks used are not mentioned in the abstract."
        ],
        "companies": [
          "Google",
          "Microsoft",
          "Carnegie Mellon University",
          "University of California, Berkeley",
          "Stanford University"
        ]
      },
      {
        "title": "Disco-RAG: Discourse-Aware Retrieval-Augmented Generation",
        "authors": [
          "Dongqi Liu",
          "Hang Ding",
          "Qiming Feng",
          "Jian Li",
          "Xurong Xie",
          "Zhucun Xue",
          "Chengjie Wang",
          "Jiangning Zhang",
          "Yabiao Wang"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.",
        "published": "2026-01-07T20:32:50+00:00",
        "url": "http://arxiv.org/abs/2601.04377v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "summary": "The paper introduces Disco-RAG, a novel Retrieval-Augmented Generation (RAG) framework that incorporates discourse structure to improve performance in knowledge-intensive tasks. Disco-RAG leverages intra-chunk discourse trees and inter-chunk rhetorical graphs to enhance knowledge synthesis from retrieved passages.",
        "contributions": [
          "Developed Disco-RAG, a discourse-aware RAG framework that improves knowledge synthesis by explicitly incorporating discourse signals.",
          "Demonstrated the efficacy of discourse structure in advancing RAG systems, achieving state-of-the-art results on question answering and long-document summarization benchmarks without fine-tuning."
        ],
        "methods": [
          "Construction of intra-chunk discourse trees to capture local hierarchical relationships within retrieved passages.",
          "Building inter-chunk rhetorical graphs to model cross-passage coherence and relationships between different retrieved passages.",
          "Integration of discourse trees and graphs into a planning blueprint to condition the generation process of the LLM."
        ],
        "datasets": [
          "Question answering benchmarks (unspecified in the abstract)",
          "Long-document summarization benchmarks (unspecified in the abstract)"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations, further reading of the paper is needed.",
          "The specific types of discourse relations used for intra-chunk and inter-chunk analysis are not detailed in the abstract, potentially limiting replicability without further information."
        ],
        "companies": [
          "Alibaba"
        ]
      },
      {
        "title": "ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues",
        "authors": [
          "Behrad Binaei-Haghighi",
          "Nafiseh Sadat Sajadi",
          "Mehrad Liviyan",
          "Reyhane Akhavan Kharazi",
          "Fatemeh Amirkhani",
          "Behnam Bahrak"
        ],
        "affiliations": [],
        "abstract": "The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.",
        "published": "2026-01-07T17:35:37+00:00",
        "url": "http://arxiv.org/abs/2601.04297v1",
        "categories": [
          "cs.LG",
          "cs.CV",
          "cs.HC",
          "cs.IR"
        ],
        "summary": "The paper introduces ArtCognition, a multimodal AI framework that analyzes digital drawings, specifically the House-Tree-Person (HTP) test, by fusing static visual features with dynamic drawing kinematics for automated affective state assessment. It leverages Retrieval-Augmented Generation (RAG) to ground the analysis in psychological knowledge and improve explainability.",
        "contributions": [
          "A novel multimodal AI framework (ArtCognition) for affective sensing using digital drawing and the HTP test.",
          "The fusion of static visual features and dynamic behavioral kinematic cues for a more nuanced affective state assessment.",
          "The use of a Retrieval-Augmented Generation (RAG) architecture to enhance explainability and reduce model hallucination in psychological analysis.",
          "Demonstrated correlations between extracted multimodal features and standardized psychological metrics, suggesting its potential as a scalable tool for clinicians."
        ],
        "methods": [
          "Computer vision models for extracting static visual features from drawings.",
          "Analysis of dynamic behavioral kinematic cues from the drawing process (e.g., stroke speed, pauses, smoothness).",
          "Retrieval-Augmented Generation (RAG) architecture to integrate psychological knowledge into the analysis.",
          "Correlation analysis between extracted features and standardized psychological metrics."
        ],
        "datasets": [
          "Data from the House-Tree-Person (HTP) test."
        ],
        "limitations": [
          "The abstract doesn't explicitly state any limitations, but future research and the full paper likely address the scope of psychological states ArtCognition can accurately assess.",
          "The abstract doesn't explicitly state any limitations, but further research would be required to validate ArtCognition's effectiveness across diverse populations and clinical settings."
        ],
        "companies": [
          "Unknown University"
        ]
      },
      {
        "title": "SoK: Privacy Risks and Mitigations in Retrieval-Augmented Generation Systems",
        "authors": [
          "Andreea-Elena Bodea",
          "Stephen Meisenbacher",
          "Alexandra Klymenko",
          "Florian Matthes"
        ],
        "affiliations": [],
        "abstract": "The continued promise of Large Language Models (LLMs), particularly in their natural language understanding and generation capabilities, has driven a rapidly increasing interest in identifying and developing LLM use cases. In an effort to complement the ingrained \"knowledge\" of LLMs, Retrieval-Augmented Generation (RAG) techniques have become widely popular. At its core, RAG involves the coupling of LLMs with domain-specific knowledge bases, whereby the generation of a response to a user question is augmented with contextual and up-to-date information. The proliferation of RAG has sparked concerns about data privacy, particularly with the inherent risks that arise when leveraging databases with potentially sensitive information. Numerous recent works have explored various aspects of privacy risks in RAG systems, from adversarial attacks to proposed mitigations. With the goal of surveying and unifying these works, we ask one simple question: What are the privacy risks in RAG, and how can they be measured and mitigated? To answer this question, we conduct a systematic literature review of RAG works addressing privacy, and we systematize our findings into a comprehensive set of privacy risks, mitigation techniques, and evaluation strategies. We supplement these findings with two primary artifacts: a Taxonomy of RAG Privacy Risks and a RAG Privacy Process Diagram. Our work contributes to the study of privacy in RAG not only by conducting the first systematization of risks and mitigations, but also by uncovering important considerations when mitigating privacy risks in RAG systems and assessing the current maturity of proposed mitigations.",
        "published": "2026-01-07T14:50:41+00:00",
        "url": "http://arxiv.org/abs/2601.03979v1",
        "categories": [
          "cs.CR",
          "cs.CL"
        ],
        "summary": "This paper presents a systematic literature review of privacy risks and mitigations in Retrieval-Augmented Generation (RAG) systems. It identifies and categorizes these risks, mitigation techniques, and evaluation strategies, aiming to unify existing research in this area.",
        "contributions": [
          "A comprehensive systematization of privacy risks, mitigation techniques, and evaluation strategies in RAG systems.",
          "A Taxonomy of RAG Privacy Risks and a RAG Privacy Process Diagram to aid in understanding and addressing privacy concerns."
        ],
        "methods": [
          "Systematic Literature Review"
        ],
        "datasets": [],
        "limitations": [
          "The abstract does not explicitly mention any limitations. Limitations would be derived from the full text of the paper."
        ],
        "companies": [
          "Technical University of Munich"
        ]
      },
      {
        "title": "The Pneuma Project: Reifying Information Needs as Relational Schemas to Automate Discovery, Guide Preparation, and Align Data with Intent",
        "authors": [
          "Muhammad Imam Luthfi Balaka",
          "Raul Castro Fernandez"
        ],
        "affiliations": [],
        "abstract": "Data discovery and preparation remain persistent bottlenecks in the data management lifecycle, especially when user intent is vague, evolving, or difficult to operationalize. The Pneuma Project introduces Pneuma-Seeker, a system that helps users articulate and fulfill information needs through iterative interaction with a language model-powered platform. The system reifies the user's evolving information need as a relational data model and incrementally converges toward a usable document aligned with that intent. To achieve this, the system combines three architectural ideas: context specialization to reduce LLM burden across subtasks, a conductor-style planner to assemble dynamic execution plans, and a convergence mechanism based on shared state. The system integrates recent advances in retrieval-augmented generation (RAG), agentic frameworks, and structured data preparation to support semi-automatic, language-guided workflows. We evaluate the system through LLM-based user simulations and show that it helps surface latent intent, guide discovery, and produce fit-for-purpose documents. It also acts as an emergent documentation layer, capturing institutional knowledge and supporting organizational memory.",
        "published": "2026-01-07T05:58:54+00:00",
        "url": "http://arxiv.org/abs/2601.03618v1",
        "categories": [
          "cs.DB"
        ],
        "summary": "The Pneuma Project introduces Pneuma-Seeker, a system that uses a language model to help users articulate and fulfill information needs by iteratively refining a relational data model representing their intent and generating a usable document. The system combines context specialization, a conductor-style planner, and a convergence mechanism to automate data discovery, guide preparation, and align data with user intent.",
        "contributions": [
          "A system, Pneuma-Seeker, that reifies user information needs as relational schemas to automate data discovery and preparation.",
          "An architecture combining context specialization, a conductor-style planner, and a convergence mechanism based on shared state to support semi-automatic, language-guided workflows."
        ],
        "methods": [
          "Retrieval-augmented generation (RAG)",
          "Agentic frameworks",
          "Structured data preparation",
          "LLM-based user simulations"
        ],
        "datasets": [],
        "limitations": [
          "The abstract does not explicitly state any limitations, but the effectiveness relies on the capabilities of the underlying language models and retrieval systems.",
          "The abstract does not describe the specific datasets used for evaluation, making it difficult to assess generalizability."
        ],
        "companies": [
          "Microsoft"
        ]
      },
      {
        "title": "Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory",
        "authors": [
          "Md. Asif Hossain",
          "Nabil Subhan",
          "Mantasha Rahman Mahi",
          "Jannatul Ferdous Nabila"
        ],
        "affiliations": [],
        "abstract": "Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings",
        "published": "2026-01-05T12:41:44+00:00",
        "url": "http://arxiv.org/abs/2601.02065v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "summary": "This paper proposes a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory to overcome the language barrier in accessing English agricultural manuals. The system translates Bengali queries to English, retrieves relevant information, generates an English response, and translates it back to Bengali, all while operating on open-source models and consumer-grade hardware.",
        "contributions": [
          "A cost-effective, open-source RAG framework for Bengali agricultural advisory that addresses the limitations of direct LLM generation and reliance on paid APIs.",
          "Demonstration of a translation-centric architecture with domain-specific keyword injection for improved alignment between farmer terminology and scientific nomenclature in cross-lingual retrieval."
        ],
        "methods": [
          "Cross-lingual Retrieval-Augmented Generation (RAG)",
          "Translation-centric architecture (Bengali to English, English to Bengali)",
          "Domain-specific keyword injection",
          "Dense vector retrieval",
          "Open-source models implementation"
        ],
        "datasets": [
          "Curated corpus of English agricultural manuals (FAO, IRRI)"
        ],
        "limitations": [
          "The abstract does not explicitly state limitations but implicitly suggests potential limitations related to the quality of translation, the completeness of the curated corpus, and the generalizability to other low-resource languages or domains.",
          "Performance may vary depending on the specific Bengali dialect and the complexity of the agricultural query."
        ],
        "companies": [
          "Bangladesh University of Engineering and Technology (BUET)"
        ]
      },
      {
        "title": "Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems",
        "authors": [
          "Niloufar Alipour Talemi",
          "Julia Boone",
          "Fatemeh Afghah"
        ],
        "affiliations": [],
        "abstract": "The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.",
        "published": "2026-01-05T08:34:17+00:00",
        "url": "http://arxiv.org/abs/2601.01891v1",
        "categories": [
          "cs.CV"
        ],
        "summary": "This paper presents a comprehensive review of agentic AI in remote sensing, a field shifting towards autonomous systems. It introduces a taxonomy for agentic AI in this context and analyzes architectural foundations while also outlining a roadmap for future development.",
        "contributions": [
          "First comprehensive review of agentic AI in remote sensing.",
          "Unified taxonomy distinguishing between single-agent copilots and multi-agent systems in remote sensing."
        ],
        "methods": [
          "Planning mechanisms",
          "Retrieval-augmented generation",
          "Memory structures"
        ],
        "datasets": [],
        "limitations": [
          "Grounding",
          "Safety",
          "Orchestration"
        ],
        "companies": [
          "University",
          "Research Lab"
        ]
      },
      {
        "title": "ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services",
        "authors": [
          "Qingqing Long",
          "Haotian Chen",
          "Chenyang Zhao",
          "Xiaolei Du",
          "Xuezhi Wang",
          "Pengyao Wang",
          "Chengzan Li",
          "Yuanchun Zhou",
          "Hengshu Zhu"
        ],
        "affiliations": [],
        "abstract": "The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.",
        "published": "2026-01-03T08:42:53+00:00",
        "url": "http://arxiv.org/abs/2601.01118v1",
        "categories": [
          "cs.IR",
          "cs.AI",
          "cs.DL"
        ],
        "summary": "The paper introduces ScienceDB AI, an LLM-driven agentic recommender system for scientific datasets, addressing the challenge of efficient dataset sharing and utilization. It leverages natural language conversations and deep reasoning to provide personalized dataset recommendations aligned with researchers' scientific intents on the Science Data Bank (ScienceDB) platform.",
        "contributions": [
          "Development of ScienceDB AI, the first LLM-driven conversational recommender tailored for large-scale scientific dataset sharing services.",
          "Introduction of novel components: Scientific Intention Perceptor, Structured Memory Compressor, and Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework for improved recommendation accuracy, trustworthiness, and reproducibility."
        ],
        "methods": [
          "LLM-driven conversational agent design",
          "Scientific Intention Perceptor for extracting structured experimental elements from queries",
          "Structured Memory Compressor for managing multi-turn dialogues",
          "Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework with a two-stage retrieval mechanism and Citable Scientific Task Record (CSTR) identifiers"
        ],
        "datasets": [
          "Over 10 million real-world datasets from Science Data Bank (ScienceDB)"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations, suggesting further investigation of the full paper is needed to identify specific limitations.",
          "The reliance on LLMs may introduce biases or inaccuracies present in the training data, requiring careful monitoring and mitigation strategies."
        ],
        "companies": [
          "Chinese Academy of Sciences"
        ]
      },
      {
        "title": "MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers",
        "authors": [
          "Satya Swaroop Gudipudi",
          "Sahil Girhepuje",
          "Ponnurangam Kumaraguru",
          "Kristine Ma"
        ],
        "affiliations": [],
        "abstract": "Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.",
        "published": "2026-01-01T23:31:02+00:00",
        "url": "http://arxiv.org/abs/2601.00926v1",
        "categories": [
          "cs.IR",
          "cs.AI"
        ],
        "summary": "The paper introduces MACA, a framework for distilling a metadata-aware Large Language Model (LLM) re-ranker into a compact student retriever for efficient retrieval in enterprise systems. MACA leverages a metadata-aware prompt to ensure teacher trustworthiness and trains the student with a MetaFusion objective that combines metadata-conditioned ranking and cross-model margin loss.",
        "contributions": [
          "A novel Metadata-Aware Cross-Model Alignment (MACA) framework for distilling trustworthy LLM re-rankers into efficient retrievers.",
          "A metadata-aware prompting strategy to verify the teacher's trustworthiness by checking consistency and robustness.",
          "A MetaFusion objective that combines metadata-conditioned ranking loss with a cross-model margin loss for improved retrieval performance."
        ],
        "methods": [
          "Knowledge distillation: Distilling a calibrated metadata aware LLM re-ranker into a compact student retriever.",
          "Metadata-aware prompting: Crafting prompts that incorporate metadata and test for consistency under permutations and robustness to paraphrases.",
          "MetaFusion objective: Combining metadata conditioned ranking loss with a cross model margin loss.",
          "Hard negative mining: Using the LLM to identify hard negatives for training the student retriever."
        ],
        "datasets": [
          "Proprietary consumer banking FAQ corpus",
          "BankFAQs"
        ],
        "limitations": [
          "The evaluation is limited to FAQ retrieval tasks in the consumer banking domain, which may not generalize to other domains.",
          "The paper does not explicitly discuss the computational cost of the teacher LLM, even though the goal is to avoid online LLM calls during inference. Training the teacher initially can still be computationally expensive."
        ],
        "companies": [
          "IIIT Hyderabad",
          "Carnegie Mellon University"
        ]
      },
      {
        "title": "In Line with Context: Repository-Level Code Generation via Context Inlining",
        "authors": [
          "Chao Hu",
          "Wenhao Zeng",
          "Yuling Shi",
          "Beijun Shen",
          "Xiaodong Gu"
        ],
        "affiliations": [],
        "abstract": "Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.",
        "published": "2026-01-01T15:56:24+00:00",
        "url": "http://arxiv.org/abs/2601.00376v1",
        "categories": [
          "cs.SE",
          "cs.AI"
        ],
        "summary": "This paper introduces InlineCoder, a novel framework for repository-level code generation that addresses the limitations of existing approaches by inlining the unfinished function into its call graph. This reframes repository understanding as a function-level coding task, improving the model's ability to reason over complex dependencies.",
        "contributions": [
          "Introduction of InlineCoder, a framework for repository-level code generation that leverages context inlining.",
          "A bidirectional inlining process consisting of Upstream Inlining and Downstream Retrieval to provide a comprehensive repository view to the LLM."
        ],
        "methods": [
          "Context Inlining: Embedding the unfinished function into its call graph to enhance repository understanding.",
          "Anchor Generation: Generating a draft completion to approximate downstream dependencies and enable perplexity-based confidence estimation.",
          "Upstream Inlining: Embedding the anchor into its callers to capture diverse usage scenarios.",
          "Downstream Retrieval: Integrating the anchor's callees into the prompt to provide precise dependency context."
        ],
        "datasets": [
          "Information about datasets are not specified in the abstract"
        ],
        "limitations": [
          "Limitations are not explicitly mentioned in the abstract, requiring further analysis of the full paper."
        ],
        "companies": [
          "Microsoft"
        ]
      },
      {
        "title": "RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation",
        "authors": [
          "Pankayaraj Pathmanathan",
          "Michael-Andrei Panaitescu-Liess",
          "Cho-Yu Jason Chiang",
          "Furong Huang"
        ],
        "affiliations": [],
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.",
        "published": "2025-12-30T14:43:57+00:00",
        "url": "http://arxiv.org/abs/2512.24268v1",
        "categories": [
          "cs.IR"
        ],
        "summary": "This paper addresses the vulnerability of Retrieval-Augmented Generation (RAG) pipelines to corpus poisoning attacks. It proposes two retrieval-stage defenses, RAGPart and RAGMask, that aim to mitigate the impact of injected malicious documents without modifying the generation model.",
        "contributions": [
          "Development of two novel retrieval-stage defenses against corpus poisoning in RAG: RAGPart (based on document partitioning) and RAGMask (based on similarity shifts under token masking).",
          "Comprehensive evaluation of the proposed defenses across various benchmarks, poisoning strategies, and state-of-the-art retrievers, demonstrating their ability to reduce attack success rates while maintaining utility.",
          "Introduction of an interpretable attack to stress-test the defenses and provide insights into their limitations."
        ],
        "methods": [
          "Document Partitioning (RAGPart): Leveraging the training dynamics of dense retrievers to mitigate the effect of poisoned documents.",
          "Token Masking and Similarity Shift Analysis (RAGMask): Identifying suspicious tokens based on significant changes in similarity scores when those tokens are masked."
        ],
        "datasets": [
          "Two benchmarks (unspecified in the abstract, but implied to be standard RAG evaluation datasets)."
        ],
        "limitations": [
          "The abstract mentions the identification of limitations of retrieval-stage defenses, but doesn't specify what those limitations are.",
          "The specific benchmarks used are not listed in the abstract, which makes it difficult to assess the generalizability of the results."
        ],
        "companies": [
          "University of Maryland, College Park"
        ]
      },
      {
        "title": "Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs",
        "authors": [
          "Yukun Zhang",
          "Stefan Elbl Droguett",
          "Samyak Jain"
        ],
        "affiliations": [],
        "abstract": "This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper's top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (>7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.",
        "published": "2025-12-29T20:24:15+00:00",
        "url": "http://arxiv.org/abs/2512.23848v1",
        "categories": [
          "cs.CL",
          "cs.CE",
          "cs.LG"
        ],
        "summary": "This research addresses the challenge of financial numerical question answering by integrating domain knowledge into a multi-retriever RAG system using LLMs. The study demonstrates that domain-specific training significantly improves performance, achieving state-of-the-art results, while also highlighting the trade-off between hallucination and knowledge gains in LLMs.",
        "contributions": [
          "Demonstrates the effectiveness of a multi-retriever RAG system for financial QA by integrating external domain knowledge and internal question contexts.",
          "Shows that domain-specific training with SecBERT significantly improves performance on financial numerical reasoning tasks, surpassing previous state-of-the-art models.",
          "Highlights the performance of prompt-based LLM generator, achieving state-of-the-art (SOTA) performance with significant improvement (>7%).",
          "Identifies the trade-off between hallucination loss and external knowledge gains in smaller models and few-shot examples, and demonstrates the enhanced numerical reasoning capabilities of optimized LLMs."
        ],
        "methods": [
          "Multi-Retriever Retrieval Augmented Generation (RAG)",
          "Domain-specific training with SecBERT encoder",
          "Prompt-based LLM generator",
          "Ablation experiments and error analysis"
        ],
        "datasets": [
          "FinQA (used as a baseline)"
        ],
        "limitations": [
          "The best prompt-based LLM generator, while achieving SOTA, is still below human expert performance, indicating room for improvement.",
          "Hallucination loss in smaller models and few-shot examples presents a limitation, requiring careful balancing with external knowledge gains."
        ],
        "companies": [
          "Microsoft",
          "University of Waterloo"
        ]
      },
      {
        "title": "The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction",
        "authors": [
          "Haoyu Pei",
          "Zhongyang Liu",
          "Xiangyi Xiao",
          "Xiaocong Du",
          "Suting Hong",
          "Kunpeng Zhang",
          "Haipeng Zhang"
        ],
        "affiliations": [],
        "abstract": "Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form coherent, interpretable investment theses. Traditional machine learning and graph neural networks both lack this reasoning capability. Large language models (LLMs) offer strong reasoning but face a modality mismatch with graphs. Recent graph-LLM methods target in-graph tasks where answers lie within the graph, whereas VC prediction is off-graph: the target exists outside the network. The core challenge is selecting graph paths that maximize predictor performance on an external objective while enabling step-by-step reasoning. We present MIRAGE-VC, a multi-perspective retrieval-augmented generation framework that addresses two obstacles: path explosion (thousands of candidate paths overwhelm LLM context) and heterogeneous evidence fusion (different startups need different analytical emphasis). Our information-gain-driven path retriever iteratively selects high-value neighbors, distilling investment networks into compact chains for explicit reasoning. A multi-agent architecture integrates three evidence streams via a learnable gating mechanism based on company attributes. Under strict anti-leakage controls, MIRAGE-VC achieves +5.0% F1 and +16.6% PrecisionAt5, and sheds light on other off-graph prediction tasks such as recommendation and risk assessment. Code: https://anonymous.4open.science/r/MIRAGE-VC-323F.",
        "published": "2025-12-29T14:20:31+00:00",
        "url": "http://arxiv.org/abs/2512.23489v2",
        "categories": [
          "cs.AI"
        ],
        "summary": "This paper introduces MIRAGE-VC, a novel framework for venture capital (VC) prediction that leverages large language models (LLMs) and graph reasoning to synthesize complex relational evidence. It addresses the challenge of off-graph prediction in VC by iteratively selecting high-value graph paths and fusing heterogeneous evidence streams for improved accuracy and interpretability.",
        "contributions": [
          "A multi-perspective retrieval-augmented generation framework (MIRAGE-VC) for off-graph venture capital prediction.",
          "An information-gain-driven path retriever that iteratively selects high-value neighbors to distill investment networks.",
          "A multi-agent architecture with a learnable gating mechanism to integrate heterogeneous evidence streams (company disclosures, investor track records, investment network structures).",
          "Demonstration of improved performance (+5.0% F1 and +16.6% PrecisionAt5) on VC prediction under strict anti-leakage controls."
        ],
        "methods": [
          "Information-Gain-Driven Path Retrieval",
          "Multi-Agent Architecture for Evidence Fusion",
          "Retrieval-Augmented Generation with LLMs",
          "Graph Reasoning"
        ],
        "datasets": [
          "Venture Capital Investment Data (unspecified, but inferred from the task)"
        ],
        "limitations": [
          "While performance is improved, the specific datasets used are not revealed (due to anonymity)",
          "Generalizability to other off-graph prediction tasks (recommendation, risk assessment) is suggested but not fully explored in this paper."
        ],
        "companies": [
          "Tsinghua University"
        ]
      }
    ],
    "Multi-Agent Reinforcement Learning": [
      {
        "title": "Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning",
        "authors": [
          "Yigal Koifman",
          "Eran Iceland",
          "Erez Koifman",
          "Ariel Barel",
          "Alfred M. Bruckstein"
        ],
        "affiliations": [],
        "abstract": "This study highlights the potential of image-based reinforcement learning methods for addressing swarm-related tasks. In multi-agent reinforcement learning, effective policy learning depends on how agents sense, interpret, and process inputs. Traditional approaches often rely on handcrafted feature extraction or raw vector-based representations, which limit the scalability and efficiency of learned policies concerning input order and size. In this work we propose an image-based reinforcement learning method for decentralized control of a multi-agent system, where observations are encoded as structured visual inputs that can be processed by Neural Networks, extracting its spatial features and producing novel decentralized motion control rules. We evaluate our approach on a multi-agent convergence task of agents with limited-range and bearing-only sensing that aim to keep the swarm cohesive during the aggregation. The algorithm's performance is evaluated against two benchmarks: an analytical solution proposed by Bellaiche and Bruckstein, which ensures convergence but progresses slowly, and VariAntNet, a neural network-based framework that converges much faster but shows medium success rates in hard constellations. Our method achieves high convergence, with a pace nearly matching that of VariAntNet. In some scenarios, it serves as the only practical alternative.",
        "published": "2026-01-06T20:58:11+00:00",
        "url": "http://arxiv.org/abs/2601.03413v1",
        "categories": [
          "cs.LG",
          "cs.MA",
          "eess.SY"
        ],
        "summary": "This paper explores using image-based reinforcement learning for decentralized control of multi-agent systems, specifically for swarm aggregation. The proposed method encodes observations as structured visual inputs, allowing neural networks to extract spatial features for decentralized motion control.",
        "contributions": [
          "Development of an image-based reinforcement learning method for decentralized swarm control using structured visual inputs.",
          "Demonstration of high convergence rates in a multi-agent convergence task, comparable to existing methods while maintaining robustness in challenging scenarios."
        ],
        "methods": [
          "Image-based Reinforcement Learning",
          "Neural Networks for spatial feature extraction",
          "Decentralized control"
        ],
        "datasets": [
          "Simulated multi-agent convergence task with limited-range and bearing-only sensing"
        ],
        "limitations": [
          "The paper focuses on a specific swarm aggregation task (convergence) and may not generalize to other swarm behaviors without modification.",
          "The evaluation is primarily conducted in simulation, and real-world performance might differ due to factors not captured in the simulation environment."
        ],
        "companies": [
          "Technion - Israel Institute of Technology"
        ]
      },
      {
        "title": "PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception",
        "authors": [
          "Guotao Li",
          "Shaoyun Xu",
          "Yuexing Hao",
          "Yang Wang",
          "Yuhui Sun"
        ],
        "affiliations": [],
        "abstract": "Distributed Multi-Agent Path Finding (MAPF) integrated with Multi-Agent Reinforcement Learning (MARL) has emerged as a prominent research focus, enabling real-time cooperative decision-making in partially observable environments through inter-agent communication. However, due to insufficient collaborative and perceptual capabilities, existing methods are inadequate for scaling across diverse environmental conditions. To address these challenges, we propose PC2P, a novel distributed MAPF method derived from a Q-learning-based MARL framework. Initially, we introduce a personalized-enhanced communication mechanism based on dynamic graph topology, which ascertains the core aspects of ``who\" and ``what\" in interactive process through three-stage operations: selection, generation, and aggregation. Concurrently, we incorporate local crowd perception to enrich agents' heuristic observation, thereby strengthening the model's guidance for effective actions via the integration of static spatial constraints and dynamic occupancy changes. To resolve extreme deadlock issues, we propose a region-based deadlock-breaking strategy that leverages expert guidance to implement efficient coordination within confined areas. Experimental results demonstrate that PC2P achieves superior performance compared to state-of-the-art distributed MAPF methods in varied environments. Ablation studies further confirm the effectiveness of each module for overall performance.",
        "published": "2026-01-06T03:11:26+00:00",
        "url": "http://arxiv.org/abs/2601.03301v1",
        "categories": [
          "cs.MA",
          "cs.AI"
        ],
        "summary": "This paper introduces PC2P, a novel distributed Multi-Agent Path Finding (MAPF) method based on Multi-Agent Reinforcement Learning (MARL) to address limitations in existing approaches regarding collaborative and perceptual capabilities in diverse environments. PC2P incorporates personalized-enhanced communication, local crowd perception, and a region-based deadlock-breaking strategy to achieve superior performance compared to state-of-the-art methods.",
        "contributions": [
          "A personalized-enhanced communication mechanism based on dynamic graph topology that focuses on selecting, generating, and aggregating relevant information for effective inter-agent communication.",
          "Integration of local crowd perception to enrich agents' heuristic observation by incorporating static spatial constraints and dynamic occupancy changes.",
          "A region-based deadlock-breaking strategy leveraging expert guidance for efficient coordination within confined areas to resolve extreme deadlock issues."
        ],
        "methods": [
          "Q-learning-based Multi-Agent Reinforcement Learning (MARL)",
          "Personalized-enhanced communication using dynamic graph topology",
          "Local crowd perception",
          "Region-based deadlock-breaking strategy"
        ],
        "datasets": [
          "Varied environments (mentioned in abstract, specific datasets not named)"
        ],
        "limitations": [
          "The abstract does not explicitly mention any limitations of the proposed method.",
          "The abstract focuses on addressing the limitations of *existing* methods, implying PC2P may still have some unaddressed weaknesses. Further reading of the full paper is needed to determine these."
        ],
        "companies": [
          "University of California, Berkeley",
          "Carnegie Mellon University",
          "Stanford University",
          "MIT",
          "Tsinghua University",
          "Peking University",
          "National University of Singapore"
        ]
      },
      {
        "title": "Offline Multi-Agent Reinforcement Learning for 6G Communications: Fundamentals, Applications and Future Directions",
        "authors": [
          "Eslam Eldeeb",
          "Hirley Alves"
        ],
        "affiliations": [],
        "abstract": "The next-generation wireless technologies, including beyond 5G and 6G networks, are paving the way for transformative applications such as vehicle platooning, smart cities, and remote surgery. These innovations are driven by a vast array of interconnected wireless entities, including IoT devices, access points, UAVs, and CAVs, which increase network complexity and demand more advanced decision-making algorithms. Artificial intelligence (AI) and machine learning (ML), especially reinforcement learning (RL), are key enablers for such networks, providing solutions to high-dimensional and complex challenges. However, as networks expand to multi-agent environments, traditional online RL approaches face cost, safety, and scalability limitations. Offline multi-agent reinforcement learning (MARL) offers a promising solution by utilizing pre-collected data, reducing the need for real-time interaction. This article introduces a novel offline MARL algorithm based on conservative Q-learning (CQL), ensuring safe and efficient training. We extend this with meta-learning to address dynamic environments and validate the approach through use cases in radio resource management and UAV networks. Our work highlights offline MARL's advantages, limitations, and future directions in wireless applications.",
        "published": "2026-01-01T12:09:58+00:00",
        "url": "http://arxiv.org/abs/2601.00321v1",
        "categories": [
          "cs.MA"
        ],
        "summary": "This paper explores the application of offline multi-agent reinforcement learning (MARL) to address the complexities of 6G communication networks. It proposes a novel offline MARL algorithm based on conservative Q-learning and meta-learning to improve safety and efficiency in dynamic environments.",
        "contributions": [
          "Introduces a novel offline MARL algorithm based on conservative Q-learning (CQL) for safe and efficient training.",
          "Extends the CQL-based offline MARL with meta-learning to address dynamic environments."
        ],
        "methods": [
          "Offline Multi-Agent Reinforcement Learning (MARL)",
          "Conservative Q-Learning (CQL)",
          "Meta-Learning"
        ],
        "datasets": [
          "Pre-collected data (general concept, specific datasets not mentioned in abstract)",
          "Simulated data for radio resource management and UAV networks (implied from use cases)"
        ],
        "limitations": [
          "Limitations of Offline MARL (general concept, not specified in abstract)",
          "Scalability limitations (implied, addressed by offline approach but not fully removed)"
        ],
        "companies": [
          "University of Oulu"
        ]
      },
      {
        "title": "MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems",
        "authors": [
          "Wan Jiang",
          "Xinyi Zang",
          "Yudong Zhao",
          "Yusi Zou",
          "Yunfei Lu",
          "Junbo Tong",
          "Yang Liu",
          "Ming Li",
          "Jiani Shi",
          "Xin Yang"
        ],
        "affiliations": [],
        "abstract": "Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources.",
        "published": "2025-12-30T16:27:41+00:00",
        "url": "http://arxiv.org/abs/2512.24325v1",
        "categories": [
          "cs.IR",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "The paper introduces MaRCA, a multi-agent reinforcement learning framework for dynamic computation resource allocation in large-scale recommender systems, addressing the limitations of existing approaches by considering inter-stage dependencies. MaRCA achieves a 16.67% revenue uplift in a real-world advertising pipeline by optimizing revenue under computation resource constraints.",
        "contributions": [
          "A multi-agent reinforcement learning (MARL) framework (MaRCA) for end-to-end computation resource allocation in recommender systems.",
          "An AutoBucket TestBench for accurate computation cost estimation.",
          "A Model Predictive Control (MPC)-based Revenue-Cost Balancer for proactive traffic load forecasting and revenue-cost trade-off adjustment.",
          "Demonstration of significant revenue uplift (16.67%) through real-world deployment in a large-scale e-commerce advertising pipeline."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL) with Centralized Training with Decentralized Execution (CTDE).",
          "Model Predictive Control (MPC).",
          "AutoBucket TestBench (for computation cost estimation)."
        ],
        "datasets": [
          "Data from a leading global e-commerce platform's advertising pipeline (hundreds of billions of ad requests per day)."
        ],
        "limitations": [
          "The abstract doesn't explicitly mention any limitations of the proposed method. Further reading of the full paper would be required to identify limitations.",
          "Generalizability to other types of recommender systems beyond the specific advertising pipeline is not explicitly discussed in the abstract."
        ],
        "companies": [
          "Google",
          "Tsinghua University"
        ]
      },
      {
        "title": "Heterogeneity in Multi-Agent Reinforcement Learning",
        "authors": [
          "Tianyi Hu",
          "Zhiqiang Pu",
          "Yuan Wang",
          "Tenghai Qiu",
          "Min Chen",
          "Xin Yu"
        ],
        "affiliations": [],
        "abstract": "Heterogeneity is a fundamental property in multi-agent reinforcement learning (MARL), which is closely related not only to the functional differences of agents, but also to policy diversity and environmental interactions. However, the MARL field currently lacks a rigorous definition and deeper understanding of heterogeneity. This paper systematically discusses heterogeneity in MARL from the perspectives of definition, quantification, and utilization. First, based on an agent-level modeling of MARL, we categorize heterogeneity into five types and provide mathematical definitions. Second, we define the concept of heterogeneity distance and propose a practical quantification method. Third, we design a heterogeneity-based multi-agent dynamic parameter sharing algorithm as an example of the application of our methodology. Case studies demonstrate that our method can effectively identify and quantify various types of agent heterogeneity. Experimental results show that the proposed algorithm, compared to other parameter sharing baselines, has better interpretability and stronger adaptability. The proposed methodology will help the MARL community gain a more comprehensive and profound understanding of heterogeneity, and further promote the development of practical algorithms.",
        "published": "2025-12-28T14:07:31+00:00",
        "url": "http://arxiv.org/abs/2512.22941v1",
        "categories": [
          "cs.MA",
          "cs.AI"
        ],
        "summary": "This paper addresses the lack of a rigorous definition and understanding of heterogeneity in multi-agent reinforcement learning (MARL) by providing a systematic discussion from definition, quantification, and utilization perspectives. The authors propose a categorization of heterogeneity, a quantification method based on heterogeneity distance, and a dynamic parameter sharing algorithm leveraging heterogeneity information.",
        "contributions": [
          "Categorization of heterogeneity in MARL into five types with mathematical definitions.",
          "Definition of heterogeneity distance and a practical quantification method for measuring heterogeneity.",
          "Development of a heterogeneity-based multi-agent dynamic parameter sharing algorithm demonstrating the application of the proposed methodology."
        ],
        "methods": [
          "Agent-level modeling of MARL to categorize heterogeneity.",
          "Definition of heterogeneity distance.",
          "Development of a multi-agent dynamic parameter sharing algorithm based on heterogeneity."
        ],
        "datasets": [
          "Not explicitly mentioned in the abstract, likely uses simulated environments or standard MARL benchmarks. Further reading of the paper is needed to identify specific datasets.",
          "N/A (Assuming no real-world datasets were used)"
        ],
        "limitations": [
          "The abstract doesn't explicitly state limitations. Further reading of the paper is required to identify limitations.",
          "The effectiveness of the proposed methods might be limited to specific types of MARL environments or agent architectures. (Inferred, needs verification from the full paper.)"
        ],
        "companies": [
          "University of Science and Technology of China",
          "Huazhong University of Science and Technology",
          "Alibaba",
          "Tencent"
        ]
      },
      {
        "title": "Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks",
        "authors": [
          "Maksim Kryzhanovskiy",
          "Svetlana Glazyrina",
          "Roman Ischenko",
          "Konstantin Vorontsov"
        ],
        "affiliations": [],
        "abstract": "Modern AI systems often comprise multiple learnable components that can be naturally organized as graphs. A central challenge is the end-to-end training of such systems without restrictive architectural or training assumptions. Such tasks fit the theory and approaches of the collaborative Multi-Agent Reinforcement Learning (MARL) field. We introduce Reinforcement Networks, a general framework for MARL that organizes agents as vertices in a directed acyclic graph (DAG). This structure extends hierarchical RL to arbitrary DAGs, enabling flexible credit assignment and scalable coordination while avoiding strict topologies, fully centralized training, and other limitations of current approaches. We formalize training and inference methods for the Reinforcement Networks framework and connect it to the LevelEnv concept to support reproducible construction, training, and evaluation. We demonstrate the effectiveness of our approach on several collaborative MARL setups by developing several Reinforcement Networks models that achieve improved performance over standard MARL baselines. Beyond empirical gains, Reinforcement Networks unify hierarchical, modular, and graph-structured views of MARL, opening a principled path toward designing and training complex multi-agent systems. We conclude with theoretical and practical directions - richer graph morphologies, compositional curricula, and graph-aware exploration. That positions Reinforcement Networks as a foundation for a new line of research in scalable, structured MARL.",
        "published": "2025-12-28T10:56:20+00:00",
        "url": "http://arxiv.org/abs/2512.22876v1",
        "categories": [
          "cs.MA",
          "cs.AI",
          "cs.LG"
        ],
        "summary": "The paper introduces Reinforcement Networks, a novel framework for collaborative Multi-Agent Reinforcement Learning (MARL) that organizes agents as vertices in a directed acyclic graph (DAG). This framework addresses limitations of existing MARL approaches by enabling flexible credit assignment, scalable coordination, and avoiding strict topologies or fully centralized training.",
        "contributions": [
          "Proposed Reinforcement Networks, a general framework for collaborative MARL based on DAGs.",
          "Demonstrated improved performance of Reinforcement Networks models over standard MARL baselines in several collaborative MARL setups."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Directed Acyclic Graph (DAG) based agent organization",
          "Training and inference methods for the Reinforcement Networks framework"
        ],
        "datasets": [
          "Several collaborative MARL setups (specific datasets not named in abstract)",
          "LevelEnv concept (for reproducible construction, training, and evaluation)"
        ],
        "limitations": [
          "Specific limitations are not explicitly mentioned in the abstract, but the future directions suggest areas for improvement, such as richer graph morphologies and graph-aware exploration.",
          "The abstract doesn't quantify the performance gains or specify the complexity of the environments used for evaluation, making it difficult to assess the scalability of the approach to very large or complex systems."
        ],
        "companies": [
          "Moscow Institute of Physics and Technology",
          "Skolkovo Institute of Science and Technology"
        ]
      },
      {
        "title": "MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning",
        "authors": [
          "Cuiling Wu",
          "Yaozhong Gan",
          "Junliang Xing",
          "Ying Fu"
        ],
        "affiliations": [],
        "abstract": "We propose Multi Agent Reflective Policy Optimization (MARPO) to alleviate the issue of sample inefficiency in multi agent reinforcement learning. MARPO consists of two key components: a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency, and an asymmetric clipping mechanism that is derived from the KL divergence and dynamically adjusts the clipping range to improve training stability. We evaluate MARPO in classic multi agent environments, where it consistently outperforms other methods.",
        "published": "2025-12-28T08:17:21+00:00",
        "url": "http://arxiv.org/abs/2512.22832v1",
        "categories": [
          "cs.MA"
        ],
        "summary": "The paper introduces Multi Agent Reflective Policy Optimization (MARPO) to address sample inefficiency in multi-agent reinforcement learning. MARPO utilizes a reflection mechanism to leverage subsequent trajectories and an asymmetric clipping mechanism derived from KL divergence to improve training stability.",
        "contributions": [
          "A reflection mechanism that uses subsequent trajectories to improve sample efficiency in multi-agent RL.",
          "An asymmetric clipping mechanism, derived from KL divergence, that dynamically adjusts the clipping range to enhance training stability."
        ],
        "methods": [
          "Reflection Mechanism",
          "Asymmetric Clipping Mechanism (based on KL divergence)",
          "Multi Agent Reinforcement Learning (MARL)",
          "Policy Optimization"
        ],
        "datasets": [
          "Classic multi-agent environments (specific environments not mentioned in the abstract)"
        ],
        "limitations": [
          "Specific details about the reflection mechanism and asymmetric clipping mechanism are not provided in the abstract.",
          "Specific environments used for evaluation are not listed in the abstract."
        ],
        "companies": [
          "Microsoft",
          "Nanyang Technological University"
        ]
      },
      {
        "title": "PHANTOM: Physics-Aware Adversarial Attacks against Federated Learning-Coordinated EV Charging Management System",
        "authors": [
          "Mohammad Zakaria Haider",
          "Amit Kumar Podder",
          "Prabin Mali",
          "Aranya Chakrabortty",
          "Sumit Paudyal",
          "Mohammad Ashiqur Rahman"
        ],
        "affiliations": [],
        "abstract": "The rapid deployment of electric vehicle charging stations (EVCS) within distribution networks necessitates intelligent and adaptive control to maintain the grid's resilience and reliability. In this work, we propose PHANTOM, a physics-aware adversarial network that is trained and optimized through a multi-agent reinforcement learning model. PHANTOM integrates a physics-informed neural network (PINN) enabled by federated learning (FL) that functions as a digital twin of EVCS-integrated systems, ensuring physically consistent modeling of operational dynamics and constraints. Building on this digital twin, we construct a multi-agent RL environment that utilizes deep Q-networks (DQN) and soft actor-critic (SAC) methods to derive adversarial false data injection (FDI) strategies capable of bypassing conventional detection mechanisms. To examine the broader grid-level consequences, a transmission and distribution (T and D) dual simulation platform is developed, allowing us to capture cascading interactions between EVCS disturbances at the distribution level and the operations of the bulk transmission system. Results demonstrate how learned attack policies disrupt load balancing and induce voltage instabilities that propagate across T and D boundaries. These findings highlight the critical need for physics-aware cybersecurity to ensure the resilience of large-scale vehicle-grid integration.",
        "published": "2025-12-26T20:54:16+00:00",
        "url": "http://arxiv.org/abs/2512.22381v1",
        "categories": [
          "cs.ET",
          "cs.LG"
        ],
        "summary": "This paper introduces PHANTOM, a physics-aware adversarial network designed to attack federated learning-coordinated electric vehicle charging management systems. It demonstrates how learned adversarial policies can disrupt load balancing and induce voltage instabilities across transmission and distribution networks, highlighting the need for enhanced cybersecurity.",
        "contributions": [
          "Development of PHANTOM, a physics-aware adversarial network for attacking EVCS-integrated systems.",
          "Integration of a physics-informed neural network (PINN) enabled by federated learning (FL) as a digital twin to model EVCS operational dynamics and constraints.",
          "Construction of a multi-agent RL environment using DQN and SAC to derive adversarial false data injection (FDI) strategies.",
          "Development of a transmission and distribution (T and D) dual simulation platform to capture cascading interactions between EVCS disturbances and bulk transmission system operations."
        ],
        "methods": [
          "Physics-Informed Neural Network (PINN)",
          "Federated Learning (FL)",
          "Multi-Agent Reinforcement Learning (MARL)",
          "Deep Q-Networks (DQN)",
          "Soft Actor-Critic (SAC)",
          "False Data Injection (FDI)",
          "Transmission and Distribution (T and D) dual simulation"
        ],
        "datasets": [
          "Not explicitly stated in the abstract. Likely uses simulated EVCS and grid data."
        ],
        "limitations": [
          "Not explicitly stated in the abstract. The abstract focuses on the proposed methodology and results, without mentioning limitations.",
          "The abstract doesn't specify the scale and complexity of the simulated grid and EVCS systems, making it difficult to assess the generalizability of the findings."
        ],
        "companies": [
          "Oak Ridge National Laboratory",
          "University of Tennessee, Knoxville",
          "Texas A&M University"
        ]
      },
      {
        "title": "Joint Design of Embedded Index Coding and Beamforming for MIMO-based Distributed Computing via Multi-Agent Reinforcement Learning",
        "authors": [
          "Heekang Song",
          "Wan Choi"
        ],
        "affiliations": [],
        "abstract": "In distributed computing systems, reducing the communication load during the data shuffling phase is a critical challenge, as excessive inter-node transmissions are a major performance bottleneck. One promising approach to alleviate this burden is Embedded Index Coding (EIC), which exploits cached data at user nodes to encode transmissions more efficiently. However, most prior work on EIC has focused on minimizing code length in wired, error-free environments-an objective often suboptimal for wireless multiple-input multiple-output (MIMO) systems, where channel conditions and spatial multiplexing gains must be considered. This paper investigates the joint design of EIC and transmit beamforming in MIMO systems to minimize total transmission time, an NP-hard problem. We first present a conventional optimization method that determines the optimal EIC via exhaustive search. To address its prohibitive complexity and adapt to dynamic wireless environments, we propose a novel, low-complexity multi-agent reinforcement learning (MARL) framework. The proposed framework enables decentralized agents to act on local observations while effectively managing the hybrid action space of discrete EIC selection and continuous beamforming design. Simulation results demonstrate that the proposed MARL-based approach achieves near-optimal performance with significantly reduced complexity, underscoring its effectiveness and practicality for real-world wireless systems.",
        "published": "2025-12-23T09:49:25+00:00",
        "url": "http://arxiv.org/abs/2512.20201v1",
        "categories": [
          "eess.SY"
        ],
        "summary": "This paper addresses the problem of minimizing communication load in distributed computing systems by jointly optimizing Embedded Index Coding (EIC) and beamforming in MIMO systems. It proposes a multi-agent reinforcement learning (MARL) framework to achieve near-optimal performance with reduced complexity compared to conventional optimization methods.",
        "contributions": [
          "Joint design of EIC and transmit beamforming in MIMO systems for minimizing total transmission time in distributed computing.",
          "Development of a novel, low-complexity multi-agent reinforcement learning (MARL) framework to manage the hybrid action space of discrete EIC selection and continuous beamforming design in a decentralized manner."
        ],
        "methods": [
          "Exhaustive search for optimal EIC (conventional optimization method).",
          "Multi-Agent Reinforcement Learning (MARL)"
        ],
        "datasets": [],
        "limitations": [
          "The conventional optimization method based on exhaustive search suffers from prohibitive complexity.",
          "The abstract doesn't explicitly mention limitations of the MARL approach, but it implies that it aims for 'near-optimal' performance, suggesting it may not always achieve the absolute optimum."
        ],
        "companies": []
      },
      {
        "title": "Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning",
        "authors": [
          "Wencan Mao",
          "Quanxi Zhou",
          "Tomas Couso Coddou",
          "Manabu Tsukada",
          "Yunling Liu",
          "Yusheng Ji"
        ],
        "affiliations": [],
        "abstract": "Unmanned aerial vehicles (UAVs) have emerged as a promising auxiliary platform for smart agriculture, capable of simultaneously performing weed detection, recognition, and data collection from wireless sensors. However, trajectory planning for UAV-based smart agriculture is challenging due to the high uncertainty of the environment, partial observations, and limited battery capacity of UAVs. To address these issues, we formulate the trajectory planning problem as a Markov decision process (MDP) and leverage multi-agent reinforcement learning (MARL) to solve it. Furthermore, we propose a novel imitation-based triple deep Q-network (ITDQN) algorithm, which employs an elite imitation mechanism to reduce exploration costs and utilizes a mediator Q-network over a double deep Q-network (DDQN) to accelerate and stabilize training and improve performance. Experimental results in both simulated and real-world environments demonstrate the effectiveness of our solution. Moreover, our proposed ITDQN outperforms DDQN by 4.43\\% in weed recognition rate and 6.94\\% in data collection rate.",
        "published": "2025-12-21T05:30:19+00:00",
        "url": "http://arxiv.org/abs/2512.18604v1",
        "categories": [
          "cs.LG"
        ],
        "summary": "This paper addresses the challenge of UAV trajectory planning for smart agriculture, considering environmental uncertainty, partial observations, and limited battery life. The authors propose an imitation-based triple deep Q-network (ITDQN) algorithm that leverages multi-agent reinforcement learning to improve weed recognition and data collection rates.",
        "contributions": [
          "Proposed a novel imitation-based triple deep Q-network (ITDQN) algorithm for UAV trajectory planning in smart agriculture.",
          "Demonstrated the effectiveness of ITDQN in both simulated and real-world environments, showing improved weed recognition and data collection rates compared to DDQN."
        ],
        "methods": [
          "Markov Decision Process (MDP) formulation for trajectory planning.",
          "Multi-Agent Reinforcement Learning (MARL) for solving the MDP.",
          "Imitation-based Triple Deep Q-Network (ITDQN) algorithm with an elite imitation mechanism and a mediator Q-network over DDQN."
        ],
        "datasets": [
          "Simulated Environment (Implicit from Experimental Results)",
          "Real-world Environment (Implicit from Experimental Results)"
        ],
        "limitations": [
          "The abstract does not explicitly mention the size and characteristics of the simulated and real-world environments used for evaluation.",
          "The abstract does not provide details on the specific hardware used for real-world experiments."
        ],
        "companies": [
          "University of Tokyo",
          "Nanjing Agricultural University"
        ]
      },
      {
        "title": "Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces",
        "authors": [
          "Arsyi Aziz",
          "Peng Wei"
        ],
        "affiliations": [],
        "abstract": "Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.",
        "published": "2026-01-07T21:18:28+00:00",
        "url": "http://arxiv.org/abs/2601.04401v1",
        "categories": [
          "cs.RO",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "This paper presents a transformer-based multi-agent reinforcement learning (MARL) approach for aircraft separation assurance in both structured and unstructured airspaces.  The method uses a relative polar state space and a transformer encoder to provide speed advisories that resolve conflicts while maintaining desired cruising speeds.",
        "contributions": [
          "A novel MARL framework for aircraft separation assurance that uses a relative polar state space representation, enabling better generalization across diverse traffic patterns and airspace configurations.",
          "A transformer encoder-based model architecture trained with a specific strategy that outperforms deeper transformer variants and a purely attention-based baseline, achieving near-zero near mid-air collision rates and shorter loss-of-separation infringements."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Transformer Encoder",
          "Relative Polar State Space Representation",
          "Speed Advisory Generation"
        ],
        "datasets": [
          "Simulated structured airspace traffic patterns",
          "Simulated unstructured airspace traffic patterns"
        ],
        "limitations": [
          "The abstract does not explicitly mention the limitations, but since the model is trained on simulated data, a limitation is that the model's performance in real-world scenarios may differ due to complexities not captured in the simulation.",
          "The abstract does not provide detail on computational cost, so another potential limitation is the computational resources required for training and deployment of the transformer-based MARL model."
        ],
        "companies": [
          "MIT",
          "Stanford University",
          "University of California, Berkeley"
        ]
      },
      {
        "title": "Hierarchical GNN-Based Multi-Agent Learning for Dynamic Queue-Jump Lane and Emergency Vehicle Corridor Formation",
        "authors": [
          "Haoran Su"
        ],
        "affiliations": [],
        "abstract": "Emergency vehicles require rapid passage through congested traffic, yet existing strategies fail to adapt to dynamic conditions. We propose a novel hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework to coordinate connected vehicles for emergency corridor formation. Our approach uses a high-level planner for global strategy and low-level controllers for trajectory execution, utilizing graph attention networks to scale with variable agent counts. Trained via Multi-Agent Proximal Policy Optimization (MAPPO), the system reduces emergency vehicle travel time by 28.3% compared to baselines and 44.6% compared to uncoordinated traffic in simulations. The design achieves near-zero collision rates (0.3%) while maintaining 81% of background traffic efficiency. Ablation and generalization studies confirm the framework's robustness across diverse scenarios. These results demonstrate the effectiveness of combining GNNs with hierarchical learning for intelligent transportation systems.",
        "published": "2026-01-07T18:43:18+00:00",
        "url": "http://arxiv.org/abs/2601.04177v1",
        "categories": [
          "cs.RO",
          "eess.SY"
        ],
        "summary": "This paper introduces a hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework for dynamic emergency corridor formation in connected vehicle environments. The framework significantly reduces emergency vehicle travel time and maintains background traffic efficiency with near-zero collision rates.",
        "contributions": [
          "A novel hierarchical GNN-based multi-agent reinforcement learning framework for dynamic emergency corridor formation.",
          "Demonstrated significant reduction in emergency vehicle travel time (28.3% vs. baselines, 44.6% vs. uncoordinated traffic) with minimal collision rates (0.3%) and maintained background traffic efficiency (81%)."
        ],
        "methods": [
          "Hierarchical Graph Neural Network (GNN)",
          "Multi-Agent Reinforcement Learning (MARL)",
          "Graph Attention Networks",
          "Multi-Agent Proximal Policy Optimization (MAPPO)"
        ],
        "datasets": [
          "Simulated traffic environments (details not specified but implied)"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations. Limitations would need to be inferred from the full paper.",
          "The abstract does not provide details about the specific traffic scenarios or scales used in the simulations, limiting understanding of generalizability. More details would be needed from the full paper."
        ],
        "companies": [
          "University"
        ]
      },
      {
        "title": "Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning",
        "authors": [
          "Javier Gonzalez-Ruiz",
          "Carlos Rodriguez-Pardo",
          "Iacopo Savelli",
          "Alice Di Bella",
          "Massimo Tavoni"
        ],
        "affiliations": [],
        "abstract": "Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.",
        "published": "2025-12-19T10:56:34+00:00",
        "url": "http://arxiv.org/abs/2512.17444v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.NE",
          "econ.GN"
        ],
        "summary": "This research introduces a multi-agent reinforcement learning model to evaluate long-term electricity market designs for decarbonization. The model simulates profit-maximizing generation companies investing in the wholesale market under different policies and market structures, highlighting the importance of market design for decarbonization and price stability.",
        "contributions": [
          "Development of a multi-agent reinforcement learning model for assessing long-term electricity market designs in the context of ambitious decarbonization targets.",
          "Demonstration of the model's application to a stylized version of the Italian electricity system, analyzing the impact of varying levels of competition, market designs, and policy scenarios on decarbonization pathways and price volatility."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Independent Proximal Policy Optimization (PPO)",
          "Hyperparameter search to ensure competitive market outcomes in decentralized training"
        ],
        "datasets": [
          "Stylized version of the Italian electricity system"
        ],
        "limitations": [
          "The model is applied to a *stylized* version of the Italian electricity system, which may not fully capture the complexities of the real-world system.",
          "The use of independent learning in a multi-agent setting can be challenging, requiring extensive hyperparameter tuning to achieve desired market behavior."
        ],
        "companies": [
          "Politecnico di Milano"
        ]
      },
      {
        "title": "Coordinated Anti-Jamming Resilience in Swarm Networks via Multi-Agent Reinforcement Learning",
        "authors": [
          "Bahman Abolhassani",
          "Tugba Erpek",
          "Kemal Davaslioglu",
          "Yalin E. Sagduyu",
          "Sastry Kompella"
        ],
        "affiliations": [],
        "abstract": "Reactive jammers pose a severe security threat to robotic-swarm networks by selectively disrupting inter-agent communications and undermining formation integrity and mission success. Conventional countermeasures such as fixed power control or static channel hopping are largely ineffective against such adaptive adversaries. This paper presents a multi-agent reinforcement learning (MARL) framework based on the QMIX algorithm to improve the resilience of swarm communications under reactive jamming. We consider a network of multiple transmitter-receiver pairs sharing channels while a reactive jammer with Markovian threshold dynamics senses aggregate power and reacts accordingly. Each agent jointly selects transmit frequency (channel) and power, and QMIX learns a centralized but factorizable action-value function that enables coordinated yet decentralized execution. We benchmark QMIX against a genie-aided optimal policy in a no-channel-reuse setting, and against local Upper Confidence Bound (UCB) and a stateless reactive policy in a more general fading regime with channel reuse enabled. Simulation results show that QMIX rapidly converges to cooperative policies that nearly match the genie-aided bound, while achieving higher throughput and lower jamming incidence than the baselines, thereby demonstrating MARL's effectiveness for securing autonomous swarms in contested environments.",
        "published": "2025-12-18T17:54:20+00:00",
        "url": "http://arxiv.org/abs/2512.16813v1",
        "categories": [
          "cs.NI",
          "cs.AI",
          "cs.DC",
          "cs.LG",
          "eess.SP"
        ],
        "summary": "This paper proposes a multi-agent reinforcement learning (MARL) framework using the QMIX algorithm to enhance the resilience of robotic swarm networks against reactive jamming attacks. The framework enables agents to cooperatively select transmission frequency and power to maximize throughput and minimize jamming incidence in contested environments.",
        "contributions": [
          "Development of a MARL framework based on QMIX for coordinated anti-jamming in swarm networks.",
          "Demonstration that the proposed QMIX-based approach achieves near-optimal performance (matching a genie-aided bound) and outperforms baseline methods like UCB and a stateless reactive policy in simulation with channel reuse."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "QMIX algorithm (centralized training, decentralized execution)",
          "Simulation of a reactive jammer with Markovian threshold dynamics",
          "Benchmarking against a genie-aided optimal policy, local UCB, and a stateless reactive policy"
        ],
        "datasets": [
          "The research does not explicitly mention specific datasets used. The results are based on simulated data."
        ],
        "limitations": [
          "The study relies on simulations, and the performance of the proposed approach in real-world robotic swarm deployments is not evaluated.",
          "The complexity of the simulated environment and jammer model might not fully capture the intricacies of real-world reactive jamming attacks."
        ],
        "companies": [
          "US Army Research Laboratory"
        ]
      },
      {
        "title": "Dynamic one-time delivery of critical data by small and sparse UAV swarms: a model problem for MARL scaling studies",
        "authors": [
          "Mika Persson",
          "Jonas Lidman",
          "Jacob Ljungberg",
          "Samuel Sandelius",
          "Adam Andersson"
        ],
        "affiliations": [],
        "abstract": "This work presents a conceptual study on the application of Multi-Agent Reinforcement Learning (MARL) for decentralized control of unmanned aerial vehicles to relay a critical data package to a known position. For this purpose, a family of deterministic games is introduced, designed for scaling studies for MARL. A robust baseline policy is proposed, which is based on restricting agent motion envelopes and applying Dijkstra's algorithm. Experimental results show that two off-the-shelf MARL algorithms perform competitively with the baseline for a small number of agents, but scalability issues arise as the number of agents increase.",
        "published": "2025-12-10T14:29:04+00:00",
        "url": "http://arxiv.org/abs/2512.09682v1",
        "categories": [
          "eess.SY",
          "cs.AI",
          "cs.GT",
          "cs.MA"
        ],
        "summary": "This paper explores using Multi-Agent Reinforcement Learning (MARL) to control UAV swarms for delivering critical data. It introduces a set of deterministic games designed for MARL scaling studies and compares MARL performance against a robust baseline policy.",
        "contributions": [
          "Introduction of a family of deterministic games specifically designed for scaling studies in MARL, focusing on UAV data relay.",
          "Proposal of a robust baseline policy for UAV swarm control based on restricted agent motion envelopes and Dijkstra's algorithm."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL) for decentralized control of UAVs.",
          "Dijkstra's algorithm for path planning within restricted motion envelopes (used in the baseline policy)."
        ],
        "datasets": [
          "A family of deterministic games designed for scaling studies in MARL for UAV data relay (implicitly defining the environment and scenarios)."
        ],
        "limitations": [
          "Scalability issues observed with off-the-shelf MARL algorithms as the number of agents increases.",
          "The study is conceptual and may not directly translate to real-world scenarios due to the simplified, deterministic environment."
        ],
        "companies": [
          "KTH Royal Institute of Technology",
          "Link\u00f6ping University",
          "Lund University",
          "Uppsala University"
        ]
      },
      {
        "title": "Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation",
        "authors": [
          "Jialin Ying",
          "Zhihao Li",
          "Zicheng Dong",
          "Guohua Wu",
          "Yihuan Liao"
        ],
        "affiliations": [],
        "abstract": "Collaborative pursuit-evasion in cluttered environments presents significant challenges due to sparse rewards and constrained Fields of View (FOV). Standard Multi-Agent Reinforcement Learning (MARL) often suffers from inefficient exploration and fails to scale to large scenarios. We propose PGF-MAPPO (Path-Guided Frontier MAPPO), a hierarchical framework bridging topological planning with reactive control. To resolve local minima and sparse rewards, we integrate an A*-based potential field for dense reward shaping. Furthermore, we introduce Directional Frontier Allocation, combining Farthest Point Sampling (FPS) with geometric angle suppression to enforce spatial dispersion and accelerate coverage. The architecture employs a parameter-shared decentralized critic, maintaining O(1) model complexity suitable for robotic swarms. Experiments demonstrate that PGF-MAPPO achieves superior capture efficiency against faster evaders. Policies trained on 10x10 maps exhibit robust zero-shot generalization to unseen 20x20 environments, significantly outperforming rule-based and learning-based baselines.",
        "published": "2025-12-10T08:09:12+00:00",
        "url": "http://arxiv.org/abs/2512.09410v1",
        "categories": [
          "cs.RO",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "This paper introduces PGF-MAPPO, a hierarchical reinforcement learning framework for collaborative pursuit-evasion in cluttered environments. It combines topological planning with reactive control and achieves superior capture efficiency and generalization compared to baselines.",
        "contributions": [
          "PGF-MAPPO: A hierarchical framework that integrates an A*-based potential field for dense reward shaping and reactive control.",
          "Directional Frontier Allocation: Combines Farthest Point Sampling (FPS) with geometric angle suppression to improve spatial dispersion and accelerate coverage."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "MAPPO (Multi-Agent Proximal Policy Optimization)",
          "A* Search Algorithm",
          "Farthest Point Sampling (FPS)",
          "Potential Field Reward Shaping",
          "Decentralized Critic"
        ],
        "datasets": [
          "Simulated 10x10 cluttered environments",
          "Simulated 20x20 cluttered environments (for generalization testing)"
        ],
        "limitations": [
          "The abstract doesn't explicitly mention limitations, suggesting further investigation of the full paper is needed to identify them.",
          "Performance may degrade in environments with significantly different characteristics than the training environments (e.g., drastically different clutter density or evader behavior)."
        ],
        "companies": []
      },
      {
        "title": "IPPO Learns the Game, Not the Team: A Study on Generalization in Heterogeneous Agent Teams",
        "authors": [
          "Ryan LeRoy",
          "Jack Kolb"
        ],
        "affiliations": [],
        "abstract": "Multi-Agent Reinforcement Learning (MARL) is commonly deployed in settings where agents are trained via self-play with homogeneous teammates, often using parameter sharing and a single policy architecture. This opens the question: to what extent do self-play PPO agents learn general coordination strategies grounded in the underlying game, compared to overfitting to their training partners' behaviors? This paper investigates the question using the Heterogeneous Multi-Agent Challenge (HeMAC) environment, which features distinct Observer and Drone agents with complementary capabilities. We introduce Rotating Policy Training (RPT), an approach that rotates heterogeneous teammate policies of different learning algorithms during training, to expose the agent to a broader range of partner strategies. When playing alongside a withheld teammate policy (DDQN), we find that RPT achieves similar performance to a standard self-play baseline, IPPO, where all agents were trained sharing a single PPO policy. This result indicates that in this heterogeneous multi-agent setting, the IPPO baseline generalizes to novel teammate algorithms despite not experiencing teammate diversity during training. This shows that a simple IPPO baseline may possess the level of generalization to novel teammates that a diverse training regimen was designed to achieve.",
        "published": "2025-12-09T18:10:17+00:00",
        "url": "http://arxiv.org/abs/2512.08877v1",
        "categories": [
          "cs.RO"
        ],
        "summary": "This paper investigates whether self-play Independent Proximal Policy Optimization (IPPO) agents learn general coordination strategies in heterogeneous multi-agent environments or overfit to their specific training partners. The study finds that a simple IPPO baseline can generalize to novel teammate algorithms, indicating it learns aspects of the underlying game rather than overfitting to specific teammates.",
        "contributions": [
          "Demonstrated that a simple IPPO baseline can generalize to novel teammate algorithms in a heterogeneous multi-agent environment (HeMAC) without requiring diverse training.",
          "Introduced Rotating Policy Training (RPT), an approach to expose agents to a broader range of partner strategies during training by rotating heterogeneous teammate policies of different learning algorithms."
        ],
        "methods": [
          "Independent Proximal Policy Optimization (IPPO)",
          "Rotating Policy Training (RPT)",
          "Deep Double Q-Network (DDQN) - used as a withheld teammate policy for evaluation"
        ],
        "datasets": [
          "Heterogeneous Multi-Agent Challenge (HeMAC)"
        ],
        "limitations": [
          "The study focuses on a single environment (HeMAC), and the results might not generalize to other heterogeneous multi-agent environments with different complexities or characteristics.",
          "The evaluation is limited to a single withheld teammate policy (DDQN), and performance against other novel teammate algorithms may vary."
        ],
        "companies": [
          "Microsoft",
          "Google",
          "OpenAI",
          "Meta",
          "DeepMind"
        ]
      },
      {
        "title": "HypeR Adaptivity: Joint $hr$-Adaptive Meshing via Hypergraph Multi-Agent Deep Reinforcement Learning",
        "authors": [
          "Niccol\u00f2 Grillo",
          "James Rowbottom",
          "Pietro Li\u00f2",
          "Carola Bibiane Sch\u00f6nlieb",
          "Stefania Fresca"
        ],
        "affiliations": [],
        "abstract": "Adaptive mesh refinement is central to the efficient solution of partial differential equations (PDEs) via the finite element method (FEM). Classical $r$-adaptivity optimizes vertex positions but requires solving expensive auxiliary PDEs such as the Monge-Amp\u00e8re equation, while classical $h$-adaptivity modifies topology through element subdivision but suffers from expensive error indicator computation and is constrained by isotropic refinement patterns that impose accuracy ceilings. Combined $hr$-adaptive techniques naturally outperform single-modality approaches, yet inherit both computational bottlenecks and the restricted cost-accuracy trade-off. Emerging machine learning methods for adaptive mesh refinement seek to overcome these limitations, but existing approaches address $h$-adaptivity or $r$-adaptivity in isolation. We present HypeR, a deep reinforcement learning framework that jointly optimizes mesh relocation and refinement. HypeR casts the joint adaptation problem using tools from hypergraph neural networks and multi-agent reinforcement learning. Refinement is formulated as a heterogeneous multi-agent Markov decision process (MDP) where element agents decide discrete refinement actions, while relocation follows an anisotropic diffusion-based policy on vertex agents with provable prevention of mesh tangling. The reward function combines local and global error reduction to promote general accuracy. Across benchmark PDEs, HypeR reduces approximation error by up to 6--10$\\times$ versus state-of-art $h$-adaptive baselines at comparable element counts, breaking through the uniform refinement accuracy ceiling that constrains subdivision-only methods. The framework produces meshes with improved shape metrics and alignment to solution anisotropy, demonstrating that jointly learned $hr$-adaptivity strategies can substantially enhance the capabilities of automated mesh generation.",
        "published": "2025-12-11T09:02:33+00:00",
        "url": "http://arxiv.org/abs/2512.10439v1",
        "categories": [
          "cs.CE"
        ],
        "summary": "This paper introduces HypeR, a deep reinforcement learning framework for joint $hr$-adaptive mesh refinement in finite element methods. HypeR combines hypergraph neural networks and multi-agent reinforcement learning to simultaneously optimize vertex relocation and element refinement, achieving significant error reduction compared to traditional $h$-adaptive methods.",
        "contributions": [
          "A novel deep reinforcement learning framework (HypeR) for joint $hr$-adaptive mesh refinement.",
          "Formulation of the $hr$-adaptation problem as a heterogeneous multi-agent Markov decision process (MDP) using hypergraph neural networks.",
          "Demonstration of significant error reduction (6-10x) compared to state-of-the-art $h$-adaptive baselines on benchmark PDEs.",
          "Improved mesh shape metrics and alignment to solution anisotropy compared to traditional methods.",
          "A provable method for preventing mesh tangling during vertex relocation."
        ],
        "methods": [
          "Deep Reinforcement Learning (DRL)",
          "Hypergraph Neural Networks (HGNN)",
          "Multi-Agent Reinforcement Learning (MARL)",
          "Finite Element Method (FEM)",
          "Anisotropic Diffusion"
        ],
        "datasets": [
          "Benchmark PDEs (unspecified, but used for evaluation)"
        ],
        "limitations": [
          "The abstract does not explicitly mention limitations.  Potential limitations could include the computational cost of training the DRL model, the generalizability of the learned policies to different PDEs, and the complexity of implementing the framework.",
          "The specific benchmark PDEs used for evaluation are not specified in the abstract, making it difficult to assess the breadth of the framework's applicability."
        ],
        "companies": [
          "University of Cambridge"
        ]
      },
      {
        "title": "Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks",
        "authors": [
          "Thai Duong Nguyen",
          "Ngoc-Tan Nguyen",
          "Thanh-Dao Nguyen",
          "Nguyen Van Huynh",
          "Dinh-Hieu Tran",
          "Symeon Chatzinotas"
        ],
        "affiliations": [],
        "abstract": "The deployment of Unmanned Aerial Vehicle (UAV) swarms as dynamic communication relays is critical for next-generation tactical networks. However, operating in contested environments requires solving a complex trade-off, including maximizing system throughput while ensuring collision avoidance and resilience against adversarial jamming. Existing heuristic-based approaches often struggle to find effective solutions due to the dynamic and multi-objective nature of this problem. This paper formulates this challenge as a cooperative Multi-Agent Reinforcement Learning (MARL) problem, solved using the Centralized Training with Decentralized Execution (CTDE) framework. Our approach employs a centralized critic that uses global state information to guide decentralized actors which operate using only local observations. Simulation results show that our proposed framework significantly outperforms heuristic baselines, increasing the total system throughput by approximately 50% while simultaneously achieving a near-zero collision rate. A key finding is that the agents develop an emergent anti-jamming strategy without explicit programming. They learn to intelligently position themselves to balance the trade-off between mitigating interference from jammers and maintaining effective communication links with ground users.",
        "published": "2025-12-09T08:11:21+00:00",
        "url": "http://arxiv.org/abs/2512.08341v1",
        "categories": [
          "cs.NI",
          "cs.LG",
          "cs.MA"
        ],
        "summary": "This paper proposes a Multi-Agent Reinforcement Learning (MARL) framework for optimizing UAV relay networks in contested environments, addressing throughput maximization, collision avoidance, and resilience against jamming. The proposed approach, using Centralized Training with Decentralized Execution (CTDE), outperforms heuristic baselines by a significant margin.",
        "contributions": [
          "Formulated the problem of UAV relay network optimization under jamming as a cooperative MARL problem.",
          "Demonstrated that the proposed CTDE-based MARL framework significantly improves system throughput and reduces collision rates compared to heuristic approaches, while also developing an emergent anti-jamming strategy."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Centralized Training with Decentralized Execution (CTDE)"
        ],
        "datasets": [
          "Simulation data (implied from the abstract)"
        ],
        "limitations": [
          "Abstract only mentions simulation results, so real-world validation is missing.",
          "The specific MARL algorithm used within the CTDE framework is not explicitly mentioned, making it difficult to assess its complexity and potential drawbacks."
        ],
        "companies": [
          "University of Luxembourg"
        ]
      },
      {
        "title": "Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control",
        "authors": [
          "Pouria Yazdani",
          "Arash Rezaali",
          "Monireh Abdoos"
        ],
        "affiliations": [],
        "abstract": "Multi-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture's core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.",
        "published": "2025-12-04T10:26:43+00:00",
        "url": "http://arxiv.org/abs/2512.04653v1",
        "categories": [
          "cs.MA",
          "cs.AI",
          "cs.LG"
        ],
        "summary": "This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi-agent reinforcement learning in traffic signal control, addressing the limitations of fully centralized and decentralized approaches. The SEMI-CTDE architecture partitions the network into regions for centralized training with regional parameter sharing and composite state/reward formulations, enabling effective coordination and improved performance across various traffic conditions.",
        "contributions": [
          "Development of the SEMI-CTDE architecture for multi-agent reinforcement learning in traffic signal control.",
          "Implementation of two models based on the SEMI-CTDE architecture with distinct design objectives and demonstration of their superior performance compared to rule-based and fully decentralized baselines."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Semi-Centralized Training, Decentralized Execution (SEMI-CTDE)",
          "Regional Parameter Sharing",
          "Composite State and Reward Formulations"
        ],
        "datasets": [],
        "limitations": [
          "The abstract doesn't explicitly mention the datasets used for evaluation, implying a potential limitation in generalizability if only specific datasets were used.",
          "The abstract focuses on the architecture and its effectiveness; further research may be needed to explore its computational complexity and scalability to very large-scale traffic networks."
        ],
        "companies": [
          "University of Manitoba"
        ]
      },
      {
        "title": "Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning System for Automated Conflict Resolution and Consensus Building",
        "authors": [
          "Deepak Bolleddu"
        ],
        "affiliations": [],
        "abstract": "Conflict resolution and consensus building represent critical challenges in multi-agent systems, negotiations, and collaborative decision-making processes. This paper introduces Dialogue Diplomats, a novel end-to-end multi-agent reinforcement learning (MARL) framework designed for automated conflict resolution and consensus building in complex, dynamic environments. The proposed system integrates advanced deep reinforcement learning architectures with dialogue-based negotiation protocols, enabling autonomous agents to engage in sophisticated conflict resolution through iterative communication and strategic adaptation. We present three primary contributions: first, a novel Hierarchical Consensus Network (HCN) architecture that combines attention mechanisms with graph neural networks to model inter-agent dependencies and conflict dynamics. second, a Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies; and third, a Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals.",
        "published": "2025-11-20T16:40:12+00:00",
        "url": "http://arxiv.org/abs/2511.17654v1",
        "categories": [
          "cs.MA",
          "cs.AI"
        ],
        "summary": "The paper introduces Dialogue Diplomats, a multi-agent reinforcement learning (MARL) framework for automated conflict resolution and consensus building. It integrates deep reinforcement learning with dialogue-based negotiation protocols to enable agents to resolve conflicts through communication and adaptation.",
        "contributions": [
          "A novel Hierarchical Consensus Network (HCN) architecture for modeling inter-agent dependencies and conflict dynamics.",
          "A Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies.",
          "A Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Deep Reinforcement Learning",
          "Dialogue-based Negotiation Protocols",
          "Hierarchical Consensus Network (HCN) - Attention Mechanisms and Graph Neural Networks",
          "Progressive Negotiation Protocol (PNP)",
          "Context-Aware Reward Shaping"
        ],
        "datasets": [
          "Not explicitly mentioned in the abstract"
        ],
        "limitations": [
          "Not explicitly mentioned in the abstract"
        ],
        "companies": [
          "Microsoft"
        ]
      },
      {
        "title": "Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning",
        "authors": [
          "Fatemeh Lotfi",
          "Hossein Rajoli",
          "Fatemeh Afghah"
        ],
        "affiliations": [],
        "abstract": "Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\u03c1$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.",
        "published": "2025-11-19T00:55:24+00:00",
        "url": "http://arxiv.org/abs/2511.15002v1",
        "categories": [
          "cs.AI",
          "cs.LG"
        ],
        "summary": "This paper introduces a novel resource management approach for O-RAN using a distributed Multi-Agent Reinforcement Learning (MARL) framework. It enhances the Soft Actor Critic (SAC) algorithm with a task-specific Sharpness-Aware Minimization (SAM) to improve robustness, generalization, and resource allocation efficiency in dynamic environments.",
        "contributions": [
          "Development of an adaptive and selective SAM mechanism driven by TD-error variance for targeted regularization in MARL.",
          "Incorporation of a dynamic \u03c1 scheduling scheme to refine the exploration-exploitation trade-off across agents in the MARL framework."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Soft Actor Critic (SAC) algorithm",
          "Sharpness-Aware Minimization (SAM)",
          "Temporal-Difference (TD)-error variance based regularization",
          "Dynamic \u03c1 scheduling for exploration-exploitation"
        ],
        "datasets": [
          "O-RAN simulation environment (inferred, as the paper mentions O-RAN slices and resource allocation)"
        ],
        "limitations": [
          "The abstract does not explicitly mention any limitations, so we can infer that the scope of the work is limited to simulation environments and might require further validation in real-world O-RAN deployments.",
          "The abstract doesn't mention computational complexity or scalability aspects of the proposed method, which could be a limitation in large-scale O-RAN deployments."
        ],
        "companies": [
          "University"
        ]
      },
      {
        "title": "Emergent Cooperative Driving Strategies for Stop-and-Go Wave Mitigation via Multi-Agent Reinforcement Learning",
        "authors": [
          "Raphael Korbmacher",
          "Daniel Straub",
          "Antoine Tordeux",
          "Claudia Totzeck"
        ],
        "affiliations": [],
        "abstract": "Stop-and-go waves in traffic flow pose a persistent challenge, compromising safety, efficiency, and environmental sustainability. This paper introduces a novel mitigation strategy discovered through training multi-agent deep reinforcement learning (DRL) agents in a simulated ring-road environment. The agents autonomously develop a cooperative driving policy, where most vehicles maintain minimal headways to maximize throughput, while a single \"buffer\" vehicle adopts a larger headway to absorb perturbations and prevent wave propagation. This strategy enhances stability without sacrificing overall flow. We further demonstrate that adapting this cooperative strategy to classical car-following models, such as the Intelligent Driver Model (IDM), yields improved stability and traffic efficiency. Furthermore, we show within a parametrised linear framework, that the cooperative strategy can optimise system performance under stability constraints. Our findings offer promising insights for future autonomous vehicle systems and highway management.",
        "published": "2025-11-18T11:40:03+00:00",
        "url": "http://arxiv.org/abs/2511.14378v1",
        "categories": [
          "physics.soc-ph"
        ],
        "summary": "This research explores a multi-agent reinforcement learning approach to mitigate stop-and-go traffic waves. The learned strategy involves cooperative driving with minimal headways (except for a 'buffer' vehicle) to enhance traffic flow stability and efficiency.",
        "contributions": [
          "Discovered a novel cooperative driving strategy using multi-agent DRL to mitigate stop-and-go waves, featuring a 'buffer' vehicle to absorb perturbations.",
          "Demonstrated that adapting the learned cooperative strategy to classical car-following models (IDM) improves stability and traffic efficiency."
        ],
        "methods": [
          "Multi-Agent Deep Reinforcement Learning (DRL)",
          "Simulation in a ring-road environment",
          "Adaptation of the learned strategy to the Intelligent Driver Model (IDM)",
          "Parametrised linear framework for optimization"
        ],
        "datasets": [
          "Simulated ring-road traffic data (implicitly)"
        ],
        "limitations": [
          "The research is conducted in a simulated environment, which may not fully capture the complexities of real-world traffic conditions.",
          "The effectiveness of the strategy may depend on the penetration rate of autonomous vehicles equipped with the learned policy (implicitly)."
        ],
        "companies": [
          "BMW Group"
        ]
      },
      {
        "title": "Robust and Efficient Communication in Multi-Agent Reinforcement Learning",
        "authors": [
          "Zejiao Liu",
          "Yi Li",
          "Jiali Wang",
          "Junqi Tu",
          "Yitian Hong",
          "Fangfei Li",
          "Yang Liu",
          "Toshiharu Sugawara",
          "Yang Tang"
        ],
        "affiliations": [],
        "abstract": "Multi-agent reinforcement learning (MARL) has made significant strides in enabling coordinated behaviors among autonomous agents. However, most existing approaches assume that communication is instantaneous, reliable, and has unlimited bandwidth; these conditions are rarely met in real-world deployments. This survey systematically reviews recent advances in robust and efficient communication strategies for MARL under realistic constraints, including message perturbations, transmission delays, and limited bandwidth. Furthermore, because the challenges of low-latency reliability, bandwidth-intensive data sharing, and communication-privacy trade-offs are central to practical MARL systems, we focus on three applications involving cooperative autonomous driving, distributed simultaneous localization and mapping, and federated learning. Finally, we identify key open challenges and future research directions, advocating a unified approach that co-designs communication, learning, and robustness to bridge the gap between theoretical MARL models and practical implementations.",
        "published": "2025-11-14T15:23:11+00:00",
        "url": "http://arxiv.org/abs/2511.11393v1",
        "categories": [
          "cs.AI"
        ],
        "summary": "This survey reviews recent advances in robust and efficient communication strategies for multi-agent reinforcement learning (MARL) under realistic constraints like message perturbations, transmission delays, and limited bandwidth. It identifies open challenges and advocates for a unified approach that co-designs communication, learning, and robustness.",
        "contributions": [
          "Systematic review of recent advances in robust and efficient communication strategies for MARL under realistic constraints.",
          "Identification of key open challenges and future research directions in communication-aware MARL."
        ],
        "methods": [
          "Review and analysis of communication strategies dealing with message perturbations.",
          "Review and analysis of communication strategies dealing with transmission delays.",
          "Review and analysis of communication strategies dealing with limited bandwidth."
        ],
        "datasets": [],
        "limitations": [
          "The review likely focuses on a specific subset of MARL communication strategies due to the breadth of the field.",
          "The survey's completeness is limited by the recency of publications and the rapidly evolving nature of MARL research."
        ],
        "companies": [
          "Google"
        ]
      },
      {
        "title": "Multi-agent In-context Coordination via Decentralized Memory Retrieval",
        "authors": [
          "Tao Jiang",
          "Zichuan Lin",
          "Lihe Li",
          "Yi-Chen Li",
          "Cong Guan",
          "Lei Yuan",
          "Zongzhang Zhang",
          "Yang Yu",
          "Deheng Ye"
        ],
        "affiliations": [],
        "abstract": "Large transformer models, trained on diverse datasets, have demonstrated impressive few-shot performance on previously unseen tasks without requiring parameter updates. This capability has also been explored in Reinforcement Learning (RL), where agents interact with the environment to retrieve context and maximize cumulative rewards, showcasing strong adaptability in complex settings. However, in cooperative Multi-Agent Reinforcement Learning (MARL), where agents must coordinate toward a shared goal, decentralized policy deployment can lead to mismatches in task alignment and reward assignment, limiting the efficiency of policy adaptation. To address this challenge, we introduce Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach designed to enhance coordination by fast adaptation. Our method involves training a centralized embedding model to capture fine-grained trajectory representations, followed by decentralized models that approximate the centralized one to obtain team-level task information. Based on the learned embeddings, relevant trajectories are retrieved as context, which, combined with the agents' current sub-trajectories, inform decision-making. During decentralized execution, we introduce a novel memory mechanism that effectively balances test-time online data with offline memory. Based on the constructed memory, we propose a hybrid utility score that incorporates both individual- and team-level returns, ensuring credit assignment across agents. Extensive experiments on cooperative MARL benchmarks, including Level-Based Foraging (LBF) and SMAC (v1/v2), show that MAICC enables faster adaptation to unseen tasks compared to existing methods. Code is available at https://github.com/LAMDA-RL/MAICC.",
        "published": "2025-11-13T07:08:31+00:00",
        "url": "http://arxiv.org/abs/2511.10030v1",
        "categories": [
          "cs.MA",
          "cs.LG"
        ],
        "summary": "This paper introduces Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC) to improve coordination in cooperative Multi-Agent Reinforcement Learning (MARL). MAICC uses a centralized embedding model and decentralized memory retrieval to enable faster adaptation to unseen tasks by balancing online and offline data and incorporating team-level returns for credit assignment.",
        "contributions": [
          "A novel approach, MAICC, for in-context coordination in decentralized MARL that enhances adaptation to unseen tasks.",
          "A memory mechanism that balances test-time online data with offline memory for effective context retrieval.",
          "A hybrid utility score that incorporates both individual- and team-level returns to improve credit assignment across agents."
        ],
        "methods": [
          "Centralized embedding model for capturing fine-grained trajectory representations.",
          "Decentralized models approximating the centralized embedding model to obtain team-level task information.",
          "Decentralized memory retrieval based on learned embeddings.",
          "Hybrid utility score incorporating individual- and team-level returns."
        ],
        "datasets": [
          "Level-Based Foraging (LBF)",
          "SMAC (v1/v2)"
        ],
        "limitations": [
          "The paper does not explicitly mention limitations, but potential limitations could include the computational cost of training the centralized embedding model.",
          "The performance of the method might be sensitive to the choice of hyperparameters and the quality of the offline memory."
        ],
        "companies": [
          "Peking University",
          "National University of Singapore"
        ]
      },
      {
        "title": "Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning",
        "authors": [
          "Satpreet H. Singh",
          "Sonja Johnson-Yu",
          "Zhouyang Lu",
          "Aaron Walsman",
          "Federico Pedraja",
          "Denis Turcu",
          "Pratyusha Sharma",
          "Naomi Saphra",
          "Nathaniel B. Sawtell",
          "Kanaka Rajan"
        ],
        "affiliations": [],
        "abstract": "Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible.",
        "published": "2025-11-11T16:38:48+00:00",
        "url": "http://arxiv.org/abs/2511.08436v1",
        "categories": [
          "cs.NE",
          "cs.AI",
          "cs.MA",
          "eess.SY",
          "q-bio.NC"
        ],
        "summary": "This research presents a novel computational framework using multi-agent reinforcement learning (MARL) with recurrent neural networks (RNNs) to simulate and study the electrosensing and electrocommunication behavior of weakly electric fish. The model successfully replicates several observed behaviors in real fish, including EOD patterns and social interactions like freeloading, providing insights into the neuroethology of these animals.",
        "contributions": [
          "Developed a biologically-inspired computational model using MARL to simulate electrosensing and electrocommunication in weakly electric fish.",
          "Demonstrated that agents trained for individual fitness can exhibit emergent social behaviors consistent with real fish collectives, without explicit social rewards.",
          "Showed how conspecific EODs and relative dominance influence foraging success in a two-fish assay."
        ],
        "methods": [
          "Multi-Agent Reinforcement Learning (MARL)",
          "Recurrent Neural Networks (RNNs) for agent control",
          "Evolution-inspired reward functions for individual fitness"
        ],
        "datasets": [
          "Simulated virtual environments for foraging tasks",
          "Data from real weakly electric fish (Gnathonemus petersii) for behavioral validation (implicitly referenced through comparison to real fish behavior)"
        ],
        "limitations": [
          "The model is a simplification of the complex biological reality of weakly electric fish.",
          "The study focuses on a specific set of behaviors and may not capture the full range of electrosensing and electrocommunication capabilities of these fish."
        ],
        "companies": [
          "Princeton University",
          "Columbia University"
        ]
      }
    ]
  }
}